{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the averge loss and standard deviation of the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from statistics import mean, stdev\n",
    "\n",
    "def parse_final_losses_from_file(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Split content by blocks between delimiter lines\n",
    "    blocks = content.split(\"=\" * 80)\n",
    "\n",
    "    model_losses = defaultdict(list)\n",
    "\n",
    "    for block in blocks:\n",
    "        model_match = re.search(r'([^\\s]+)\\s*->\\s*([^\\n]+)', block)\n",
    "        loss_match = re.search(r'Final Loss:\\s*([0-9.]+)', block)\n",
    "\n",
    "        if model_match and loss_match:\n",
    "            teacher_model = model_match.group(1).strip()\n",
    "            student_model = model_match.group(2).strip()\n",
    "            loss = float(loss_match.group(1))\n",
    "\n",
    "            # Aggregate by teacher -> student combination\n",
    "            pair_key = f\"{teacher_model} -> {student_model}\"\n",
    "            model_losses[pair_key].append(loss)\n",
    "    return model_losses\n",
    "\n",
    "def aggregate_losses(folder_path):\n",
    "    aggregated_losses = defaultdict(list)\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                file_losses = parse_final_losses_from_file(file_path)\n",
    "                for model, losses in file_losses.items():\n",
    "                    aggregated_losses[model].extend(losses)\n",
    "                    \n",
    "    summary = {}\n",
    "    for model_pair, losses in aggregated_losses.items():\n",
    "        avg = mean(losses)\n",
    "        std = stdev(losses) if len(losses) > 1 else 0.0\n",
    "        summary[model_pair] = (avg, std)\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Final Loss ± Std per Teacher -> Student Model:\n",
      "nonoverlappingCNN_relu -> fcnn_decreasing_relu: 0.0003 ± 0.0001\n",
      "nonoverlappingCNN_relu -> fcnn_decreasing_sigmoid: 3.3007 ± 0.0316\n",
      "nonoverlappingCNN_relu -> fcnn_decreasing_tanh: 3.5434 ± 0.0319\n",
      "nonoverlappingCNN_sigmoid -> fcnn_decreasing_relu: 0.0111 ± 0.0001\n",
      "nonoverlappingCNN_sigmoid -> fcnn_decreasing_sigmoid: 0.0026 ± 0.0000\n",
      "nonoverlappingCNN_sigmoid -> fcnn_decreasing_tanh: 0.2528 ± 0.0000\n",
      "nonoverlappingCNN_tanh -> fcnn_decreasing_relu: 0.1941 ± 0.0010\n",
      "nonoverlappingCNN_tanh -> fcnn_decreasing_sigmoid: 0.2940 ± 0.0994\n",
      "nonoverlappingCNN_tanh -> fcnn_decreasing_tanh: 0.0004 ± 0.0000\n"
     ]
    }
   ],
   "source": [
    "#init 0.2\n",
    "folder = \"../experiment_output/Experiment3/init0.2\"\n",
    "results = aggregate_losses(folder)\n",
    "\n",
    "print(\"Average Final Loss ± Std per Teacher -> Student Model:\")\n",
    "for model_pair, (avg_loss, std_loss) in sorted(results.items()):\n",
    "    print(f\"{model_pair}: {avg_loss:.4f} ± {std_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Final Loss ± Std per Teacher -> Student Model:\n",
      "nonoverlappingCNN_relu -> fcnn_decreasing_relu: 0.0003 ± 0.0001\n",
      "nonoverlappingCNN_relu -> fcnn_decreasing_sigmoid: 3.2904 ± 0.0496\n",
      "nonoverlappingCNN_relu -> fcnn_decreasing_tanh: 3.5330 ± 0.0501\n",
      "nonoverlappingCNN_sigmoid -> fcnn_decreasing_relu: 0.0111 ± 0.0001\n",
      "nonoverlappingCNN_sigmoid -> fcnn_decreasing_sigmoid: 0.0004 ± 0.0000\n",
      "nonoverlappingCNN_sigmoid -> fcnn_decreasing_tanh: 0.2526 ± 0.0001\n",
      "nonoverlappingCNN_tanh -> fcnn_decreasing_relu: 0.1938 ± 0.0013\n",
      "nonoverlappingCNN_tanh -> fcnn_decreasing_sigmoid: 0.1850 ± 0.0015\n",
      "nonoverlappingCNN_tanh -> fcnn_decreasing_tanh: 0.0004 ± 0.0000\n"
     ]
    }
   ],
   "source": [
    "#init 1\n",
    "folder = \"../experiment_output/Experiment3/init1\"\n",
    "results = aggregate_losses(folder)\n",
    "\n",
    "print(\"Average Final Loss ± Std per Teacher -> Student Model:\")\n",
    "for model_pair, (avg_loss, std_loss) in sorted(results.items()):\n",
    "    print(f\"{model_pair}: {avg_loss:.4f} ± {std_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "def load_model_weights(model_path):\n",
    "    \"\"\"Load model weights from a .pth file.\"\"\"\n",
    "    checkpoint = torch.load(model_path, map_location=torch.device(\"cpu\"))\n",
    "    model_state = checkpoint[\"student_model_state_dict\"]\n",
    "    return {k: v.cpu().numpy() for k, v in model_state.items() if \"weight\" in k}\n",
    "\n",
    "# compute level of sparsity of model\n",
    "def compute_sparsity(weights_dict):\n",
    "    \"\"\"Compute the sparsity of model weights.\"\"\"\n",
    "    sparsity = {}\n",
    "    for layer_name, weights in weights_dict.items():\n",
    "        num_elements = weights.size\n",
    "        num_zeros = (abs(weights) < 1e-4).sum()\n",
    "        sparsity[layer_name] = num_zeros / num_elements    \n",
    "    return sparsity\n",
    "\n",
    "def compute_all_sparsity(directory):\n",
    "    model_sparsities = {}  # model filename → average sparsity\n",
    "    best_model = None\n",
    "    best_sparsity = float(\"-inf\")\n",
    "\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if not file.endswith(\".pth\"):\n",
    "                continue\n",
    "\n",
    "            model_path = os.path.join(root, file)\n",
    "\n",
    "            weights_dict = load_model_weights(model_path)\n",
    "            sparsity = compute_sparsity(weights_dict)\n",
    "            avg_sparsity = sum(sparsity.values()) / len(sparsity)\n",
    "\n",
    "            model_sparsities[file] = avg_sparsity\n",
    "\n",
    "            for layer_name, sparsity_value in sparsity.items():\n",
    "                pass\n",
    "            #     print(f\"Sparsity of {layer_name}: {sparsity_value * 100:.2f}%\")\n",
    "\n",
    "            # print(f\"→ Average sparsity for '{file}': {avg_sparsity * 100:.2f}%\")\n",
    "\n",
    "            if avg_sparsity > best_sparsity:\n",
    "                best_sparsity = avg_sparsity\n",
    "                best_model = file\n",
    "\n",
    "    print(\"\\n========== Summary ==========\")\n",
    "    for model_file, avg in model_sparsities.items():\n",
    "        print(f\"{model_file}: {avg * 100:.2f}% avg sparsity\")\n",
    "\n",
    "    # return model_sparsities, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Summary ==========\n",
      "nonoverlappingCNN_relu__fcnn_decreasing_sigmoid.pth: 85.52% avg sparsity\n",
      "nonoverlappingCNN_sigmoid__fcnn_decreasing_relu.pth: 84.43% avg sparsity\n",
      "nonoverlappingCNN_sigmoid__fcnn_decreasing_tanh.pth: 98.69% avg sparsity\n",
      "nonoverlappingCNN_tanh__fcnn_decreasing_tanh.pth: 95.27% avg sparsity\n",
      "nonoverlappingCNN_tanh__fcnn_decreasing_sigmoid.pth: 66.67% avg sparsity\n",
      "nonoverlappingCNN_relu__fcnn_decreasing_tanh.pth: 86.18% avg sparsity\n",
      "nonoverlappingCNN_relu__fcnn_decreasing_relu.pth: 97.77% avg sparsity\n",
      "nonoverlappingCNN_sigmoid__fcnn_decreasing_sigmoid.pth: 66.67% avg sparsity\n",
      "nonoverlappingCNN_tanh__fcnn_decreasing_relu.pth: 76.62% avg sparsity\n"
     ]
    }
   ],
   "source": [
    "#init 0.2\n",
    "compute_all_sparsity(\"../experiment_output/Experiment3/init0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Summary ==========\n",
      "nonoverlappingCNN_relu__fcnn_decreasing_sigmoid.pth: 59.77% avg sparsity\n",
      "nonoverlappingCNN_sigmoid__fcnn_decreasing_relu.pth: 88.36% avg sparsity\n",
      "nonoverlappingCNN_sigmoid__fcnn_decreasing_tanh.pth: 98.42% avg sparsity\n",
      "nonoverlappingCNN_tanh__fcnn_decreasing_tanh.pth: 95.28% avg sparsity\n",
      "nonoverlappingCNN_tanh__fcnn_decreasing_sigmoid.pth: 63.82% avg sparsity\n",
      "nonoverlappingCNN_relu__fcnn_decreasing_tanh.pth: 78.03% avg sparsity\n",
      "nonoverlappingCNN_relu__fcnn_decreasing_relu.pth: 96.33% avg sparsity\n",
      "nonoverlappingCNN_sigmoid__fcnn_decreasing_sigmoid.pth: 65.41% avg sparsity\n",
      "nonoverlappingCNN_tanh__fcnn_decreasing_relu.pth: 78.80% avg sparsity\n"
     ]
    }
   ],
   "source": [
    "#init 1\n",
    "compute_all_sparsity(\"../experiment_output/Experiment3/init1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
