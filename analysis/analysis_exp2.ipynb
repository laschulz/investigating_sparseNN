{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the averge loss and standard deviation of the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from statistics import mean, stdev\n",
    "\n",
    "def parse_final_losses_from_file(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Split content by blocks between delimiter lines\n",
    "    blocks = content.split(\"=\" * 80)\n",
    "\n",
    "    model_losses = defaultdict(list)\n",
    "\n",
    "    for block in blocks:\n",
    "        model_match = re.search(r'([^\\s]+)\\s*->\\s*([^\\n]+)', block)\n",
    "        loss_match = re.search(r'Final Loss:\\s*([0-9.]+)', block)\n",
    "\n",
    "        if model_match and loss_match:\n",
    "            teacher_model = model_match.group(1).strip()\n",
    "            student_model = model_match.group(2).strip()\n",
    "            loss = float(loss_match.group(1))\n",
    "\n",
    "            # Aggregate by teacher -> student combination\n",
    "            pair_key = f\"{teacher_model} -> {student_model}\"\n",
    "            model_losses[pair_key].append(loss)\n",
    "    return model_losses\n",
    "\n",
    "def aggregate_losses(folder_path):\n",
    "    aggregated_losses = defaultdict(list)\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                file_losses = parse_final_losses_from_file(file_path)\n",
    "                for model, losses in file_losses.items():\n",
    "                    aggregated_losses[model].extend(losses)\n",
    "                    \n",
    "    summary = {}\n",
    "    for model_pair, losses in aggregated_losses.items():\n",
    "        avg = mean(losses)\n",
    "        std = stdev(losses) if len(losses) > 1 else 0.0\n",
    "        summary[model_pair] = (avg, std)\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Final Loss ± Std per Teacher -> Student Model:\n",
      "baselineCNN_relu -> multiChannelCNN_relu: 0.0000 ± 0.0000\n",
      "baselineCNN_relu -> multiChannelCNN_sigmoid: 3.3447 ± 0.0848\n",
      "baselineCNN_relu -> multiChannelCNN_tanh: 3.6629 ± 0.0827\n",
      "baselineCNN_sigmoid -> multiChannelCNN_relu: 0.0118 ± 0.0004\n",
      "baselineCNN_sigmoid -> multiChannelCNN_sigmoid: 0.0000 ± 0.0000\n",
      "baselineCNN_sigmoid -> multiChannelCNN_tanh: 0.2514 ± 0.0005\n",
      "baselineCNN_tanh -> multiChannelCNN_relu: 0.2155 ± 0.0099\n",
      "baselineCNN_tanh -> multiChannelCNN_sigmoid: 0.2226 ± 0.0843\n",
      "baselineCNN_tanh -> multiChannelCNN_tanh: 0.0000 ± 0.0000\n"
     ]
    }
   ],
   "source": [
    "folder = \"../experiment_output/Experiment2/exp2_noReg_init0.2\"\n",
    "results = aggregate_losses(folder)\n",
    "\n",
    "print(\"Average Final Loss ± Std per Teacher -> Student Model:\")\n",
    "for model_pair, (avg_loss, std_loss) in sorted(results.items()):\n",
    "    print(f\"{model_pair}: {avg_loss:.4f} ± {std_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "def load_model_weights(model_path):\n",
    "    \"\"\"Load model weights from a .pth file.\"\"\"\n",
    "    checkpoint = torch.load(model_path, map_location=torch.device(\"cpu\"))\n",
    "    model_state = checkpoint[\"student_model_state_dict\"]\n",
    "    return {k: v.cpu().numpy() for k, v in model_state.items() if \"weight\" in k}\n",
    "\n",
    "def compute_sparsity(weights_dict):\n",
    "    \"\"\"Compute the sparsity of model weights (per layer).\"\"\"\n",
    "    sparsity = {}\n",
    "    for layer_name, weights in weights_dict.items():\n",
    "        num_elements = weights.size\n",
    "        num_zeros = (abs(weights) < 1e-4).sum()\n",
    "        sparsity[layer_name] = num_zeros / num_elements    \n",
    "    return sparsity\n",
    "\n",
    "def compute_layerwise_sparsity(directory):\n",
    "    \"\"\"Compute and print layer-wise sparsity for each model in a folder.\"\"\"\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if not file.endswith(\".pth\"):\n",
    "                continue\n",
    "\n",
    "            model_path = os.path.join(root, file)\n",
    "            weights_dict = load_model_weights(model_path)\n",
    "            sparsity = compute_sparsity(weights_dict)\n",
    "\n",
    "            print(f\"\\nModel: {file}\")\n",
    "            for layer_name, sparsity_value in sparsity.items():\n",
    "                print(f\"  {layer_name}: {sparsity_value * 100:.2f}% sparsity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: nonoverlappingCNN_sigmoid__overlappingCNN_sigmoid.pth\n",
      "  layers.0.weight: 0.00% sparsity\n",
      "  layers.1.weight: 0.00% sparsity\n",
      "  layers.2.weight: 0.00% sparsity\n",
      "\n",
      "Model: nonoverlappingCNN_tanh__overlappingCNN_sigmoid.pth\n",
      "  layers.0.weight: 0.00% sparsity\n",
      "  layers.1.weight: 0.00% sparsity\n",
      "  layers.2.weight: 0.00% sparsity\n",
      "\n",
      "Model: nonoverlappingCNN_relu__overlappingCNN_relu.pth\n",
      "  layers.0.weight: 8.33% sparsity\n",
      "  layers.1.weight: 9.38% sparsity\n",
      "  layers.2.weight: 0.00% sparsity\n",
      "\n",
      "Model: nonoverlappingCNN_tanh__overlappingCNN_tanh.pth\n",
      "  layers.0.weight: 0.00% sparsity\n",
      "  layers.1.weight: 0.00% sparsity\n",
      "  layers.2.weight: 0.00% sparsity\n",
      "\n",
      "Model: nonoverlappingCNN_relu__overlappingCNN_sigmoid.pth\n",
      "  layers.0.weight: 0.00% sparsity\n",
      "  layers.1.weight: 0.00% sparsity\n",
      "  layers.2.weight: 0.00% sparsity\n",
      "\n",
      "Model: nonoverlappingCNN_sigmoid__overlappingCNN_relu.pth\n",
      "  layers.0.weight: 0.00% sparsity\n",
      "  layers.1.weight: 0.00% sparsity\n",
      "  layers.2.weight: 0.00% sparsity\n",
      "\n",
      "Model: nonoverlappingCNN_sigmoid__overlappingCNN_tanh.pth\n",
      "  layers.0.weight: 0.00% sparsity\n",
      "  layers.1.weight: 0.00% sparsity\n",
      "  layers.2.weight: 0.00% sparsity\n",
      "\n",
      "Model: nonoverlappingCNN_tanh__overlappingCNN_relu.pth\n",
      "  layers.0.weight: 0.00% sparsity\n",
      "  layers.1.weight: 0.00% sparsity\n",
      "  layers.2.weight: 0.00% sparsity\n",
      "\n",
      "Model: nonoverlappingCNN_relu__overlappingCNN_tanh.pth\n",
      "  layers.0.weight: 0.00% sparsity\n",
      "  layers.1.weight: 0.00% sparsity\n",
      "  layers.2.weight: 0.00% sparsity\n"
     ]
    }
   ],
   "source": [
    "compute_layerwise_sparsity(\"../experiment_output/Experiment2/experiments_exp2_l2_init1_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def parse_final_losses_from_file(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Split into blocks using separator line\n",
    "    blocks = content.split(\"=\" * 80)\n",
    "\n",
    "    model_losses = defaultdict(list)\n",
    "\n",
    "    for block in blocks:\n",
    "        model_match = re.search(r'([^\\s]+)\\s*->\\s*([^\\n]+)', block)\n",
    "        loss_match = re.search(r'Final Loss:\\s*([0-9.]+)', block)\n",
    "\n",
    "        if model_match and loss_match:\n",
    "            teacher_model = model_match.group(1).strip()\n",
    "            student_model = model_match.group(2).strip()\n",
    "            loss = float(loss_match.group(1))\n",
    "\n",
    "            pair_key = f\"{teacher_model} -> {student_model}\"\n",
    "            model_losses[pair_key].append(loss)\n",
    "    return model_losses\n",
    "\n",
    "def collect_all_losses(folder_path):\n",
    "    all_losses = defaultdict(list)\n",
    "\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                file_losses = parse_final_losses_from_file(file_path)\n",
    "                for model_pair, losses in file_losses.items():\n",
    "                    all_losses[model_pair].extend(losses)\n",
    "\n",
    "    # Print results\n",
    "    for model_pair, losses in all_losses.items():\n",
    "        print(f\"{model_pair}:\")\n",
    "        for i, loss in enumerate(losses):\n",
    "            print(f\"  Run {i+1}: {loss}\")\n",
    "    \n",
    "    #return all_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonoverlappingCNN_sigmoid -> overlappingCNN_sigmoid:\n",
      "  Run 1: 0.0001\n",
      "nonoverlappingCNN_sigmoid -> overlappingCNN_relu:\n",
      "  Run 1: 0.0121\n",
      "nonoverlappingCNN_sigmoid -> overlappingCNN_tanh:\n",
      "  Run 1: 0.2521\n",
      "nonoverlappingCNN_relu -> overlappingCNN_sigmoid:\n",
      "  Run 1: 3.3666\n",
      "nonoverlappingCNN_relu -> overlappingCNN_relu:\n",
      "  Run 1: 0.0001\n",
      "nonoverlappingCNN_relu -> overlappingCNN_tanh:\n",
      "  Run 1: 3.6672\n",
      "nonoverlappingCNN_tanh -> overlappingCNN_sigmoid:\n",
      "  Run 1: 0.1919\n",
      "nonoverlappingCNN_tanh -> overlappingCNN_relu:\n",
      "  Run 1: 0.2112\n",
      "nonoverlappingCNN_tanh -> overlappingCNN_tanh:\n",
      "  Run 1: 0.0002\n"
     ]
    }
   ],
   "source": [
    "collect_all_losses(\"../experiment_output/Experiment2/experiments_exp2_l2_init1_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
