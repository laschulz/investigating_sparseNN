Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[ 2.59 -2.83  0.87]]]
layers.1.weight: [[[-1.38  1.29]]]
layers.2.weight: [[[ 0.86 -0.84]]]

================================================================================

nonoverlappingCNN_relu -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[-0.00473664 -0.2717026  -0.10739307 ... -0.17406993  0.04040781
  -0.03324324]
 [ 0.21511935 -0.27024096  0.02173191 ... -0.02559706 -0.0593335
   0.01090294]
 [ 0.01048817 -0.13664025 -0.026594   ...  0.11723302 -0.1490807
   0.19124562]
 ...
 [-0.11731025  0.20817278 -0.31339154 ... -0.11338664  0.11290919
   0.20219721]
 [-0.00684952 -0.03467426 -0.01933421 ...  0.4156818  -0.45954487
   0.14125498]
 [ 0.08366061  0.15318029 -0.16107854 ... -0.09914928  0.11221683
   0.10249609]]
layers.1.weight: [[-0.08638292  0.18126863 -0.5262264  ... -0.58681077 -0.01625445
   0.01322288]
 [ 0.01042544 -0.03108525 -0.16124846 ...  0.07948697 -0.59378487
   0.07231532]
 [ 0.10894603 -0.28924516  0.13643761 ... -0.07358797 -0.4115492
   0.23040739]
 ...
 [ 0.09456664  0.354778   -0.21534224 ... -0.18321942  0.18474506
   0.00928373]
 [ 0.0334042  -0.1759451  -0.3341704  ...  0.21370617 -0.12544467
  -0.23194607]
 [-0.41624287  0.2579237   0.210543   ... -0.011578    0.06589126
  -0.07131055]]
layers.2.weight: [[ 2.4421952   1.2276154   0.3664826  -1.3625652  -2.542737   -1.9617239
   0.28843796  0.8025717  -0.8802327  -1.613396    0.26467782  0.14756617
  -0.8071954   0.7155091   0.3679617   0.55689824 -0.41919133  0.3721756
   1.4294622   0.27510655 -1.7696569  -1.7309308  -1.3345596  -0.50879115
  -0.1849484  -0.47244316  0.7797062  -0.74127173 -2.169234   -0.5374451
  -0.2921164   1.7687806 ]]

Final Loss: 0.0121
Distance Metric: 40.9401
L1 norm: 5e-06
L2 norm: 0
Batch size: 32
Clipping: 0
Learning rate: 0.005
data size: 5120

================================================================================

nonoverlappingCNN_relu -> fcnn_decreasing_tanh

Student Model Parameters:
layers.0.weight: [[ 0.03508578 -0.09284467  0.3432426  ... -0.04906924  0.47123623
   0.14426823]
 [ 0.06461966  0.10242835  0.1374084  ...  0.38817644  0.2446884
  -0.32328057]
 [ 0.25918767  0.32297987 -0.6185605  ... -0.19180544  0.33109814
   0.31220272]
 ...
 [-0.35875934 -0.29425615 -0.64218265 ... -0.02017527  0.14162561
   0.39585483]
 [ 0.5621638   0.8387348  -0.24682659 ...  0.00190505 -0.66390795
   0.6250721 ]
 [ 0.3895393   0.16539645  0.32563427 ...  0.37878338  0.49219275
  -0.0269162 ]]
layers.1.weight: [[ 0.12667674  0.05872381 -0.0497196  ... -0.15424918 -0.05905263
   0.23614965]
 [-0.09001361 -0.08016438  0.10284232 ...  0.31779987 -0.22741713
   0.29231519]
 [-0.04435808 -0.11923646 -0.11016356 ...  0.1985498   0.05688908
   0.23177134]
 ...
 [ 0.01828634  0.10140425  0.21451883 ...  0.17702396 -0.0021303
  -0.28015506]
 [ 0.56177324  0.1462363  -0.10848093 ...  0.1263791   0.32825944
   0.16217525]
 [ 0.61643845 -0.3958495  -0.02979139 ...  0.4714987  -0.6267801
  -0.15635577]]
layers.2.weight: [[-0.627817   -0.49674135 -0.39460188  0.9611206   0.3395257  -0.504823
   0.62328523 -0.51144207  0.9660034  -0.8325368  -0.39424983  0.55322945
   0.3374898   0.5484628   1.9545089  -0.7635876  -0.5066938  -1.3843496
   0.76104754  1.1251938  -0.7845752   0.58165026  0.91370326  0.44230857
   0.86678225 -0.39932823 -0.7624297   0.6734221  -0.59708136 -0.6184827
   0.69293135  1.7979156 ]]

Final Loss: 3.4890
Distance Metric: 51.2142
L1 norm: 5e-06
L2 norm: 0
Batch size: 32
Clipping: 0
Learning rate: 0.005
data size: 5120

================================================================================

nonoverlappingCNN_relu -> fcnn_decreasing_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.02611003 -0.08520678 -0.03625049 ... -0.08960041  0.02871958
  -0.10984307]
 [-0.13389696  0.08835238 -0.12696292 ...  0.17486048 -0.00442886
   0.08468632]
 [-0.06023536  0.10210804 -0.16457695 ... -0.52272594  0.73148984
   0.06624562]
 ...
 [ 0.2941384  -0.1482861   0.07381897 ...  0.03850774 -0.03419216
   0.12193044]
 [-0.018529    0.25822124 -0.06593898 ...  0.13258383 -0.07051532
   0.17689651]
 [-0.16980493  0.13822605 -0.10021752 ... -0.13786437  0.15080284
   0.04808812]]
layers.1.weight: [[ 0.04795945  0.26176456  0.25042862 ...  0.16840394  0.11047991
  -0.22822626]
 [-0.06458912 -0.04035444  0.15234633 ...  0.08973081 -0.0470317
  -0.12187872]
 [-0.08301079  0.15044679 -0.03990299 ...  0.04415759  0.10408021
   0.11882844]
 ...
 [ 0.01908956 -0.0416269  -0.21075717 ...  0.04606169 -0.12161046
   0.12594001]
 [-0.15468189 -0.13454989 -0.09229317 ... -0.10838895  0.1493874
  -0.0826612 ]
 [ 0.06625331 -0.11831953 -0.04135106 ... -0.0903183   0.02937695
   0.08407494]]
layers.2.weight: [[ 4.9215531e+00  3.4960220e+00  1.8537383e+00 -4.2013283e+00
  -8.3602220e-01  2.9868219e+00  3.5110107e-01  3.5487652e+00
   2.4892101e+00  3.6161678e+00  1.1796179e+00 -1.4116846e+00
  -1.5511289e+00 -1.1079125e+00 -3.2971007e-01  3.0936809e+00
  -4.7088766e+00  1.4665093e+00  3.9185286e+00 -3.8932142e+00
   2.7280910e+00 -2.5702674e+00  4.5749182e-03 -4.6014778e-02
  -1.3796964e+00 -2.6931887e+00  3.0183582e+00  9.8997915e-01
  -9.2124671e-01 -3.2093873e+00 -2.3587742e+00  8.1911135e-01]]

Final Loss: 3.4161
Distance Metric: 53.3778
L1 norm: 5e-06
L2 norm: 0
Batch size: 32
Clipping: 0
Learning rate: 0.005
data size: 5120

================================================================================

nonoverlappingCNN_tanh -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[ 0.01450316  0.20646134  0.05736629 ... -0.23440665 -0.15569247
   0.06308187]
 [ 0.26533672 -0.14775303  0.20454672 ...  0.1591358   0.14809416
   0.05648707]
 [-0.0066101   0.13910139 -0.07240093 ...  0.02738467  0.08799067
   0.06219828]
 ...
 [-0.04678305  0.04932544 -0.01808219 ... -0.07602834  0.13928737
   0.02894169]
 [ 0.07368498  0.11530896  0.10002318 ...  0.01804488 -0.01280562
   0.1084782 ]
 [-0.16875137  0.09000747  0.10633419 ...  0.00263889  0.00405174
   0.06206473]]
layers.1.weight: [[-0.15998484 -0.16573586 -0.07921688 ... -0.3586298  -0.06120868
   0.00434798]
 [-0.41138315 -0.05327942  0.10376447 ...  0.3571795   0.17114519
   0.21918897]
 [-0.07534609  0.27202153  0.04482673 ... -0.31642708 -0.14068694
  -0.07604221]
 ...
 [-0.15590912  0.25480098  0.15889789 ... -0.08151836 -0.04384729
   0.39424   ]
 [ 0.17645305 -0.32523972  0.07075389 ...  0.10005945 -0.28334692
   0.21812701]
 [-0.05403133  0.03399354 -0.04701179 ... -0.14568342  0.40853167
  -0.03962674]]
layers.2.weight: [[ 2.4276793  -0.5831626  -0.99409574  0.9875136  -0.12371991 -0.3490832
  -1.5209284   0.26623404  0.93101054  0.4770285  -0.20537958 -1.3078257
   0.5648693   0.05361758  1.0950137   1.9782197   1.119907    0.00381309
   0.4544596  -0.42018217  0.37659323  1.961188    0.22504829  0.39784113
  -2.2085478  -1.1506739  -0.12011579  0.17434472 -0.4758036  -2.0750918
   0.8452795   0.3282017 ]]

Final Loss: 0.3730
Distance Metric: 37.9341
L1 norm: 5e-06
L2 norm: 0
Batch size: 32
Clipping: 0
Learning rate: 0.005
data size: 5120

================================================================================

nonoverlappingCNN_tanh -> fcnn_decreasing_tanh

Student Model Parameters:
layers.0.weight: [[-0.06163616 -0.09869886 -0.18410704 ...  0.19094655 -0.02896556
   0.01758066]
 [-0.01373923 -0.15936701 -0.10484612 ...  0.03972536 -0.27784267
  -0.01155388]
 [-0.04255981  0.12113787 -0.07750361 ...  0.03511212  0.10285499
   0.12318584]
 ...
 [-0.1350254   0.0874971  -0.14027236 ...  0.11829104  0.07152988
   0.22734082]
 [-0.00880061  0.0163282   0.02669722 ...  0.10896906 -0.05938705
  -0.01143166]
 [ 0.02801105  0.04078263 -0.09937729 ...  0.13837573  0.01071787
   0.15431286]]
layers.1.weight: [[ 0.19732575  0.23826759 -0.21283087 ...  0.08134317 -0.22191364
   0.0755901 ]
 [ 0.09625154  0.1814794  -0.09593116 ... -0.1798102  -0.17597963
   0.15071324]
 [-0.14815019 -0.02406293 -0.12074164 ... -0.24404348 -0.15126203
   0.15920794]
 ...
 [ 0.21734935  0.08561159  0.07517914 ... -0.1410247  -0.23908906
   0.11542884]
 [-0.1752178  -0.12883246 -0.14395258 ... -0.10309763 -0.00126692
   0.2569463 ]
 [-0.02384373  0.03713068  0.02110352 ...  0.04475053  0.09991523
   0.0648122 ]]
layers.2.weight: [[-0.27612123  0.00576333 -0.06567943 -0.01217708  0.00979295 -0.00299278
  -0.4787434   0.0028558   0.18517856 -0.00471798 -0.00357396 -0.02690896
  -0.00183035 -0.15304345 -0.01090813  0.00388969 -0.03826617 -0.00705775
  -0.3794245   0.01150831  0.01167728  0.01360554 -0.00182845  0.01426264
   0.00837341 -0.38622445 -0.001675    0.02366325  0.46195003  0.03067906
  -0.27718857  0.00380465]]

Final Loss: 0.0068
Distance Metric: 25.1487
L1 norm: 5e-06
L2 norm: 0
Batch size: 32
Clipping: 0
Learning rate: 0.005
data size: 5120

================================================================================

nonoverlappingCNN_tanh -> fcnn_decreasing_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.11125863 -0.07219377  0.07159305 ...  0.3995885  -0.47113135
   0.14431028]
 [-0.03048883 -0.19158016  0.1611817  ... -0.08761129 -0.06921417
   0.05948654]
 [ 0.32541323 -0.3562046   0.22540157 ... -0.0116512  -0.14388826
   0.06275111]
 ...
 [ 0.13501586  0.01736098  0.13820353 ...  0.27323747 -0.11639703
  -0.06910091]
 [-0.09222756  0.09244655  0.09686879 ... -0.05540888  0.11158135
  -0.01165401]
 [ 0.11321029 -0.28954518  0.08907759 ... -0.03910208  0.07714619
   0.13806485]]
layers.1.weight: [[ 0.17683665  0.03124167  0.08643418 ...  0.07179667  0.01454346
   0.07585149]
 [-0.07868491 -0.07920678  0.00699369 ...  0.10427218  0.06563579
   0.09780191]
 [-0.08161984 -0.13199782  0.04750828 ...  0.02254715  0.0471777
   0.00878501]
 ...
 [ 0.14620885 -0.01584936 -0.1103722  ...  0.09218979 -0.0760242
  -0.01669102]
 [ 0.29663327  0.1290664   0.07238212 ...  0.31890655 -0.16410318
   0.18900946]
 [ 0.09503531  0.03259735 -0.01361716 ...  0.05089181  0.13825284
   0.11745534]]
layers.2.weight: [[-2.7591047  -1.017709    0.99033177 -2.3087986   2.321737   -6.3283896
   1.1470339   1.5212404  -1.0120845  -0.88738346  0.68486243 -1.365154
  -1.2402525  -2.8019862   0.50485224  0.63408625 -2.5285141  -2.129839
  -1.2567967   1.1366838  -0.19555269  1.3464786   0.8780354  -0.35252383
  -1.7352427   1.1235098  -1.9368778  -2.3721678   0.25353602 -2.418723
  -2.9416986   0.55844504]]

Final Loss: 0.1862
Distance Metric: 51.4098
L1 norm: 5e-06
L2 norm: 0
Batch size: 32
Clipping: 0
Learning rate: 0.005
data size: 5120

================================================================================

nonoverlappingCNN_sigmoid -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[-0.00923057  0.04792546  0.1651832  ...  0.00643398 -0.05632642
   0.11709981]
 [-0.12827797 -0.01904041  0.06524599 ... -0.10884652 -0.05227997
   0.11000636]
 [ 0.05883296  0.22681588 -0.08225045 ... -0.13456286  0.0601528
  -0.14272858]
 ...
 [ 0.1119744  -0.12568285  0.07638356 ... -0.20273039 -0.33903635
  -0.10333793]
 [ 0.05221689 -0.11475298  0.12902112 ... -0.03802505 -0.19159676
  -0.05128922]
 [ 0.1831882   0.04503202 -0.16139978 ...  0.26525936  0.45892084
   0.0010215 ]]
layers.1.weight: [[ 0.19477896  0.23820396  0.3808596  ... -0.17015904 -0.23910685
  -0.01494098]
 [-0.04750022  0.13142984  0.2849271  ... -0.13017279 -0.40233663
  -0.14766231]
 [-0.0771772   0.46035394 -0.01526624 ...  0.1492412   0.45607302
   0.4381952 ]
 ...
 [ 0.2347462   0.03357117  0.20137136 ...  0.54488283 -0.4837015
  -0.10015874]
 [-0.11067391  0.173805    0.24308892 ...  0.41758838  0.11968544
  -0.06851967]
 [ 0.22308129  0.18593448 -0.56838745 ...  0.02442204  0.22390103
   0.14218552]]
layers.2.weight: [[ 1.1999074  -0.05794521 -2.6471949  -0.300779   -2.5757322   1.4105461
   2.912891   -1.057817   -0.8141895  -0.14482652 -0.23865892 -0.28637326
   0.14678863  0.9208545  -1.5871029   2.035851    0.59225166 -1.0715123
  -2.2349896  -0.46220714  0.16248755  1.5767117   0.23699453 -0.41810307
  -0.7599523   0.80706984  1.266547   -0.03900409 -1.6059327  -0.59992737
  -0.25202614 -1.5840032 ]]

Final Loss: 0.2659
Distance Metric: 41.6769
L1 norm: 5e-06
L2 norm: 0
Batch size: 32
Clipping: 0
Learning rate: 0.005
data size: 5120

================================================================================

nonoverlappingCNN_sigmoid -> fcnn_decreasing_tanh

Student Model Parameters:
layers.0.weight: [[ 0.36742392  0.24753612 -0.70669484 ...  0.21904932  0.19480482
  -0.15010409]
 [ 1.0406433   0.4226552  -0.00518886 ... -0.7741754   0.38045943
  -0.27650023]
 [ 0.5617468  -0.2742858  -0.491893   ...  0.8116743  -0.21706723
   0.22357273]
 ...
 [-0.67772806 -0.39150932  0.3674269  ...  0.37511745  0.9060731
   0.44529286]
 [-0.13789544 -0.38199213 -0.4017072  ... -0.63738793 -0.7038932
  -0.10588372]
 [-0.31267148 -0.17761421 -0.0668842  ...  0.4319508  -0.0198834
   0.44208527]]
layers.1.weight: [[-0.4213909  -0.26339772  0.11392108 ...  0.00863514  0.01874003
   0.2581225 ]
 [-0.40728146  0.01917025 -0.01402157 ... -0.04718939  0.2608299
   0.06271539]
 [ 0.08087561 -0.21025544  0.16432759 ...  0.07411426  0.13674514
  -0.11447221]
 ...
 [ 0.40840805 -0.16089852 -0.04210822 ... -0.05494748 -0.02031839
  -0.06731434]
 [-0.13922183  0.06973629 -0.01567363 ...  0.3552527   0.45224154
   0.35847846]
 [-0.26382858 -0.21022832 -0.06983881 ...  0.2675025  -0.06282847
   0.08639291]]
layers.2.weight: [[-0.71283853 -0.35593677 -0.55914557  0.5513787  -0.7636017   0.2930929
  -0.440947    0.6825354   0.6672084   0.34115213 -0.60354596  0.56588256
  -0.55372447  0.5196781   0.64596194 -0.5321995  -0.73761386  0.5792885
  -0.45384642  0.5460949   0.6198018   0.6231582   0.5256678  -0.5307807
  -0.531144   -0.39034384 -0.5952583  -0.5853827  -0.51755387  0.5203477
  -0.5689072  -0.52836865]]

Final Loss: 0.0119
Distance Metric: 46.8304
L1 norm: 5e-06
L2 norm: 0
Batch size: 32
Clipping: 0
Learning rate: 0.005
data size: 5120

================================================================================

nonoverlappingCNN_sigmoid -> fcnn_decreasing_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.13686448 -0.04389551  0.13635479 ... -0.06002733 -0.03214995
  -0.14854673]
 [ 0.02388135 -0.11904533 -0.09532536 ...  0.08255963 -0.01321729
  -0.06553376]
 [-0.04733554 -0.01775401  0.06509677 ...  0.1120099   0.07644065
   0.05061733]
 ...
 [ 0.10095438  0.15418848  0.04968195 ... -0.13597164 -0.0612677
   0.07417698]
 [ 0.07065377 -0.0160478  -0.10182875 ...  0.15493023 -0.08076434
  -0.12326005]
 [ 0.12588544  0.02238104 -0.0464985  ...  0.1550849  -0.1559369
  -0.05425893]]
layers.1.weight: [[ 0.07903814  0.01442934  0.05563298 ... -0.07364992 -0.00655059
   0.06871029]
 [-0.06085199  0.05901024 -0.01336505 ...  0.10126078 -0.0235194
   0.02820298]
 [-0.01757244 -0.07402772 -0.01503807 ...  0.02610684  0.07437831
   0.11041049]
 ...
 [ 0.06797849 -0.05340341 -0.07049865 ... -0.00578061 -0.09490288
   0.05876274]
 [ 0.00030343  0.00212437 -0.1105321  ... -0.13628407  0.0277396
  -0.14238009]
 [-0.13258803 -0.05067449 -0.128483   ...  0.02665546 -0.08888759
   0.02828858]]
layers.2.weight: [[-0.28913572 -0.12427095 -0.20135997  0.12420315 -0.09654664  0.15367898
  -0.31032854  0.07352199  0.18407719 -0.02610209  0.50275165 -0.19015254
   0.23311043  0.30851382 -0.12729427  0.21489146 -0.10263184  0.19732697
   0.13148548 -0.53161967  0.33118787 -0.07487309 -0.1926563   0.3311114
  -0.51098126  0.52064276  0.28645083  0.08395161 -0.07504349  0.43299833
   0.11185174  0.00466303]]

Final Loss: 0.0046
Distance Metric: 19.5549
L1 norm: 5e-06
L2 norm: 0
Batch size: 32
Clipping: 0
Learning rate: 0.005
data size: 5120

================================================================================

