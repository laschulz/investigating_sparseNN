Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[ 0.5784602  -0.05761588 -0.12829268]]]
layers.1.weight: [[[ 0.55400753 -0.6922507 ]]]
layers.2.weight: [[[0.5927121 0.7333151]]]

================================================================================

baselineCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.01351003 -0.00136346 -0.00302591 ... -0.02093587  0.00211217
   0.00467229]
 [-0.02193431  0.00220648  0.00492007 ...  0.0339791  -0.00343977
  -0.00759093]
 [-0.01046912  0.00105166  0.00234919 ...  0.01622358 -0.00163682
  -0.00361837]
 ...
 [ 0.01130516 -0.00113346 -0.00253235 ... -0.01750973  0.00176844
   0.00390898]
 [ 0.01991466 -0.00199954 -0.00446315 ... -0.03085494  0.0031223
   0.00689004]
 [ 0.02921034 -0.00293743 -0.00655197 ... -0.0452646   0.00457722
   0.01010935]]
layers.1.weight: [[ 0.01092918 -0.01785786 -0.00854678 ...  0.00913169  0.0161285
   0.02369885]
 [ 0.00685486 -0.01115525 -0.00532394 ...  0.0057359   0.01010872
   0.01484946]
 [-0.00727109  0.01183212  0.00564348 ... -0.00607292 -0.01071708
  -0.01574435]
 ...
 [ 0.00550563 -0.00893257 -0.00426395 ...  0.00460071  0.00810815
   0.0119079 ]
 [-0.00614735  0.00999347  0.00476589 ... -0.00514022 -0.00906813
  -0.01331721]
 [-0.00226953  0.00366552  0.00174669 ... -0.0018998  -0.0033439
  -0.00490886]]
layers.2.weight: [[ 0.2184652   0.13669246 -0.14464355  0.19557074  0.16753978  0.02873315
  -0.04537513 -0.07501182  0.11682253  0.12800771  0.06261312 -0.0668084
   0.20078239  0.2043495   0.08068805  0.17056394 -0.03072306 -0.10769915
  -0.12090341  0.00459565 -0.02962323 -0.0256075   0.13613425  0.03806154
   0.10592005 -0.03858617 -0.09194633 -0.14007752  0.24983095  0.10960951
  -0.12226714 -0.04486417]]

Final Loss: 0.0000
Distance Metric: 3.9914
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 1107

================================================================================

baselineCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[ 0.          0.          0.00010624 ...  0.          0.00017655
   0.        ]
 [ 0.00011907  0.          0.00010747 ... -0.00010276  0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ... -0.00010376 -0.0001719
  -0.00016297]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.2.weight: [[-0.0003384   0.         -0.0008508   0.00011646  0.00010193  0.
   0.00034549  0.         -0.00042145  0.          0.00042375 -0.00025891
   0.00018149 -0.00018573  0.          0.         -0.00044086 -0.00070948
   0.00029595  0.00036311 -0.00028196 -0.00041439  0.          0.00046777
  -0.00028625 -0.00015345 -0.00018423 -0.00012502  0.          0.
  -0.00019732 -0.00050757]]

Final Loss: 0.1474
Distance Metric: 2.8303
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 894

================================================================================

baselineCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 6.4902075e-02 -7.2419852e-02  7.2420961e-01 ... -2.3754446e-01
   7.6780334e-02  3.3981192e-01]
 [-3.2988217e-04  0.0000000e+00 -2.6967897e-04 ... -3.2300394e-04
   0.0000000e+00 -1.8450279e-04]
 [-1.0940406e-03 -4.5064811e-04 -9.7962096e-04 ... -1.3533648e-03
   1.1884299e-04 -5.5713381e-04]
 ...
 [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00
   0.0000000e+00  0.0000000e+00]
 [ 4.2072672e-04  2.0550775e-04  4.0008425e-04 ...  5.6599505e-04
   0.0000000e+00  2.0025921e-04]
 [-5.1610573e-04 -2.5395936e-04 -5.2645069e-04 ... -6.9585786e-04
   0.0000000e+00 -2.9535865e-04]]
layers.1.weight: [[ 4.0371556e-02 -5.0894904e-04 -4.5252676e-04 ...  3.8629392e-04
  -4.4645887e-04  0.0000000e+00]
 [-1.1575756e-01 -3.9096846e-04 -3.5613589e-04 ... -1.1272047e-04
   7.5307261e-04 -2.5807950e-04]
 [-6.2892474e-02  0.0000000e+00 -5.4877339e-04 ...  1.6907815e-04
   6.1090058e-04  5.6522025e-04]
 ...
 [-1.1071865e-01 -3.6695896e-04 -9.3461585e-04 ... -5.3597643e-04
  -1.6988775e-04 -8.1784249e-04]
 [-1.9862246e-02 -5.7653378e-04  2.0030077e-04 ... -5.4205424e-04
  -2.3694092e-04 -5.6859391e-04]
 [ 2.5662050e-02  7.3619047e-04  2.1168946e-04 ... -5.9983839e-04
  -6.2579627e-04 -4.7825859e-04]]
layers.2.weight: [[ 0.01382491 -0.04273603 -0.02183365  0.02826317  0.00870025 -0.01950881
   0.0048688  -0.00835667  0.00229783 -0.02115203  0.02454409 -0.01067797
   0.01534054  0.00199293  0.02270786 -0.02550983  0.00097048  0.00050056
  -0.00395068  0.03873252  0.02017498  0.00345735 -0.01587429 -0.00345105
   0.01491172  0.0091977  -0.00414376  0.02113706  0.01236086 -0.04054796
  -0.00675287  0.00874496]]

Final Loss: 0.2534
Distance Metric: 6.3147
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 601

================================================================================

baselineCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0.]]

Final Loss: 0.0000
Distance Metric: 6.2197
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 5315

================================================================================

baselineCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.01979524  0.00675011 -0.02549703 ...  0.00703102  0.00164844
  -0.01458289]
 [ 0.01949011  0.00666786 -0.02509868 ...  0.00650837  0.00152242
  -0.0138545 ]
 [-0.00015411  0.00063793  0.0003602  ... -0.00572826 -0.00238244
   0.00540086]
 ...
 [-0.0005772   0.00068362  0.00090834 ... -0.0021934  -0.00132891
   0.0005842 ]
 [-0.00663374 -0.00138427  0.00898425 ...  0.00406491  0.0005329
  -0.00532336]
 [-0.00051721  0.00069647  0.00082692 ... -0.00336704 -0.00167046
   0.00212531]]
layers.1.weight: [[ 1.8196855e-02  1.7964408e-02  1.7125420e-03 ...  1.3635213e-04
  -1.0981399e-02  5.8816676e-04]
 [ 2.1979952e-02  2.1691630e-02  1.8398964e-03 ...  0.0000000e+00
  -1.3049971e-02  5.6793640e-04]
 [-1.2801287e-02 -1.2645251e-02 -1.5379861e-03 ... -3.8848768e-04
   7.4472423e-03 -7.1735005e-04]
 ...
 [ 1.7638871e-02  1.7413329e-02  1.6879048e-03 ...  1.4909996e-04
  -1.0653523e-02  5.9001858e-04]
 [ 1.7503690e-02  1.7280839e-02  1.6816893e-03 ...  1.5254787e-04
  -1.0573641e-02  5.9036410e-04]
 [ 1.4702795e-01  1.4586280e-01  3.5600111e-02 ...  1.4502328e-02
  -9.6108459e-02  2.0325746e-02]]
layers.2.weight: [[ 0.44117987  0.55890316 -0.28439692 -0.11379141 -0.28993863 -0.56274927
   0.37771323  2.1696875  -0.2467135  -5.501142   -0.06000801  0.3335151
  -0.5404727  -0.12193632 -0.23516722 -0.75113165 -0.5251605  -0.33994022
   0.29564095  0.4901821  -0.12487064 -0.25969383 -0.24502568  0.44692582
  -0.22834638 -0.6080098  -5.850592   -0.22763324  0.64906937  0.42508346
   0.42121962  1.0389559 ]]

Final Loss: 0.3506
Distance Metric: 28.5162
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 1431

================================================================================

baselineCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.         -0.00036762  0.         -0.00023369  0.          0.
   0.          0.          0.00010739  0.          0.00020292  0.00025912
   0.         -0.00010568  0.00015766 -0.00020111  0.00011073  0.
   0.00014055  0.          0.00025316  0.          0.          0.
   0.00036628 -0.00021367 -0.00011304 -0.00022451  0.          0.00035929
  -0.00013849  0.00025791]]

Final Loss: 0.3644
Distance Metric: 3.7847
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 965

================================================================================

baselineCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.00039519  0.          0.00018557 ... -0.00017954  0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.00049902  0.          0.00023454 ... -0.00020726  0.
   0.        ]
 ...
 [-0.00024025  0.          0.00011298 ...  0.          0.
   0.        ]
 [-0.00032267  0.          0.00015135 ... -0.00016091  0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[-0.00045749  0.         -0.00052798 ... -0.00024028 -0.00041015
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.2.weight: [[ 0.915124   -0.04309598 -0.07630862  0.07771713  0.02004994  0.03179438
  -0.03376108  0.01207194  0.0018487   0.07328099 -0.03843933 -0.04169064
  -0.07838621 -0.11009202  0.04208668  0.00712194  0.03754595  0.05047289
   0.07484455  0.03436213  0.06538979 -0.03524694 -0.02491151 -0.07222261
   0.08468872 -0.05851065  1.018761   -0.07371008 -0.01258109  0.11180077
   0.00322671  0.0183718 ]]

Final Loss: 0.0001
Distance Metric: 3.1762
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 6032

================================================================================

