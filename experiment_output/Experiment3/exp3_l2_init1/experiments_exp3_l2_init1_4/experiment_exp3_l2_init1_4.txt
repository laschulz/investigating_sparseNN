Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.3301512  -0.3301196   0.19602978]]]
layers.1.weight: [[[-0.2781349  1.0295225]]]
layers.2.weight: [[[ 0.20006615 -0.35124314]]]

================================================================================

baselineCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.00362293 -0.00331839  0.00104498 ... -0.01994259 -0.02063347
   0.01283863]
 [ 0.00065826 -0.000336    0.         ...  0.0023874   0.0022793
  -0.00045345]
 [ 0.00012091  0.00012733  0.00016756 ...  0.00452176  0.00427612
  -0.00194433]
 ...
 [-0.00308693 -0.00202838  0.00169603 ... -0.01744229 -0.01667359
   0.01073618]
 [ 0.00191863  0.00192614 -0.00103615 ...  0.01602948  0.0163125
  -0.01009193]
 [ 0.00043359  0.001017   -0.00078935 ...  0.00297167  0.00370497
  -0.00193279]]
layers.1.weight: [[ 0.00518473 -0.00108257 -0.00153983 ...  0.00420019 -0.00416988
  -0.00080334]
 [-0.0067095   0.00039554  0.00132654 ... -0.00581251  0.00522087
   0.00141205]
 [ 0.00971796 -0.00152317 -0.00199849 ...  0.00826881 -0.00768254
  -0.00154001]
 ...
 [-0.00546924  0.          0.00073193 ... -0.0041475   0.0039735
   0.00047379]
 [-0.00956713  0.00113723  0.00216944 ... -0.00726902  0.00633753
   0.00145683]
 [-0.0076587   0.00015907  0.00226393 ... -0.00727083  0.0065907
   0.00156579]]
layers.2.weight: [[-0.04138577  0.04151708 -0.06724162 -0.04575932 -0.03943796 -0.0242347
  -0.01232051  0.05121543 -0.02755866  0.05603597 -0.06717514  0.0202026
  -0.05299141 -0.08610763  0.00687256  0.00295562 -0.01335532 -0.08395883
   0.00705342  0.05177365  0.00139678  0.02992094 -0.03549565  0.04593628
   0.00960014 -0.00226632 -0.09443358  0.04075824  0.03456644  0.03282557
   0.06035542  0.05578407]]

Final Loss: 0.0000
Distance Metric: 2.5614
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 4
stopped after epoch: 571

================================================================================

baselineCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[ 0.00014339  0.          0.         ...  0.          0.
   0.        ]
 [-0.00012622  0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ... -0.00011177  0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.         -0.00010473 ...  0.          0.
  -0.00012559]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.2.weight: [[ 0.00026309  0.         -0.00028735  0.          0.          0.00012577
   0.00079764 -0.00011293  0.         -0.00037975  0.         -0.00022305
   0.         -0.00024829 -0.00038941  0.         -0.00059417 -0.00053999
  -0.00018292  0.          0.00028922 -0.00044219  0.          0.00032701
   0.          0.          0.0003363  -0.00021122 -0.00029129  0.00044455
  -0.00015807  0.        ]]

Final Loss: 0.0853
Distance Metric: 2.6873
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 4
stopped after epoch: 900

================================================================================

baselineCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.00138665 -0.00381868  0.00200011 ...  0.02224874  0.04089458
  -0.0584    ]
 [-0.01199507 -0.01036389  0.0244127  ... -0.04946213 -0.09180457
   0.1299375 ]
 [-0.04054114 -0.0824352   0.12321472 ... -0.00291954 -0.00722453
   0.01252572]
 ...
 [-0.0232169  -0.04788184  0.07119629 ...  0.00112639  0.00099975
  -0.00013375]
 [-0.03213603 -0.0680519   0.10058082 ...  0.00549644  0.00836651
  -0.01021727]
 [-0.02190343 -0.0500998   0.07248238 ...  0.01430953  0.02485865
  -0.034208  ]]
layers.1.weight: [[ 0.01185314 -0.02256144  0.02356351 ...  0.0147727   0.02359171
   0.02271156]
 [ 0.01259965 -0.02400712  0.02446798 ...  0.01537795  0.02459499
   0.02378381]
 [-0.01886411  0.03638977 -0.03069636 ... -0.01967862 -0.03187983
  -0.03194819]
 ...
 [-0.00867952  0.01631344 -0.01910726 ... -0.01187543 -0.01880206
  -0.01774544]
 [-0.01424823  0.02709118 -0.02643724 ... -0.01671675 -0.02676932
  -0.02610669]
 [-0.0166798   0.03195137 -0.02882922 ... -0.01836406 -0.02958208
  -0.02927202]]
layers.2.weight: [[-0.7362495  -0.77121     1.0480669  -0.8362741  -3.918585    0.70184493
  -0.7531929  -0.093342   -0.8879188   0.06892751 -0.83793926 -0.6910109
   0.92281353 -0.7386209  -0.9149917   1.0468574   1.0134726  -0.54391307
  -0.87061155  1.0132176   1.0258425   0.8982107  -0.66799164  0.06467626
   0.4846965   1.0438898  -0.33959237 -0.82572573  0.9060247   0.5843731
   0.8580981   0.96134657]]

Final Loss: 0.0038
Distance Metric: 21.4860
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 4
stopped after epoch: 1568

================================================================================

baselineCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.0000000e+00  6.5546273e-04  5.0585219e-03 ... -7.2647440e-03
  -4.1749427e-04  0.0000000e+00]
 [-3.5695485e-03 -4.4225305e-01  2.4874598e-02 ... -3.2581635e-02
   2.7312040e-01 -1.9678985e-01]
 [ 0.0000000e+00  3.7845137e-04  1.8018169e-03 ... -2.7411515e-03
  -2.0104011e-04  1.0114962e-04]
 ...
 [ 0.0000000e+00 -1.7510392e-04 -6.9092494e-04 ...  1.1937809e-03
   1.4295110e-04  0.0000000e+00]
 [ 0.0000000e+00  2.5964776e-04  1.3348658e-03 ... -2.1227524e-03
  -1.7973196e-04  0.0000000e+00]
 [ 0.0000000e+00 -3.8631327e-04 -1.9142255e-03 ...  2.8197479e-03
   1.5383361e-04  0.0000000e+00]]
layers.1.weight: [[ 1.1490197e-03  4.2646352e-02  3.8920676e-03 ...  2.7411981e-03
   2.0766952e-03 -4.1678529e-03]
 [ 2.3256626e-03 -3.6015436e-03 -8.5321144e-04 ... -2.1102144e-03
  -7.4675813e-04 -3.0041786e-03]
 [-3.4852067e-03 -2.5711255e-02 -2.7963989e-03 ... -6.2482158e-04
  -6.6736125e-04  3.1369976e-03]
 ...
 [-2.4791083e-03 -1.6195815e-02  1.2533429e-04 ...  0.0000000e+00
  -2.1208657e-03  1.4611961e-03]
 [-6.5999492e-03 -1.3741615e-01  1.1587846e-03 ...  3.6065995e-03
  -9.1559486e-04 -9.5142866e-04]
 [-3.7231261e-03 -8.8080317e-02 -7.0944894e-04 ...  3.8720522e-04
  -1.5608146e-04  3.7923786e-03]]
layers.2.weight: [[ 0.01356467 -0.00111854 -0.00807855 -0.00731271  0.02661165  0.0020687
   0.01128848  0.02102335 -0.02230141 -0.0066359  -0.00725182 -0.00326922
   0.00191254 -0.00074312  0.00087588 -0.00821922  0.01047787  0.04386582
  -0.01511037  0.01872179  0.01161121 -0.03845591 -0.00077206  0.00375104
   0.03476592  0.01751913  0.01508011 -0.05344915  0.02566181 -0.00524476
  -0.04499743 -0.02823331]]

Final Loss: 0.4265
Distance Metric: 8.9461
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 4
stopped after epoch: 430

================================================================================

baselineCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0.]]

Final Loss: 0.0000
Distance Metric: 5.7481
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 4
stopped after epoch: 5316

================================================================================

baselineCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 1.3492000e-03  0.0000000e+00  5.5588043e-04 ...  4.4348549e-02
  -1.9459900e-02  2.8320594e-02]
 [-4.9946498e-04  0.0000000e+00 -3.3768572e-04 ...  3.7336025e-01
  -1.6660698e-01  2.3801850e-01]
 [-2.1849349e-04  0.0000000e+00  0.0000000e+00 ... -1.1539958e-01
   5.1388860e-02 -7.3564626e-02]
 ...
 [-4.9147377e-04  0.0000000e+00 -3.2403093e-04 ...  3.3483046e-01
  -1.4941578e-01  2.1344092e-01]
 [ 1.2454220e-04  0.0000000e+00  1.6454204e-04 ... -3.4015658e-01
   1.5169129e-01 -2.1685249e-01]
 [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ... -1.5780330e-02
   7.0262738e-03 -1.0059785e-02]]
layers.1.weight: [[-0.00050545  0.          0.         ...  0.          0.
   0.        ]
 [-0.00395007  0.00130754  0.00062317 ...  0.00141351  0.
   0.00014597]
 [ 0.00280717 -0.00090167 -0.00044071 ... -0.00097911  0.
   0.        ]
 ...
 [ 0.00313997 -0.00103325 -0.00050463 ... -0.00111933  0.
  -0.00012199]
 [ 0.00272895 -0.00087159 -0.00042596 ... -0.00094695  0.
   0.        ]
 [-0.00021176  0.          0.         ...  0.          0.
   0.        ]]
layers.2.weight: [[-0.02224149 -0.20537125  0.14604309  0.1153477  -0.42461896 -0.13279103
  -4.3565755   0.08265445  0.12054449  0.01437858  0.05019552 -0.11225981
  -0.03021379  0.10039626  0.06064379 -0.04690447 -4.26704     0.13962302
   0.11336493  0.13316774 -0.01352107 -0.45072657  0.16053146  0.11423796
  -0.21418072 -0.02703105 -0.32296792 -0.03841996  0.09947975  0.16400939
   0.14183661 -0.00775499]]

Final Loss: 0.0830
Distance Metric: 19.7211
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 4
stopped after epoch: 2072

================================================================================

baselineCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.         0.         0.        ...  0.         0.         0.       ]
 [ 0.         0.         0.        ...  0.         0.         0.       ]
 [ 0.         0.         0.        ...  0.         0.         0.       ]
 ...
 [ 0.         0.         0.        ... -0.0001111  0.         0.       ]
 [ 0.         0.         0.        ...  0.         0.         0.       ]
 [ 0.         0.         0.        ...  0.         0.         0.       ]]
layers.1.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.         -0.00014637 ...  0.          0.
   0.        ]
 [ 0.         -0.00012681  0.         ...  0.          0.
  -0.00010849]
 ...
 [ 0.          0.         -0.00010445 ...  0.          0.
   0.        ]
 [ 0.          0.00019767  0.         ...  0.          0.
  -0.00012453]
 [ 0.          0.          0.         ... -0.0001063   0.
   0.        ]]
layers.2.weight: [[ 0.          0.0003534   0.00012528  0.00026093  0.00021598  0.00027515
  -0.00038377  0.00021515  0.         -0.00044214 -0.00019473 -0.00042129
   0.00077903 -0.00023539  0.0003885   0.00073781  0.         -0.00019717
   0.0005346   0.00012559  0.0007588   0.0001253  -0.00034062 -0.00079455
   0.00053936  0.          0.00027855  0.00010206 -0.00029062 -0.0003052
  -0.00037944  0.00044671]]

Final Loss: 0.4043
Distance Metric: 4.1313
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 4
stopped after epoch: 865

================================================================================

baselineCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.00252771 -0.00286882 -0.00010496 ... -0.04212761 -0.05106513
  -0.00210599]
 [-0.00012225 -0.00012579  0.         ...  0.00833875  0.01003913
   0.00041302]
 [ 0.00027241  0.00028969  0.         ... -0.00243859 -0.00291119
  -0.00012349]
 ...
 [ 0.00032529  0.00034799  0.         ...  0.00131826  0.0016242
   0.        ]
 [ 0.0010933   0.00120753  0.         ...  0.02123509  0.02571029
   0.00104556]
 [ 0.00228108  0.00283846  0.         ...  0.06968567  0.08413134
   0.0035641 ]]
layers.1.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.00024833  0.          0.         ...  0.          0.00012842
   0.0001487 ]
 [-0.00043575 -0.00364511  0.00272791 ...  0.00174685 -0.00010152
  -0.00315182]
 ...
 [ 0.00036451  0.          0.         ...  0.         -0.00018852
  -0.00021658]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.00119862  0.00016793 -0.00024083 ... -0.00024592 -0.00062073
  -0.00055423]]
layers.2.weight: [[-0.00773236  0.02287681 -0.38274097  0.11814925 -1.207635    0.12581769
   0.00384455  0.02097498 -0.01743985  0.10229947 -0.36512116  0.05753984
   0.06610186 -0.00949898  0.04344531 -0.00139864  0.06647776  0.00690458
  -0.03598453 -0.01807449 -0.01920624 -0.00121325  0.02837904 -0.01356898
   0.12205717 -0.03338479 -0.10680476  1.1225063   0.08571166 -0.03367644
   0.00331756 -0.11948201]]

Final Loss: 0.0002
Distance Metric: 6.5043
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 4
stopped after epoch: 2183

================================================================================

baselineCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-0.00011162  0.          0.         ...  0.          0.00015746
   0.00013821]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.         -0.00015261
   0.        ]
 ...
 [-0.0002527   0.          0.         ...  0.00027701  0.00030619
   0.00016546]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[ 0.          0.00012642  0.         ...  0.00011566  0.
  -0.00014929]
 [ 0.          0.000151    0.         ...  0.          0.
   0.        ]
 [ 0.00012569  0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.00023275 ...  0.          0.
  -0.00020474]
 [ 0.00010064 -0.00019032  0.         ...  0.          0.
   0.00014528]
 [ 0.0001025   0.          0.         ... -0.00010494  0.
   0.        ]]
layers.2.weight: [[-0.00042458  0.         -0.00021729  0.00046995 -0.00037041 -0.00018282
  -0.00020211 -0.00027741 -0.00070879 -0.00037246  0.00016096  0.
   0.00015997  0.          0.00047099  0.00022429  0.00048842 -0.00060574
  -0.00094279  0.00010098  0.0003779  -0.00013995  0.00021299  0.
  -0.00020216 -0.00052643  0.00015685 -0.00064202  0.00031291  0.
   0.00032387 -0.00055081]]

Final Loss: 4.9022
Distance Metric: 7.0350
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 4
stopped after epoch: 849

================================================================================

