Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.6643082   0.04732776 -0.43385768]]]
layers.1.weight: [[[-0.5221824  -0.55525833]]]
layers.2.weight: [[[ 1.1406595 -0.6489098]]]

================================================================================

baselineCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.02263471  0.00161408 -0.01474653 ...  0.01373184 -0.00093463
   0.0089332 ]
 [-0.01024911  0.00073116 -0.00667746 ...  0.00622011 -0.00042297
   0.00404725]
 [-0.02111986  0.00150795 -0.01376167 ...  0.01281248 -0.00087432
   0.00833574]
 ...
 [ 0.03374625 -0.00240809  0.02198707 ... -0.02046637  0.00139396
  -0.01331521]
 [ 0.01140521 -0.00081237  0.00743122 ... -0.00692007  0.0004719
  -0.00450276]
 [ 0.00108435  0.          0.00070658 ... -0.00065767  0.
  -0.0004284 ]]
layers.1.weight: [[ 0.01121809  0.0050964   0.01046837 ... -0.01665197 -0.00560319
  -0.00050363]
 [ 0.00081465  0.00036544  0.00075895 ... -0.0012326  -0.00042108
   0.        ]
 [-0.00222025 -0.00099981 -0.00206973 ...  0.00333058  0.00113061
   0.00011595]
 ...
 [-0.01097098 -0.00498538 -0.01023928 ...  0.01628442  0.00547743
   0.00049128]
 [ 0.00681656  0.00308625  0.00636006 ... -0.01017232 -0.00343651
  -0.00032831]
 [-0.00049391 -0.0002238  -0.00046141 ...  0.00073873  0.00025094
   0.        ]]
layers.2.weight: [[-0.20421591 -0.01481558  0.0408872  -0.14439268  0.04029689 -0.1896573
   0.14484285 -0.19042008  0.15698528 -0.09196643  0.17538454  0.212945
  -0.14840174  0.16653693 -0.16776864 -0.08983544  0.19812106 -0.06716809
  -0.12733354  0.07865843  0.02199609  0.27967954 -0.21069908  0.19041552
  -0.10221561  0.00358654  0.19323958  0.03799724  0.07853381  0.20010106
  -0.12439138  0.00923235]]

Final Loss: 0.0000
Distance Metric: 4.7680
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 1229

================================================================================

baselineCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.         -0.0002921   0.
   0.00014964  0.          0.          0.00011275  0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.00011416  0.00028323  0.00017717  0.00022518  0.
   0.00022076  0.        ]]

Final Loss: 0.0944
Distance Metric: 2.4127
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 1006

================================================================================

baselineCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.00649507 -0.00352521  0.00170255 ... -0.01133575  0.01034751
   0.00370278]
 [ 0.00296459  0.00260995 -0.00069572 ...  0.00726525 -0.00649862
  -0.00173126]
 [-0.00235921 -0.00178955  0.00167374 ... -0.00602965  0.00474719
   0.00068866]
 ...
 [ 0.00081046  0.00036426  0.00037026 ...  0.00180354 -0.00181837
  -0.00083515]
 [ 0.          0.          0.         ... -0.00099025  0.
   0.00029339]
 [ 0.00496997  0.00391408 -0.00093855 ...  0.00979517 -0.00904289
  -0.00308712]]
layers.1.weight: [[ 0.00419197 -0.00568444 -0.00031797 ... -0.00320042  0.
  -0.00347069]
 [-0.00020377  0.00090096 -0.00098195 ...  0.00157497  0.0028523
  -0.00034299]
 [ 0.00557616  0.          0.00419314 ... -0.00298996  0.00039536
  -0.00317127]
 ...
 [-0.00179269  0.00234304 -0.00123795 ... -0.00133797  0.00137335
  -0.00285552]
 [ 0.0040961  -0.00321255  0.00341593 ...  0.0006552   0.00081621
  -0.00205831]
 [ 0.0007328   0.00484432 -0.00290179 ...  0.00161973  0.00322996
   0.00092499]]
layers.2.weight: [[ 0.0256602   0.01251784  0.0326518  -0.03111859  0.00242896 -0.01136789
   0.00159387  0.03813764 -0.01393201  0.04164825 -0.01827164  0.01619079
  -0.02403075 -0.00642052  0.01745247 -0.02144421 -0.01114203  0.02537349
   0.00164436 -0.05664362 -0.00866756  0.01971503 -0.02416108  0.03226669
   0.04745552  0.00065802  0.00439175  0.00441823  0.00156271  0.00200308
   0.0237344  -0.01724092]]

Final Loss: 0.2131
Distance Metric: 5.0347
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 455

================================================================================

baselineCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.00106848 -0.00091504 -0.00326831 ...  0.0005469  -0.00444618
  -0.01329194]
 [-0.00437227 -0.01643679  0.03009255 ...  0.00453038  0.00990749
  -0.052548  ]
 [-0.00372958 -0.00348183  0.0162519  ... -0.00048654  0.0086287
   0.00485942]
 ...
 [-0.00204324 -0.00042485  0.02152566 ... -0.00645471  0.01094018
   0.01421441]
 [ 0.00403532  0.00513426 -0.01747634 ... -0.00031969 -0.01275862
  -0.02205605]
 [-0.00402046 -0.01228627  0.01768404 ...  0.00407772  0.00091912
  -0.04738188]]
layers.1.weight: [[ 0.00520158  0.01124324  0.00418694 ...  0.00252691 -0.00519381
   0.0040682 ]
 [-0.00146364  0.01011499  0.00673371 ...  0.00654031 -0.00313566
   0.00382489]
 [-0.0030294   0.00571505  0.00428891 ...  0.00812952 -0.00358917
   0.0065785 ]
 ...
 [ 0.00242412 -0.00494539 -0.0061322  ... -0.00124348  0.00043077
   0.00265381]
 [-0.00084537  0.00065016  0.00139036 ...  0.00292883  0.00631283
  -0.0036971 ]
 [ 0.0004485   0.00740915  0.00197442 ...  0.00250215 -0.00485348
   0.00876615]]
layers.2.weight: [[ 0.05226703  0.05627217  0.05494921  0.01863641 -0.05388945  0.04909304
   0.01422395  0.05341817  0.05303288 -0.04959138  0.04932338  0.0520777
   0.05460652  0.05356546  0.05619518  0.04509235 -0.04956793  0.0531907
  -0.05340129 -0.27736956 -0.05264479 -0.04877993 -0.05353437 -0.0535658
   0.05614613  0.05290126 -0.16467631  0.05352172  0.05036201 -0.05201079
  -0.02810124  0.05543582]]

Final Loss: 0.0439
Distance Metric: 6.7066
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 376

================================================================================

baselineCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.01018152 -0.00092292  0.00805579 ... -0.01534189 -0.00241777
   0.01311607]
 [-0.00681422 -0.00058314  0.00533862 ... -0.01288014 -0.00205885
   0.01101815]
 [-0.01005142 -0.00161107  0.00777528 ... -0.01062289 -0.00145068
   0.00853394]
 ...
 [-0.00933144 -0.00155768  0.00709912 ... -0.01422765 -0.00203369
   0.01156147]
 [-0.03330828 -0.00298178  0.02696967 ... -0.02517773 -0.00382632
   0.02176438]
 [-0.01061068 -0.00172215  0.00817104 ... -0.01229176 -0.00170024
   0.00991017]]
layers.1.weight: [[ 0.00505956  0.00458656 -0.00095687 ...  0.00028668  0.00765038
  -0.00074364]
 [ 0.0045279   0.00410531 -0.00084579 ...  0.00026504  0.00684334
  -0.00065536]
 [ 0.01230249  0.01111038 -0.00287198 ...  0.00026685  0.01882382
  -0.00233147]
 ...
 [ 0.01058584  0.00956756 -0.00238164 ...  0.00029922  0.01615586
  -0.00192086]
 [-0.1931238  -0.18366188  0.10354798 ...  0.04709203 -0.24451023
   0.09873296]
 [ 0.00954096  0.00862838 -0.00208801 ...  0.00031568  0.01453635
  -0.00167522]]
layers.2.weight: [[ 0.1032217   0.09276617  0.254166    0.24905908  0.00584834 -4.9455295
   0.23839837  0.28070036  0.25298077  0.14254981  0.27434638  0.28392997
  -0.18192805  0.29457545  0.24911565  0.19764353  0.17305055  0.27775797
   0.23316573  0.28232113  0.11141323  0.25670746 -4.9018126   0.17990133
   0.15558833 -0.3356382   0.12784274 -1.9166573   0.26079398  0.21721382
  -2.072852    0.19504131]]

Final Loss: 0.2988
Distance Metric: 25.3796
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 3046

================================================================================

baselineCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.00013453  0.         -0.00014607 ...  0.          0.
   0.        ]]
layers.2.weight: [[-0.00044228  0.          0.00027641 -0.00056718 -0.00044914  0.
  -0.00018447 -0.00013595  0.00041284  0.00050639  0.00018425 -0.00045804
   0.00100154  0.00041297 -0.00040217  0.00063769  0.00060165 -0.00025543
  -0.00072845 -0.00010613  0.         -0.00010813  0.          0.
  -0.00013463  0.00032804  0.         -0.00065101  0.          0.00018714
  -0.0004347  -0.00018231]]

Final Loss: 0.4817
Distance Metric: 4.6036
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 903

================================================================================

baselineCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.0001387   0.00116958 -0.0008013  ...  0.         -0.00057693
   0.00028621]
 [ 0.         -0.00016475  0.00010803 ...  0.          0.00010246
   0.        ]
 [ 0.          0.00037304 -0.00025434 ...  0.         -0.00018911
   0.        ]
 ...
 [ 0.00026137  0.00215964 -0.00146755 ... -0.00016958 -0.00112446
   0.00056411]
 [-0.00015069 -0.00125112  0.00085129 ...  0.          0.0006434
  -0.00032223]
 [ 0.         -0.00069139  0.00047111 ...  0.          0.00035195
  -0.00017592]]
layers.1.weight: [[ 0.          0.          0.         ...  0.00012515  0.
   0.        ]
 [ 0.00011013  0.          0.         ...  0.00021284 -0.0001221
   0.        ]
 [ 0.00014647  0.          0.         ...  0.00028309 -0.0001624
   0.        ]
 ...
 [ 0.00015591  0.          0.         ...  0.00030131 -0.00017285
   0.        ]
 [ 0.00010181  0.          0.         ...  0.00019677 -0.00011288
   0.        ]
 [-0.00010783  0.          0.         ... -0.00020839  0.00011955
   0.        ]]
layers.2.weight: [[ 0.0095655   0.01626422  0.02162841  0.0435475   0.66727877  0.39677534
   0.03233972  0.0107666   0.01887375  0.01358038  0.03105392  0.02438995
  -0.02184439  0.03225563  0.00869447  0.01420477  0.01034871  0.01995058
   0.00656402 -0.00895585 -0.01342487  0.20766015  0.009134   -0.04634636
  -0.04231646 -0.03535963  0.02069168  0.04755789  0.01771424  0.02301919
   0.01503685 -0.01592489]]

Final Loss: 0.0001
Distance Metric: 3.4006
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 3389

================================================================================

