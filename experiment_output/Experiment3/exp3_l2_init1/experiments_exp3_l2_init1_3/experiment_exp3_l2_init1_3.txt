Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.6643082   0.04732776 -0.43385768]]]
layers.1.weight: [[[-0.5221824  -0.55525833]]]
layers.2.weight: [[[ 1.1406595 -0.6489098]]]

================================================================================

baselineCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.02263471  0.00161408 -0.01474653 ...  0.01373184 -0.00093463
   0.0089332 ]
 [-0.01024911  0.00073116 -0.00667746 ...  0.00622011 -0.00042297
   0.00404725]
 [-0.02111986  0.00150795 -0.01376167 ...  0.01281248 -0.00087432
   0.00833574]
 ...
 [ 0.03374625 -0.00240809  0.02198707 ... -0.02046637  0.00139396
  -0.01331521]
 [ 0.01140521 -0.00081237  0.00743122 ... -0.00692007  0.0004719
  -0.00450276]
 [ 0.00108435  0.          0.00070658 ... -0.00065767  0.
  -0.0004284 ]]
layers.1.weight: [[ 0.01121809  0.0050964   0.01046837 ... -0.01665197 -0.00560319
  -0.00050363]
 [ 0.00081465  0.00036544  0.00075895 ... -0.0012326  -0.00042108
   0.        ]
 [-0.00222025 -0.00099981 -0.00206973 ...  0.00333058  0.00113061
   0.00011595]
 ...
 [-0.01097098 -0.00498538 -0.01023928 ...  0.01628442  0.00547743
   0.00049128]
 [ 0.00681656  0.00308625  0.00636006 ... -0.01017232 -0.00343651
  -0.00032831]
 [-0.00049391 -0.0002238  -0.00046141 ...  0.00073873  0.00025094
   0.        ]]
layers.2.weight: [[-0.20421591 -0.01481558  0.0408872  -0.14439268  0.04029689 -0.1896573
   0.14484285 -0.19042008  0.15698528 -0.09196643  0.17538454  0.212945
  -0.14840174  0.16653693 -0.16776864 -0.08983544  0.19812106 -0.06716809
  -0.12733354  0.07865843  0.02199609  0.27967954 -0.21069908  0.19041552
  -0.10221561  0.00358654  0.19323958  0.03799724  0.07853381  0.20010106
  -0.12439138  0.00923235]]

Final Loss: 0.0000
Distance Metric: 4.7680
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 1229

================================================================================

baselineCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.         -0.0002921   0.
   0.00014964  0.          0.          0.00011275  0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.00011416  0.00028323  0.00017717  0.00022518  0.
   0.00022076  0.        ]]

Final Loss: 0.0944
Distance Metric: 2.4127
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 1006

================================================================================

baselineCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.00649507 -0.00352521  0.00170255 ... -0.01133575  0.01034751
   0.00370278]
 [ 0.00296459  0.00260995 -0.00069572 ...  0.00726525 -0.00649862
  -0.00173126]
 [-0.00235921 -0.00178955  0.00167374 ... -0.00602965  0.00474719
   0.00068866]
 ...
 [ 0.00081046  0.00036426  0.00037026 ...  0.00180354 -0.00181837
  -0.00083515]
 [ 0.          0.          0.         ... -0.00099025  0.
   0.00029339]
 [ 0.00496997  0.00391408 -0.00093855 ...  0.00979517 -0.00904289
  -0.00308712]]
layers.1.weight: [[ 0.00419197 -0.00568444 -0.00031797 ... -0.00320042  0.
  -0.00347069]
 [-0.00020377  0.00090096 -0.00098195 ...  0.00157497  0.0028523
  -0.00034299]
 [ 0.00557616  0.          0.00419314 ... -0.00298996  0.00039536
  -0.00317127]
 ...
 [-0.00179269  0.00234304 -0.00123795 ... -0.00133797  0.00137335
  -0.00285552]
 [ 0.0040961  -0.00321255  0.00341593 ...  0.0006552   0.00081621
  -0.00205831]
 [ 0.0007328   0.00484432 -0.00290179 ...  0.00161973  0.00322996
   0.00092499]]
layers.2.weight: [[ 0.0256602   0.01251784  0.0326518  -0.03111859  0.00242896 -0.01136789
   0.00159387  0.03813764 -0.01393201  0.04164825 -0.01827164  0.01619079
  -0.02403075 -0.00642052  0.01745247 -0.02144421 -0.01114203  0.02537349
   0.00164436 -0.05664362 -0.00866756  0.01971503 -0.02416108  0.03226669
   0.04745552  0.00065802  0.00439175  0.00441823  0.00156271  0.00200308
   0.0237344  -0.01724092]]

Final Loss: 0.2131
Distance Metric: 5.0347
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 455

================================================================================

baselineCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.00106848 -0.00091504 -0.00326831 ...  0.0005469  -0.00444618
  -0.01329194]
 [-0.00437227 -0.01643679  0.03009255 ...  0.00453038  0.00990749
  -0.052548  ]
 [-0.00372958 -0.00348183  0.0162519  ... -0.00048654  0.0086287
   0.00485942]
 ...
 [-0.00204324 -0.00042485  0.02152566 ... -0.00645471  0.01094018
   0.01421441]
 [ 0.00403532  0.00513426 -0.01747634 ... -0.00031969 -0.01275862
  -0.02205605]
 [-0.00402046 -0.01228627  0.01768404 ...  0.00407772  0.00091912
  -0.04738188]]
layers.1.weight: [[ 0.00520158  0.01124324  0.00418694 ...  0.00252691 -0.00519381
   0.0040682 ]
 [-0.00146364  0.01011499  0.00673371 ...  0.00654031 -0.00313566
   0.00382489]
 [-0.0030294   0.00571505  0.00428891 ...  0.00812952 -0.00358917
   0.0065785 ]
 ...
 [ 0.00242412 -0.00494539 -0.0061322  ... -0.00124348  0.00043077
   0.00265381]
 [-0.00084537  0.00065016  0.00139036 ...  0.00292883  0.00631283
  -0.0036971 ]
 [ 0.0004485   0.00740915  0.00197442 ...  0.00250215 -0.00485348
   0.00876615]]
layers.2.weight: [[ 0.05226703  0.05627217  0.05494921  0.01863641 -0.05388945  0.04909304
   0.01422395  0.05341817  0.05303288 -0.04959138  0.04932338  0.0520777
   0.05460652  0.05356546  0.05619518  0.04509235 -0.04956793  0.0531907
  -0.05340129 -0.27736956 -0.05264479 -0.04877993 -0.05353437 -0.0535658
   0.05614613  0.05290126 -0.16467631  0.05352172  0.05036201 -0.05201079
  -0.02810124  0.05543582]]

Final Loss: 0.0439
Distance Metric: 6.7066
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 376

================================================================================

baselineCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.01018152 -0.00092292  0.00805579 ... -0.01534189 -0.00241777
   0.01311607]
 [-0.00681422 -0.00058314  0.00533862 ... -0.01288014 -0.00205885
   0.01101815]
 [-0.01005142 -0.00161107  0.00777528 ... -0.01062289 -0.00145068
   0.00853394]
 ...
 [-0.00933144 -0.00155768  0.00709912 ... -0.01422765 -0.00203369
   0.01156147]
 [-0.03330828 -0.00298178  0.02696967 ... -0.02517773 -0.00382632
   0.02176438]
 [-0.01061068 -0.00172215  0.00817104 ... -0.01229176 -0.00170024
   0.00991017]]
layers.1.weight: [[ 0.00505956  0.00458656 -0.00095687 ...  0.00028668  0.00765038
  -0.00074364]
 [ 0.0045279   0.00410531 -0.00084579 ...  0.00026504  0.00684334
  -0.00065536]
 [ 0.01230249  0.01111038 -0.00287198 ...  0.00026685  0.01882382
  -0.00233147]
 ...
 [ 0.01058584  0.00956756 -0.00238164 ...  0.00029922  0.01615586
  -0.00192086]
 [-0.1931238  -0.18366188  0.10354798 ...  0.04709203 -0.24451023
   0.09873296]
 [ 0.00954096  0.00862838 -0.00208801 ...  0.00031568  0.01453635
  -0.00167522]]
layers.2.weight: [[ 0.1032217   0.09276617  0.254166    0.24905908  0.00584834 -4.9455295
   0.23839837  0.28070036  0.25298077  0.14254981  0.27434638  0.28392997
  -0.18192805  0.29457545  0.24911565  0.19764353  0.17305055  0.27775797
   0.23316573  0.28232113  0.11141323  0.25670746 -4.9018126   0.17990133
   0.15558833 -0.3356382   0.12784274 -1.9166573   0.26079398  0.21721382
  -2.072852    0.19504131]]

Final Loss: 0.2988
Distance Metric: 25.3796
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 3046

================================================================================

baselineCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.00013453  0.         -0.00014607 ...  0.          0.
   0.        ]]
layers.2.weight: [[-0.00044228  0.          0.00027641 -0.00056718 -0.00044914  0.
  -0.00018447 -0.00013595  0.00041284  0.00050639  0.00018425 -0.00045804
   0.00100154  0.00041297 -0.00040217  0.00063769  0.00060165 -0.00025543
  -0.00072845 -0.00010613  0.         -0.00010813  0.          0.
  -0.00013463  0.00032804  0.         -0.00065101  0.          0.00018714
  -0.0004347  -0.00018231]]

Final Loss: 0.4817
Distance Metric: 4.6036
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 903

================================================================================

baselineCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.0001387   0.00116958 -0.0008013  ...  0.         -0.00057693
   0.00028621]
 [ 0.         -0.00016475  0.00010803 ...  0.          0.00010246
   0.        ]
 [ 0.          0.00037304 -0.00025434 ...  0.         -0.00018911
   0.        ]
 ...
 [ 0.00026137  0.00215964 -0.00146755 ... -0.00016958 -0.00112446
   0.00056411]
 [-0.00015069 -0.00125112  0.00085129 ...  0.          0.0006434
  -0.00032223]
 [ 0.         -0.00069139  0.00047111 ...  0.          0.00035195
  -0.00017592]]
layers.1.weight: [[ 0.          0.          0.         ...  0.00012515  0.
   0.        ]
 [ 0.00011013  0.          0.         ...  0.00021284 -0.0001221
   0.        ]
 [ 0.00014647  0.          0.         ...  0.00028309 -0.0001624
   0.        ]
 ...
 [ 0.00015591  0.          0.         ...  0.00030131 -0.00017285
   0.        ]
 [ 0.00010181  0.          0.         ...  0.00019677 -0.00011288
   0.        ]
 [-0.00010783  0.          0.         ... -0.00020839  0.00011955
   0.        ]]
layers.2.weight: [[ 0.0095655   0.01626422  0.02162841  0.0435475   0.66727877  0.39677534
   0.03233972  0.0107666   0.01887375  0.01358038  0.03105392  0.02438995
  -0.02184439  0.03225563  0.00869447  0.01420477  0.01034871  0.01995058
   0.00656402 -0.00895585 -0.01342487  0.20766015  0.009134   -0.04634636
  -0.04231646 -0.03535963  0.02069168  0.04755789  0.01771424  0.02301919
   0.01503685 -0.01592489]]

Final Loss: 0.0001
Distance Metric: 3.4006
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 3389

================================================================================

baselineCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.03579202 -0.02709637 -0.0457859  ... -0.01196246 -0.0538394
   0.08244622]
 [-0.07838759  0.02629263  0.00639234 ... -0.0250636  -0.03556927
  -0.00625814]
 [-0.01991376 -0.08264825  0.06423415 ...  0.09725652 -0.12308538
  -0.07258948]
 ...
 [ 0.05199016  0.01957901  0.02109025 ... -0.01755433  0.04213408
  -0.0596647 ]
 [ 0.05083043  0.02846031  0.02823838 ... -0.0559647   0.02567025
  -0.07277083]
 [ 0.02610859  0.06451353 -0.02284955 ...  0.00409719 -0.10105681
   0.00359856]]
layers.1.weight: [[ 0.1120176  -0.00161595 -0.08986497 ... -0.00202534 -0.06034452
   0.02391454]
 [ 0.0462943  -0.04553173  0.20430978 ...  0.15218611  0.00822663
   0.06704677]
 [-0.13172418  0.02928835  0.07296637 ...  0.06149404 -0.11281049
  -0.01743371]
 ...
 [ 0.0154936   0.01795319 -0.05219404 ... -0.04364409  0.07548062
   0.00990757]
 [-0.09286968  0.10616311  0.00622047 ...  0.03305627  0.04554479
  -0.16358523]
 [-0.06443702 -0.07235121  0.08762808 ...  0.0438148  -0.02066895
  -0.08707909]]
layers.2.weight: [[ 0.22649151 -0.6203598   0.25897774 -0.61675024 -0.07163467 -0.49011418
  -0.15078244 -0.71336687 -0.09249025 -0.8664575  -0.43901733  0.19347723
  -0.26352862 -0.2911576  -0.27563557  0.12512408  0.01705535 -0.19134784
   0.40622583 -0.09661114  0.21963717 -0.09215941  0.33045912  0.752174
   0.2189256  -0.49471423  0.02641901  0.4177191   0.32153302 -0.2582777
  -0.24694526  0.05670831]]

Final Loss: 4.8756
Distance Metric: 18.6546
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 100

================================================================================

baselineCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.18137401 -0.20235687  0.06356847 ...  0.03781332 -0.02782337
   0.01079387]
 [ 0.07717489 -0.07729989  0.02284757 ...  0.03867635 -0.01944114
   0.01106297]
 [-0.09190185  0.11019128 -0.03110962 ... -0.03605202  0.04266293
  -0.01395646]
 ...
 [ 0.0114621  -0.00272756  0.00783346 ... -0.02915777  0.04762762
  -0.01514485]
 [ 0.06519187 -0.07151701  0.03884084 ... -0.09588333  0.10393439
  -0.03930903]
 [ 0.08008822 -0.09190448  0.02733344 ...  0.00769724 -0.00205912
   0.00140374]]
layers.1.weight: [[-0.05134959 -0.02995805 -0.00285958 ... -0.04937119 -0.09946997
  -0.01997067]
 [ 0.07633754  0.10093727  0.0126112  ...  0.04276939 -0.0652645
   0.03744105]
 [-0.05387272 -0.02173145  0.0255977  ...  0.02883488  0.06196868
  -0.0431853 ]
 ...
 [-0.02702927 -0.0120755   0.01009459 ...  0.00860695  0.02064999
  -0.02039597]
 [-0.00990757 -0.00453163  0.00368904 ...  0.0006426   0.00241017
  -0.00643749]
 [ 0.02503661  0.01497995 -0.00265726 ...  0.0150545   0.03342704
   0.01069141]]
layers.2.weight: [[-2.4680328  -3.2293718   2.4693506  -0.02082309 -2.1172333  -0.14036873
   1.1578178   0.83062154 -0.24132937  2.9024134  -0.33725938  1.7213136
   4.471642   -0.51193887 -4.2903075   1.5475168   1.2529477   2.1068678
  -0.4288644  -1.9868577  -1.8152556  -3.0487955  -6.556895   -3.0893433
   1.285507   -1.2905682   1.3356348   3.4101868  -0.5436248   1.4216685
   0.48289704  0.65660334]]

Final Loss: 3.2573
Distance Metric: 39.8357
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 1147

================================================================================

