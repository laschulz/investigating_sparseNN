Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.35649812  0.16707432  0.23166955]]]
layers.1.weight: [[[ 1.1215595 -0.1441364]]]
layers.2.weight: [[[ 0.21158198 -0.9305709 ]]]

================================================================================

baselineCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.00338335  0.00159179  0.00219909 ... -0.00195158  0.00091557
   0.00123283]
 [-0.00685149  0.00321249  0.0044385  ... -0.00393489  0.0018412
   0.00248403]
 [ 0.00434838 -0.00203767 -0.00282373 ...  0.0025018  -0.00116436
  -0.00157503]
 ...
 [ 0.0047114  -0.00221481 -0.00306126 ...  0.0027145  -0.00126516
  -0.00170826]
 [-0.00578832  0.00272137  0.00375945 ... -0.00332741  0.0015522
   0.0020973 ]
 [ 0.00317231 -0.00148828 -0.00206069 ...  0.0018227  -0.00085342
  -0.00114767]]
layers.1.weight: [[-0.00411204 -0.00828767  0.00521787 ...  0.00566634 -0.00701381
   0.00379736]
 [-0.00030272 -0.00061763  0.00039592 ...  0.00043039 -0.00052871
   0.00029153]
 [-0.00154275 -0.00312765  0.00201035 ...  0.00217935 -0.00264793
   0.00147278]
 ...
 [-0.00616632 -0.01238573  0.00771833 ...  0.00837808 -0.01048626
   0.00560024]
 [-0.00075548 -0.00154723  0.0009904  ...  0.00107531 -0.00130246
   0.00072915]
 [ 0.00207271  0.00421156 -0.00269806 ... -0.00292606  0.00356014
  -0.00197134]]
layers.2.weight: [[-0.14622155 -0.01123878 -0.05578651  0.10711215 -0.09755739 -0.05121961
  -0.1279312   0.1295966  -0.02791284  0.04900096 -0.00767738 -0.1729517
  -0.13836189  0.24327588  0.08246033 -0.02919215 -0.17180954 -0.1045325
   0.13658734 -0.15474056 -0.20940368  0.13539523 -0.20503403 -0.01128176
  -0.13662054  0.06752773 -0.02641523  0.12078871  0.11487637 -0.21746403
  -0.02766439  0.07443466]]

Final Loss: 0.0000
Distance Metric: 4.1250
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 1
stopped after epoch: 1100

================================================================================

baselineCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.00011149 ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 ...
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]]
layers.1.weight: [[ 0.         -0.00012359  0.         ...  0.          0.
   0.00015107]
 [ 0.          0.          0.         ...  0.         -0.00018034
   0.        ]
 [ 0.          0.          0.         ... -0.00010122  0.
   0.00016832]
 ...
 [-0.00010126  0.          0.         ... -0.00015038  0.
  -0.00023704]
 [ 0.          0.00016186  0.         ...  0.         -0.0001148
   0.        ]
 [ 0.          0.         -0.00017409 ...  0.          0.
   0.        ]]
layers.2.weight: [[ 0.00053119  0.         -0.00027983 -0.00050231 -0.00043581 -0.00013085
   0.          0.00032701 -0.00034645  0.00020693  0.         -0.00049843
   0.         -0.00095077 -0.00030588  0.0002254  -0.00019899 -0.00025493
  -0.00079112 -0.00053027  0.00051776  0.00015442  0.0006532   0.00033816
   0.0007491   0.00111075  0.00013421 -0.00027229  0.00076624  0.00051346
   0.00088948 -0.00046768]]

Final Loss: 0.1347
Distance Metric: 2.6093
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 1
stopped after epoch: 850

================================================================================

baselineCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 5.9886903e-02 -4.2709797e-03  1.1623859e-02 ...  2.3584685e-01
   1.1393054e-02  8.5607329e-03]
 [-8.1244417e-02 -5.6699864e-03 -5.5443509e-03 ...  2.2533645e-01
   1.6339237e-02  1.1634381e-02]
 [ 8.7151930e-02  9.3467804e-03  4.8614154e-03 ... -2.2269523e-01
  -1.6281076e-02 -1.1430828e-02]
 ...
 [ 1.3800836e-02 -2.1208427e-03  1.9150407e-03 ...  1.5197220e-01
   1.0794416e-02  7.9779904e-03]
 [ 4.4240296e-02  1.2765374e-04  1.7438903e-03 ...  6.3304938e-02
   5.0304523e-03  3.8946650e-03]
 [ 3.9073218e-02 -2.2352235e-04  2.4791507e-03 ...  7.1535252e-02
   7.6101306e-03  4.1380902e-03]]
layers.1.weight: [[-8.4995925e-03  8.8455938e-03 -1.6851494e-02 ... -2.7894750e-03
  -7.3654498e-03 -1.2013409e-02]
 [ 1.4788045e-01  1.3428146e-01 -1.1539578e-01 ...  8.6743757e-02
   3.4023497e-02  3.8482886e-02]
 [-1.6166250e-01 -1.5135552e-01  1.3372350e-01 ... -9.5240422e-02
  -3.5057075e-02 -3.8325164e-02]
 ...
 [-4.1981600e-02 -1.1355594e-04  0.0000000e+00 ... -2.3690766e-02
  -3.0634584e-02 -8.7057345e-02]
 [ 1.3210099e-02 -1.1349108e-02  2.2624830e-02 ...  4.6732402e-03
   1.0529071e-02  1.6360741e-02]
 [ 8.0710180e-02  3.0899433e-02 -6.2781251e-03 ...  4.5044832e-02
   3.7775129e-02  5.2648824e-02]]
layers.2.weight: [[-0.57050914 -3.5897474   3.8614578   0.03723075  0.19879279  3.5046513
   0.9310009  -0.7523447   0.7745572   0.9672922  -0.8126389  -2.8973324
  -0.24933366  3.7446744  -0.89632994 -0.90070975  2.7948647   3.444821
  -0.94407725 -0.8830377  -0.9034322  -0.8152834   0.8400323  -0.8986432
   3.5287018  -0.66983485  2.462042    0.78724205  0.77570045  2.9153214
   0.93300873 -1.6875511 ]]

Final Loss: 0.7401
Distance Metric: 36.0345
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 1
stopped after epoch: 1395

================================================================================

