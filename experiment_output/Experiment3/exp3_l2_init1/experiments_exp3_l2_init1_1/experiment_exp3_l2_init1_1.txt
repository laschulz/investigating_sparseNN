Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.35649812  0.16707432  0.23166955]]]
layers.1.weight: [[[ 1.1215595 -0.1441364]]]
layers.2.weight: [[[ 0.21158198 -0.9305709 ]]]

================================================================================

baselineCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.00338335  0.00159179  0.00219909 ... -0.00195158  0.00091557
   0.00123283]
 [-0.00685149  0.00321249  0.0044385  ... -0.00393489  0.0018412
   0.00248403]
 [ 0.00434838 -0.00203767 -0.00282373 ...  0.0025018  -0.00116436
  -0.00157503]
 ...
 [ 0.0047114  -0.00221481 -0.00306126 ...  0.0027145  -0.00126516
  -0.00170826]
 [-0.00578832  0.00272137  0.00375945 ... -0.00332741  0.0015522
   0.0020973 ]
 [ 0.00317231 -0.00148828 -0.00206069 ...  0.0018227  -0.00085342
  -0.00114767]]
layers.1.weight: [[-0.00411204 -0.00828767  0.00521787 ...  0.00566634 -0.00701381
   0.00379736]
 [-0.00030272 -0.00061763  0.00039592 ...  0.00043039 -0.00052871
   0.00029153]
 [-0.00154275 -0.00312765  0.00201035 ...  0.00217935 -0.00264793
   0.00147278]
 ...
 [-0.00616632 -0.01238573  0.00771833 ...  0.00837808 -0.01048626
   0.00560024]
 [-0.00075548 -0.00154723  0.0009904  ...  0.00107531 -0.00130246
   0.00072915]
 [ 0.00207271  0.00421156 -0.00269806 ... -0.00292606  0.00356014
  -0.00197134]]
layers.2.weight: [[-0.14622155 -0.01123878 -0.05578651  0.10711215 -0.09755739 -0.05121961
  -0.1279312   0.1295966  -0.02791284  0.04900096 -0.00767738 -0.1729517
  -0.13836189  0.24327588  0.08246033 -0.02919215 -0.17180954 -0.1045325
   0.13658734 -0.15474056 -0.20940368  0.13539523 -0.20503403 -0.01128176
  -0.13662054  0.06752773 -0.02641523  0.12078871  0.11487637 -0.21746403
  -0.02766439  0.07443466]]

Final Loss: 0.0000
Distance Metric: 4.1250
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 1
stopped after epoch: 1100

================================================================================

baselineCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.00011149 ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 ...
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]]
layers.1.weight: [[ 0.         -0.00012359  0.         ...  0.          0.
   0.00015107]
 [ 0.          0.          0.         ...  0.         -0.00018034
   0.        ]
 [ 0.          0.          0.         ... -0.00010122  0.
   0.00016832]
 ...
 [-0.00010126  0.          0.         ... -0.00015038  0.
  -0.00023704]
 [ 0.          0.00016186  0.         ...  0.         -0.0001148
   0.        ]
 [ 0.          0.         -0.00017409 ...  0.          0.
   0.        ]]
layers.2.weight: [[ 0.00053119  0.         -0.00027983 -0.00050231 -0.00043581 -0.00013085
   0.          0.00032701 -0.00034645  0.00020693  0.         -0.00049843
   0.         -0.00095077 -0.00030588  0.0002254  -0.00019899 -0.00025493
  -0.00079112 -0.00053027  0.00051776  0.00015442  0.0006532   0.00033816
   0.0007491   0.00111075  0.00013421 -0.00027229  0.00076624  0.00051346
   0.00088948 -0.00046768]]

Final Loss: 0.1347
Distance Metric: 2.6093
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 1
stopped after epoch: 850

================================================================================

baselineCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 5.9886903e-02 -4.2709797e-03  1.1623859e-02 ...  2.3584685e-01
   1.1393054e-02  8.5607329e-03]
 [-8.1244417e-02 -5.6699864e-03 -5.5443509e-03 ...  2.2533645e-01
   1.6339237e-02  1.1634381e-02]
 [ 8.7151930e-02  9.3467804e-03  4.8614154e-03 ... -2.2269523e-01
  -1.6281076e-02 -1.1430828e-02]
 ...
 [ 1.3800836e-02 -2.1208427e-03  1.9150407e-03 ...  1.5197220e-01
   1.0794416e-02  7.9779904e-03]
 [ 4.4240296e-02  1.2765374e-04  1.7438903e-03 ...  6.3304938e-02
   5.0304523e-03  3.8946650e-03]
 [ 3.9073218e-02 -2.2352235e-04  2.4791507e-03 ...  7.1535252e-02
   7.6101306e-03  4.1380902e-03]]
layers.1.weight: [[-8.4995925e-03  8.8455938e-03 -1.6851494e-02 ... -2.7894750e-03
  -7.3654498e-03 -1.2013409e-02]
 [ 1.4788045e-01  1.3428146e-01 -1.1539578e-01 ...  8.6743757e-02
   3.4023497e-02  3.8482886e-02]
 [-1.6166250e-01 -1.5135552e-01  1.3372350e-01 ... -9.5240422e-02
  -3.5057075e-02 -3.8325164e-02]
 ...
 [-4.1981600e-02 -1.1355594e-04  0.0000000e+00 ... -2.3690766e-02
  -3.0634584e-02 -8.7057345e-02]
 [ 1.3210099e-02 -1.1349108e-02  2.2624830e-02 ...  4.6732402e-03
   1.0529071e-02  1.6360741e-02]
 [ 8.0710180e-02  3.0899433e-02 -6.2781251e-03 ...  4.5044832e-02
   3.7775129e-02  5.2648824e-02]]
layers.2.weight: [[-0.57050914 -3.5897474   3.8614578   0.03723075  0.19879279  3.5046513
   0.9310009  -0.7523447   0.7745572   0.9672922  -0.8126389  -2.8973324
  -0.24933366  3.7446744  -0.89632994 -0.90070975  2.7948647   3.444821
  -0.94407725 -0.8830377  -0.9034322  -0.8152834   0.8400323  -0.8986432
   3.5287018  -0.66983485  2.462042    0.78724205  0.77570045  2.9153214
   0.93300873 -1.6875511 ]]

Final Loss: 0.7401
Distance Metric: 36.0345
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 1
stopped after epoch: 1395

================================================================================

baselineCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.0016958  -0.0055503   0.00393453 ... -0.00401079 -0.00076465
  -0.01021906]
 [ 0.          0.00020251  0.00015769 ...  0.00013627 -0.00012881
   0.        ]
 [ 0.00136058  0.00417709 -0.00279819 ...  0.00347864  0.00081611
   0.00752323]
 ...
 [ 0.          0.00082103 -0.00077798 ...  0.00107627  0.
   0.00180887]
 [ 0.0003588   0.00109622 -0.00060547 ...  0.00073145  0.00034604
   0.00192849]
 [ 0.00058981  0.00138122 -0.00084287 ...  0.00114317  0.
   0.00273941]]
layers.1.weight: [[ 0.00298244 -0.00044432 -0.00171025 ... -0.00039709 -0.00100978
  -0.00170644]
 [ 0.00092984  0.00028279  0.00025459 ...  0.00102403  0.00091823
  -0.00042457]
 [ 0.00058871 -0.00126161  0.00087528 ... -0.00088598 -0.00036672
  -0.00051978]
 ...
 [ 0.00230881  0.00069805 -0.00315588 ...  0.00064858 -0.00158725
  -0.00077307]
 [-0.00102664  0.00069171 -0.00054905 ... -0.00075179  0.00014194
   0.00090137]
 [ 0.0032211  -0.00093188 -0.00293736 ... -0.00071146  0.00040443
   0.        ]]
layers.2.weight: [[ 0.03584603  0.00249066  0.00248901 -0.01981027  0.02174127 -0.03580464
  -0.00951247 -0.02072299  0.01151635 -0.03780807  0.00034068 -0.00507902
   0.00050063 -0.03305772 -0.00571501 -0.0071065  -0.01992645 -0.00454399
   0.07129589 -0.01236733 -0.01226252  0.00783366 -0.01265797 -0.00997751
   0.0057171   0.02155771  0.00756164  0.00810852 -0.01524722  0.02637322
   0.00414758  0.03235805]]

Final Loss: 0.1004
Distance Metric: 6.4610
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 1
stopped after epoch: 563

================================================================================

baselineCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.00318522  0.00565326 -0.00385092 ... -0.00019342  0.00308061
  -0.00148769]
 [ 0.00570811  0.00999641 -0.0072576  ... -0.01559259 -0.03612542
   0.03870892]
 [ 0.00268684  0.00477292 -0.00393908 ... -0.00951859 -0.02365159
   0.02499643]
 ...
 [ 0.00019935  0.00017409  0.00090394 ...  0.01819324  0.05075485
  -0.05041756]
 [ 0.00311388  0.00539543 -0.00238822 ...  0.0140777   0.04356284
  -0.04203632]
 [ 0.00371461  0.00658841 -0.00440441 ... -0.00053902  0.00286545
  -0.00108293]]
layers.1.weight: [[-0.00208558  0.00041852  0.00083379 ... -0.00488352 -0.00586426
  -0.00238275]
 [-0.00017516  0.          0.         ... -0.00041486 -0.00049182
  -0.0001929 ]
 [ 0.00015208  0.          0.         ...  0.00035714  0.00042526
   0.00016374]
 ...
 [-0.00037699  0.00010881  0.00016903 ... -0.00091277 -0.00107969
  -0.00042115]
 [ 0.00023684  0.         -0.00010546 ...  0.0005873   0.00069669
   0.00027359]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.2.weight: [[ 1.00164436e-01  8.18535872e-03 -6.99147023e-03  1.80588644e-02
  -1.02436855e-01  7.50156306e-03 -1.66454896e-01  1.92406558e-04
   1.59636457e-02  1.87741835e-02  1.24211060e-02  3.26651558e-02
  -6.82679994e-04 -1.30262633e-03 -2.11865921e-02  1.15612894e-02
   3.06858076e-03  1.47772051e-04 -1.36344070e-02  3.64812374e-01
  -2.81114727e-01 -1.09281596e-02 -1.32980831e-02  1.53961778e-01
  -4.36198246e-03 -1.51980678e-02  1.52827287e-02  2.68119872e-01
  -1.76830664e-02  1.78791620e-02 -1.15117654e-02  3.19208222e-04]]

Final Loss: 0.0007
Distance Metric: 5.4903
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 1
stopped after epoch: 1142

================================================================================

baselineCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.00625056  0.00691209  0.00075161 ... -0.00814729 -0.00861577
  -0.00040766]
 [-0.0288823  -0.02921395 -0.0026051  ...  0.01451089  0.01471881
   0.00068934]
 [-0.00552404 -0.00532435 -0.00031878 ... -0.00186679 -0.00204705
  -0.00016787]
 ...
 [-0.03067699 -0.03138272 -0.00263595 ...  0.01234547  0.01273696
   0.00042041]
 [ 0.01062748  0.00964074  0.00190777 ... -0.02882458 -0.02856429
  -0.00231369]
 [-0.03067875 -0.03224355 -0.00226354 ...  0.00350006  0.00429306
  -0.00044487]]
layers.1.weight: [[ 0.0038002  -0.02807601 -0.00860422 ... -0.0340191  -0.01603883
  -0.04554898]
 [ 0.00413761 -0.00321658  0.00217101 ... -0.00233778  0.0118413
   0.00100681]
 [ 0.00178331 -0.00168934  0.0008547  ... -0.00127415  0.00542162
   0.00030555]
 ...
 [-0.00142831  0.00136769 -0.00068058 ...  0.00103362 -0.00435683
  -0.00023779]
 [ 0.00451036 -0.00348186  0.00237306 ... -0.00252685  0.01288226
   0.00110795]
 [ 0.00295985 -0.00241807  0.0015217  ... -0.0017753   0.00859369
   0.00067066]]
layers.2.weight: [[-2.6764364  -0.5853121  -0.28449422  0.6368991   0.31135452 -0.50724345
  -0.2963533  -0.39899185 -0.6473201   0.3850077   0.00828847  0.45839638
  -1.0833123  -0.7113347   0.5422468   0.65602225  0.69934577 -0.4300249
  -0.18601927 -0.40626344 -0.68282294 -0.04716209  0.15334567  2.5689662
   0.40644062 -0.21064834 -0.1027317  -0.21856403 -6.2774315   0.2285189
  -0.6325946  -0.43500483]]

Final Loss: 0.1727
Distance Metric: 24.1166
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 1
stopped after epoch: 2202

================================================================================

baselineCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.         -0.00013592  0.         ...  0.         -0.00014584
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.         -0.00014133
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[ 0.          0.          0.         ...  0.         -0.00011667
   0.        ]
 [-0.00016043  0.          0.         ...  0.         -0.000141
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [-0.00016994  0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ... -0.00011583  0.
   0.        ]
 [ 0.          0.         -0.00017312 ...  0.         -0.00013995
   0.        ]]
layers.2.weight: [[ 0.          0.00025535  0.          0.         -0.00038709 -0.00010389
   0.         -0.00032568  0.          0.00012684 -0.00034605 -0.00061757
  -0.0003138  -0.00034865  0.00050099  0.          0.00014129 -0.0005152
  -0.00024098  0.         -0.00069995  0.         -0.00015607  0.00032404
  -0.00034158 -0.00014716  0.          0.         -0.00046713  0.
   0.00061692  0.0006225 ]]

Final Loss: 0.4757
Distance Metric: 4.1571
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 1
stopped after epoch: 877

================================================================================

baselineCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.0000000e+00 -2.1505114e-04  4.2301879e-04 ...  5.6660124e-03
   4.7638654e-03 -1.2660263e-02]
 [-2.2626344e-04 -1.8358581e-04  3.9552167e-04 ... -4.1908422e-03
  -3.4103335e-03  9.6145337e-03]
 [-1.5105003e-04  0.0000000e+00  6.9257303e-04 ... -1.1312587e-02
  -9.5260218e-03  2.5560956e-02]
 ...
 [ 1.5612708e-03  1.3292591e-03 -4.0706517e-03 ...  6.6952676e-02
   5.5363700e-02 -1.5380666e-01]
 [-6.9009408e-04 -5.6633755e-04  1.9076283e-03 ... -2.8272193e-02
  -2.3406604e-02  6.4860769e-02]
 [-6.6370808e-04 -5.3045148e-04  1.7751150e-03 ... -2.7486004e-02
  -2.2656865e-02  6.2894337e-02]]
layers.1.weight: [[ 0.          0.          0.         ...  0.00068241 -0.00024003
  -0.00026219]
 [ 0.          0.          0.         ...  0.00025316  0.
   0.        ]
 [ 0.          0.          0.         ... -0.00016548  0.
   0.        ]
 ...
 [-0.00164595  0.00207245  0.01096444 ... -0.0532572   0.02280416
   0.02112403]
 [ 0.          0.          0.         ... -0.00025139  0.
   0.        ]
 [ 0.          0.00025964  0.00024762 ... -0.00237699  0.00083149
   0.00091056]]
layers.2.weight: [[ 1.2166041e-02  4.5235399e-03 -2.9397814e-03 -9.0653896e-03
  -3.3100869e-03  1.2631449e-02  2.6537490e-04 -2.2580489e-04
   1.5086998e-03 -1.6721923e-02  7.4935576e-04 -1.1277294e-03
   5.1900704e-04  4.0425174e-03 -3.9103919e-01  4.2074248e-03
   1.8961195e-02  2.8614937e-03 -3.3817418e-02 -7.3509473e-01
   1.7347266e-03  2.7906427e-03  1.4964590e-02 -2.7927545e-01
   5.3174454e-03  4.2354632e-03 -1.2071300e-03 -5.1880614e-03
  -1.4695693e+00  3.1174678e-01 -4.4545992e-03 -4.3455672e-02]]

Final Loss: 0.0002
Distance Metric: 7.3770
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 1
stopped after epoch: 1309

================================================================================

baselineCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.          0.00021879 -0.0002039   0.0001152   0.
  -0.00018311 -0.00014787  0.          0.          0.          0.
   0.          0.          0.          0.          0.         -0.00028526
   0.          0.00011389  0.          0.0001593  -0.00016068  0.
   0.         -0.00012731  0.00014363  0.          0.00019844  0.
   0.          0.        ]]

Final Loss: 4.9466
Distance Metric: 7.0250
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 1
stopped after epoch: 995

================================================================================

