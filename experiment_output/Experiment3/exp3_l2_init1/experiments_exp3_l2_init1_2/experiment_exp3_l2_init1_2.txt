Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.44146323  0.26276267  0.19673789]]]
layers.1.weight: [[[ 0.2921897 -1.0049269]]]
layers.2.weight: [[[ 0.8164113 -1.0470921]]]

================================================================================

baselineCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.00267978  0.00162648  0.00121429 ... -0.01180636  0.00701184
   0.00526389]
 [-0.00337086  0.00200369  0.00149317 ... -0.01479394  0.00878048
   0.00656861]
 [ 0.00266827 -0.0015803  -0.00120463 ...  0.01170375 -0.00694751
  -0.00519595]
 ...
 [-0.01005588  0.00604559  0.00452118 ... -0.04430567  0.02633879
   0.01970505]
 [-0.00438751  0.00263437  0.00197733 ... -0.01939106  0.01151418
   0.00862307]
 [ 0.00225809 -0.00134305 -0.00101745 ...  0.00989925 -0.00589196
  -0.00441581]]
layers.1.weight: [[-0.00075639 -0.00094768  0.00075798 ... -0.00281591 -0.00123088
   0.0006347 ]
 [ 0.00337615  0.00419814 -0.0033174  ...  0.01262065  0.00549886
  -0.0028265 ]
 [ 0.          0.          0.         ... -0.00029321 -0.00013209
   0.        ]
 ...
 [ 0.00417371  0.00523693 -0.00412511 ...  0.01569603  0.00685333
  -0.00349179]
 [ 0.00019544  0.00026249 -0.00019045 ...  0.0007648   0.00033877
  -0.00018399]
 [-0.00035729 -0.0004465   0.00033671 ... -0.00134894 -0.00058208
   0.00030356]]
layers.2.weight: [[-0.0330124   0.14716862 -0.00338063  0.20487356  0.02183472  0.14108239
  -0.2143763  -0.1785352   0.03904314 -0.18306907  0.14842789  0.0503468
   0.17382005 -0.16508597 -0.2176929  -0.15146308  0.14849679 -0.20863633
   0.03103707 -0.19154303  0.04975985  0.03512607 -0.2543177  -0.17179313
   0.17639212  0.20745203 -0.19842516  0.09485442  0.13589711  0.18307343
   0.00898969 -0.01565505]]

Final Loss: 0.0000
Distance Metric: 4.8644
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 970

================================================================================

baselineCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.         -0.00010784
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.00014413  0.          0.         ...  0.          0.
   0.00010013]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[ 0.          0.0001353   0.         ... -0.0001591   0.
   0.        ]
 [ 0.00010815  0.00021484  0.00036731 ...  0.         -0.00014649
   0.        ]
 [-0.00014464  0.          0.         ...  0.0001052   0.
   0.        ]
 ...
 [-0.00014336  0.          0.00033384 ... -0.00021167  0.
   0.        ]
 [-0.00012544 -0.00010655  0.         ...  0.0001376   0.
   0.        ]
 [ 0.          0.          0.00012067 ...  0.          0.
   0.        ]]
layers.2.weight: [[ 0.00048597 -0.00018033 -0.00028615  0.00031892  0.00044686 -0.00052805
  -0.00056706  0.00092068 -0.0001144   0.00019828  0.          0.00043414
  -0.00100442  0.00053171  0.00074115  0.00068252 -0.00058056  0.
  -0.00048121  0.00051385 -0.00032794  0.00039479  0.00069388  0.00012736
  -0.00054768 -0.00020691  0.00034222 -0.00016058  0.         -0.00016887
   0.00045308  0.00043858]]

Final Loss: 0.4831
Distance Metric: 3.3840
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 825

================================================================================

baselineCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.01196248  0.00208681 -0.00055367 ... -0.00282785  0.00237794
  -0.00283185]
 [-0.04371656  0.00758735 -0.00347768 ... -0.01013599  0.00858518
  -0.01022672]
 [ 0.01947519 -0.00345396  0.00142887 ...  0.00469928 -0.00437297
   0.00493334]
 ...
 [-0.03793396  0.00650444 -0.00306648 ... -0.00882719  0.00725037
  -0.00908872]
 [-0.05869968  0.00984285 -0.00550978 ... -0.01327151  0.00935175
  -0.01331362]
 [ 0.02567061 -0.00458945  0.0019634  ...  0.00602568 -0.00522383
   0.00607878]]
layers.1.weight: [[-0.00198638 -0.00217307  0.00112693 ... -0.00355283 -0.00747563
   0.00110566]
 [-0.00046841  0.00199582  0.00215905 ... -0.00223816  0.00134832
  -0.00028159]
 [-0.00068632  0.00500506 -0.00075941 ...  0.00498676  0.00393287
  -0.00174175]
 ...
 [-0.00177682 -0.0036503   0.00179966 ...  0.         -0.00318067
   0.00357112]
 [-0.00415009 -0.00762563  0.00334999 ... -0.00579443 -0.00550166
   0.00510963]
 [-0.00098462 -0.00120922 -0.00032394 ...  0.00115479 -0.00066788
  -0.00251947]]
layers.2.weight: [[ 0.01901195 -0.0023331  -0.01184422  0.00712661  0.00363538  0.00292052
  -0.00183798  0.00786068 -0.0046697  -0.00235394 -0.02859327 -0.01253879
   0.01901135 -0.01804484 -0.00408884  0.00212712  0.02255233  0.03683785
  -0.00088745 -0.0031021   0.01773991 -0.02302796  0.01958819  0.01711076
   0.02949273  0.0051898  -0.03364884 -0.03031701 -0.006458    0.00995187
   0.02475623  0.00109827]]

Final Loss: 0.3822
Distance Metric: 4.1330
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 458

================================================================================

baselineCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0.]]

Final Loss: 0.0000
Distance Metric: 2.5115
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 5315

================================================================================

baselineCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.0004228  -0.00087069  0.00262698 ... -0.02559974  0.02689338
  -0.03444422]
 [ 0.00348349 -0.00340257  0.00592405 ... -0.01704932  0.01825254
  -0.02323798]
 [-0.00379138  0.0019338  -0.00273171 ... -0.01226653  0.01265168
  -0.01676812]
 ...
 [ 0.00469741 -0.00452395  0.00688386 ... -0.00452646  0.00535885
  -0.00678919]
 [ 0.03389213 -0.03947259  0.04870733 ...  0.04278833 -0.04859842
   0.05873284]
 [-0.00221147  0.00093214 -0.00012413 ... -0.03003442  0.03117342
  -0.04015609]]
layers.1.weight: [[-2.41571832e-02 -2.09750030e-02 -4.57461830e-03 ... -1.11090895e-02
  -1.16884327e+00 -2.37779524e-02]
 [-1.10780317e-02 -2.48931232e-03 -1.85915977e-02 ...  4.03791713e-03
  -9.70358849e-02 -2.06585303e-02]
 [ 1.05601747e-03  5.82819979e-04  7.76603876e-04 ...  0.00000000e+00
  -8.38248699e-04  1.41512218e-03]
 ...
 [ 1.32744457e-03  7.59084243e-04  9.91723733e-04 ...  0.00000000e+00
  -9.21821978e-04  1.75892387e-03]
 [ 9.31838993e-04  5.02004288e-04  6.78091310e-04 ...  0.00000000e+00
  -8.01744987e-04  1.25795580e-03]
 [ 1.05313095e-03  5.80975844e-04  7.74357875e-04 ...  0.00000000e+00
  -8.37387168e-04  1.41146849e-03]]
layers.2.weight: [[-2.7691498  -2.0334036   0.04546467  0.05028703  0.05297447  0.03990364
   0.05358677  3.3783796   0.04544051  0.5111114   0.05002141  0.04511117
   0.04560874  0.04421571  0.05051235 -2.2051866   0.03941723  0.04198753
   0.04611489  0.05136189  0.04459959  0.06396321  0.04445688 -7.647436
   0.05477336  0.04488402  0.0506536   0.04493046  0.04450917  0.052198
   0.0423991   0.04539495]]

Final Loss: 0.3098
Distance Metric: 30.7406
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 2855

================================================================================

baselineCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.         -0.00011312 ...  0.00010392  0.00013329
   0.        ]
 [ 0.          0.00012739  0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.00016095 ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.2.weight: [[-0.00024688  0.00065433 -0.0001357  -0.00025341  0.00019838  0.00038259
  -0.00019251  0.         -0.00012944 -0.00040561  0.00011353  0.00042274
   0.00063677  0.0004929   0.00013336  0.         -0.0007296  -0.00036567
   0.         -0.00047697  0.         -0.00012409 -0.00052359 -0.00047778
  -0.00016517  0.00032174 -0.00020704 -0.00038319  0.00010876 -0.00034119
  -0.00059462  0.00016923]]

Final Loss: 0.3523
Distance Metric: 3.6419
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 885

================================================================================

baselineCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.00727622 -0.00803738  0.00068561 ... -0.00450592 -0.00507625
   0.00041663]
 [-0.00260953 -0.00297031  0.00024551 ... -0.00725822 -0.00811852
   0.00069255]
 [ 0.00185834  0.00194999 -0.00018391 ... -0.00561118 -0.00622583
   0.00053872]
 ...
 [-0.0009348  -0.0010114   0.         ...  0.00071418  0.00080892
   0.        ]
 [-0.00230923 -0.0025662   0.0002207  ... -0.00234877 -0.00264572
   0.00022295]
 [ 0.00207822  0.00223217 -0.00019927 ... -0.00289065 -0.00320297
   0.00028035]]
layers.1.weight: [[-0.00047519 -0.00084733 -0.00051312 ...  0.00021501 -0.00032498
  -0.00029141]
 [-0.00045288 -0.00080872 -0.00048958 ...  0.00020575 -0.00031019
  -0.00027824]
 [-0.00047167 -0.00084125 -0.0005094  ...  0.00021356 -0.00032263
  -0.00028933]
 ...
 [-0.00044258 -0.00079086 -0.00047871 ...  0.00020143 -0.00030335
  -0.00027213]
 [ 0.00023798  0.00042956  0.00025981 ... -0.00011111  0.00016472
   0.00014834]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.2.weight: [[-0.1215523  -0.11652661 -0.12076633 -0.11954349  0.3538356  -0.14132129
   0.117191   -0.11810913 -0.11690689  0.12128813 -0.10120878  0.10412477
   0.08932613 -0.7428895  -0.11017276 -0.06593534 -0.13014354  0.7290995
  -0.05261648  0.09225585 -0.10763533  0.05324178 -0.11238823  0.12069151
  -0.11935776 -0.12395281  0.02109492  0.01340397  0.35257086 -0.11416723
   0.06362297 -0.0019381 ]]

Final Loss: 0.0001
Distance Metric: 6.6935
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 2834

================================================================================

baselineCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.00013533 ...  0.          0.
  -0.00013376]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[-0.00010735  0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.00010147  0.
  -0.0001574 ]
 [ 0.          0.          0.         ...  0.00014101  0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.00011759  0.
  -0.00030453]
 [-0.00013013  0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.00016163 ...  0.         -0.00016195
   0.        ]]
layers.2.weight: [[ 0.00022991 -0.0001072  -0.00035986  0.00120842 -0.00032091 -0.00047064
   0.          0.00011009 -0.0001986   0.         -0.00051926 -0.00094572
   0.00024794  0.00018529 -0.00022036  0.00022817 -0.00048048 -0.00039908
   0.         -0.00075418 -0.00085183 -0.00050206 -0.00017803  0.00103446
  -0.00032826  0.00019252  0.00012775  0.00095654  0.00047507 -0.00119644
   0.00037147  0.00022699]]

Final Loss: 4.8963
Distance Metric: 7.0351
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 838

================================================================================

baselineCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.05461565 -0.05614881  0.0216638  ...  0.01813569 -0.02885654
   0.01243662]
 [ 0.06954963 -0.07268442  0.0287811  ...  0.04421765 -0.05712278
   0.02201832]
 [ 0.0111283  -0.00625866  0.0033517  ... -0.01517668  0.00697566
  -0.00328486]
 ...
 [ 0.04134089 -0.04191053  0.01671922 ...  0.01198837 -0.02229983
   0.00972891]
 [ 0.00070245  0.00456395  0.0002161  ... -0.01294599  0.00391475
  -0.00266125]
 [ 0.02971407 -0.02557763  0.00966521 ... -0.01009153  0.00125991
  -0.0007818 ]]
layers.1.weight: [[-0.03993447 -0.05854308  0.01291005 ... -0.02397128  0.02598005
  -0.00927439]
 [ 0.00420143  0.00497217  0.00167754 ...  0.00363801  0.00140155
   0.0023867 ]
 [ 0.01570655  0.02005955  0.00595674 ...  0.013991    0.00602505
   0.00766526]
 ...
 [-0.00108787 -0.00111222 -0.00097834 ... -0.00106005 -0.00095789
  -0.00101641]
 [ 0.00516754  0.00612338  0.00212623 ...  0.00449931  0.00181937
   0.00295704]
 [ 0.00466322  0.00552019  0.00189306 ...  0.00404932  0.00160075
   0.00266161]]
layers.2.weight: [[ 5.586219   -0.42311773 -1.3962599  -3.6819837   0.88142776 -1.6961075
   3.7004666   0.55954385  0.08596823 -0.15280628 -1.3297213   0.3762852
   3.6545799   1.0797977   0.85331064 -0.5308583   3.5423563  -0.549905
  -0.45211202 -6.659089    0.48237458  0.5977459  -0.59288484  1.4402707
  -2.903539   -4.8569417  -1.377296    1.0592635  -0.63936645  0.01740401
  -0.51148957 -0.46517602]]

Final Loss: 3.2777
Distance Metric: 39.6925
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 1745

================================================================================

