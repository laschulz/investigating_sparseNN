Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[ 0.9141675  0.6294384 -0.6204891]]]
layers.1.weight: [[[ 1.1834604  -0.79461116]]]
layers.2.weight: [[[-1.047713   -0.25362793]]]

================================================================================

baselineCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.11596186  0.00677078 -0.08091039 ... -0.05176969  0.00616657
  -0.10863377]
 [ 0.00922803  0.03607019 -0.08825684 ... -0.14987677  0.01111806
   0.10594703]
 [ 0.19296613  0.19927053 -0.17685951 ...  0.14763372 -0.03509612
   0.04536061]
 ...
 [ 0.06292178 -0.12381174 -0.0950136  ... -0.130212   -0.04501738
   0.10529177]
 [-0.07743075 -0.01626467 -0.06760845 ...  0.16145594  0.14734384
  -0.11584323]
 [ 0.09763394 -0.02126503 -0.09160304 ...  0.08360394  0.126172
   0.01929472]]
layers.1.weight: [[ 0.03409196 -0.0453313  -0.00865284 ...  0.11624423  0.02508534
   0.02123021]
 [-0.12145557  0.02744355 -0.1359557  ... -0.05208448  0.06775038
  -0.01172222]
 [-0.06441421  0.1351323  -0.01767982 ...  0.00177891 -0.02447727
   0.05625   ]
 ...
 [-0.11178102  0.01271593  0.11260631 ... -0.06174042 -0.13239111
   0.04158948]
 [ 0.03867204  0.02603188  0.1114182  ...  0.08969495 -0.14055245
  -0.01123075]
 [-0.06695063  0.04990947  0.06655028 ...  0.03193391  0.01013912
   0.13669677]]
layers.2.weight: [[-0.4340927   0.33287913  0.37302172  0.40117955  0.2080161   0.10444993
  -0.20070389  0.22619326 -0.02435437  0.47425976 -0.13654926 -0.19570936
   0.02635212 -0.309842   -0.23290946  0.03101085  0.27943176  0.08254314
  -0.08537438  0.10606964  0.25275367  0.19248322 -0.41434658 -0.00390553
   0.17641155 -0.63091755 -0.11006472  0.08531731 -0.4288768  -0.30198264
   0.16680971 -0.53056353]]

Final Loss: 0.0000
Distance Metric: 15.7135
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 1999

================================================================================

baselineCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.01529323  0.06309035 -0.0557071  ... -0.02612596  0.01263146
  -0.02913882]
 [ 0.00089144 -0.15462449  0.13254905 ...  0.0785742  -0.02236757
  -0.15308587]
 [ 0.09936672 -0.09574034 -0.08210564 ...  0.06378649  0.01196794
  -0.05163131]
 ...
 [-0.07017232 -0.00397302  0.04844194 ...  0.04862936  0.06150832
  -0.05531839]
 [-0.05109058  0.09134673  0.08240531 ...  0.07015604  0.24830571
  -0.03982739]
 [-0.02669867 -0.00516244  0.07061228 ... -0.22317706 -0.00801126
  -0.0010344 ]]
layers.1.weight: [[-0.16710475  0.03253261  0.2487432  ...  0.0973589   0.4644668
  -0.11007323]
 [ 0.05705134  0.46677    -0.29829398 ...  0.2346913  -0.2344821
  -0.00380676]
 [ 0.06745856  0.2824145  -0.08551038 ...  0.04121376  0.17182338
  -0.24981907]
 ...
 [-0.11746721  0.02655424 -0.13690715 ...  0.61796254 -0.15901807
  -0.0788308 ]
 [-0.06468211 -0.19217981 -0.40363464 ...  0.07224295  0.02599264
  -0.19028027]
 [ 0.27945444 -0.25552136 -0.12535296 ... -0.31071657 -0.04966981
   0.12073562]]
layers.2.weight: [[-2.4654489  -0.16234294 -0.16676249  0.3382878   1.2182137  -2.2098408
  -1.3516219   0.28780267 -0.5001479   0.29791868 -1.1891211  -0.00702777
   1.9567498   1.3850672  -0.9347626  -1.2760897  -0.31566992  0.7740497
  -1.6189605   1.8641411  -1.5160847  -1.8021636   0.83038795  0.46688232
  -2.661329    1.193076   -0.9359573  -1.9279666  -2.8013146   0.68025684
   0.66537094  0.579346  ]]

Final Loss: 0.2464
Distance Metric: 37.0501
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 295

================================================================================

baselineCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.10660227  0.15714718 -0.04333931 ... -0.41055566 -0.23703204
  -0.15541358]
 [ 0.33092228 -0.12451076  0.11815614 ...  1.5215392   0.74204934
  -1.9384434 ]
 [ 1.2546551   0.6845121   0.66392124 ... -1.0029562   2.522046
   2.0958612 ]
 ...
 [ 0.23944691 -0.30211258 -1.4300388  ...  0.32045275  0.36088786
   0.08359316]
 [ 0.592604    0.94258106  3.064885   ...  1.1018007  -3.2544606
  -0.6827403 ]
 [-1.6627139  -4.5112762  -0.60925627 ...  2.896254    0.47282773
   0.0984816 ]]
layers.1.weight: [[ 0.01268119 -0.01093616  0.00770479 ...  0.01178472 -0.00869635
   0.01281265]
 [ 0.23982336 -0.27369583 -1.1927067  ... -0.42082003 -1.0330675
   0.04051451]
 [-0.1267169   0.54345065 -0.24332877 ... -0.41642517  0.58434075
   0.05385153]
 ...
 [ 0.02902534  0.05799063 -0.00607184 ... -0.01731205  0.00632786
   0.00656699]
 [-0.02072519  0.02384454  0.03415791 ... -0.01662439  0.01451937
  -0.02573333]
 [ 0.04089848 -0.0014617  -0.00831947 ...  0.02645037  0.01976637
  -0.01195397]]
layers.2.weight: [[-1.4691538e-02  1.5263800e-01 -9.1730423e-02  1.8287823e-02
  -1.1525415e-02 -7.2449900e-02 -1.3824619e-02  1.4368600e-01
   1.9200506e-02  2.6902847e-02 -1.1880821e-01  5.6037707e-03
   2.9944886e-02  1.1792723e-02 -1.5562454e-02 -3.6236190e-03
  -7.5733028e-03 -6.1783649e-04 -1.2957901e-02 -1.8237005e-01
  -2.8680488e-03 -2.5840037e-04  1.6127972e-02 -7.7142091e-03
  -2.6687225e-03  1.1692518e-04  5.2920529e-03 -1.4395573e-02
  -4.4926558e-02 -1.9449797e-02  1.5441922e-03  1.4466761e-02]]

Final Loss: 0.1869
Distance Metric: 102.0802
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 1999

================================================================================

