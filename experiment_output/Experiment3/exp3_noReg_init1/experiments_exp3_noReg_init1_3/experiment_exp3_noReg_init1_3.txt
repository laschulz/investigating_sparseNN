Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.50010145 -0.15296769 -0.12133324]]]
layers.1.weight: [[[-1.1361446  -0.39026177]]]
layers.2.weight: [[[-0.1034214  0.67912  ]]]

================================================================================

baselineCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.12281943  0.1005003  -0.10581652 ...  0.07391732 -0.04625219
   0.08328491]
 [-0.1364231  -0.02044082  0.14579977 ... -0.01199657 -0.06294554
   0.12545648]
 [-0.04900296  0.02910212 -0.11675338 ...  0.09627519  0.09532732
   0.06322315]
 ...
 [ 0.07054867 -0.04304327  0.00950203 ... -0.13364291 -0.02610008
  -0.13507283]
 [-0.14125474 -0.06434095  0.08343733 ...  0.03875443  0.13162813
  -0.04547865]
 [ 0.07223608  0.13966388  0.14689283 ... -0.04211019  0.14087613
   0.11568819]]
layers.1.weight: [[-0.00968303 -0.10245164 -0.08078627 ...  0.1353015   0.06727152
   0.0181799 ]
 [-0.13141805 -0.04679543 -0.06461474 ... -0.07367187 -0.0930762
   0.10269817]
 [-0.04583022 -0.0438558   0.11457641 ...  0.13033025 -0.07031085
  -0.06902817]
 ...
 [-0.02730492 -0.01669443  0.1081434  ...  0.04856058  0.07426063
  -0.0497583 ]
 [-0.01660034 -0.08282069  0.09327774 ...  0.10968521 -0.07863844
  -0.02762985]
 [ 0.03209259 -0.00855575  0.0656232  ... -0.03587527  0.03770291
  -0.0039965 ]]
layers.2.weight: [[-0.36945376  0.01445177 -0.41270277  0.19744477  0.40046653  0.26000667
  -0.09569833 -0.08415093  0.3382575  -0.00805787 -0.19967413  0.03950303
   0.10118519 -0.3285401   0.30330086 -0.08858929  0.12724806 -0.26598927
  -0.35822    -0.31282318 -0.18064645  0.2981311   0.3104581   0.08194809
  -0.15694065  0.22960214 -0.01310124  0.22074512 -0.37530002  0.21580172
   0.04381095  0.2015717 ]]

Final Loss: 0.0000
Distance Metric: 15.1894
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 1999

================================================================================

baselineCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-2.39182636e-01 -4.88933548e-02  1.29567593e-01 ... -7.01867342e-02
  -1.27967641e-01  2.47048765e-01]
 [ 2.35456333e-01 -5.39446175e-02  5.26345134e-01 ... -2.87371725e-01
  -4.02662396e-01  9.55993012e-02]
 [-2.79342145e-01 -1.61901221e-03  2.44964257e-01 ... -1.45615086e-01
   2.45347008e-01 -2.79296070e-01]
 ...
 [-1.64876372e-01 -3.07726121e-04 -9.23787206e-02 ...  1.14534564e-01
   9.55245718e-02 -7.88364261e-02]
 [-2.97726959e-01 -2.59331644e-01  3.24149609e-01 ...  4.10294890e-01
   1.80205718e-01  2.56730407e-01]
 [-6.78136423e-02 -3.61195266e-01  3.07183832e-01 ...  9.20717046e-02
   1.49670348e-01  2.76617408e-01]]
layers.1.weight: [[-0.27582613 -0.25203326 -0.21788402 ... -0.34841198 -0.32257646
  -0.0752158 ]
 [-0.10007454 -0.06790996 -0.20984264 ...  0.285447   -0.35873988
  -0.20453237]
 [-0.19551821 -0.06332328  0.39553794 ... -0.31762925  0.07007433
  -0.08295743]
 ...
 [ 0.28302127  0.09506627  0.08783665 ... -0.5705432   0.6590704
  -0.04137126]
 [-0.11048556 -0.12849844 -0.4094933  ... -0.23030303 -0.3993787
   0.00066068]
 [ 0.01118113 -0.44062     0.18436444 ...  0.10328244  0.14494027
   0.2852219 ]]
layers.2.weight: [[ 1.4370735  -0.36505556 -0.17696781 -0.2541809  -0.22035114 -1.1566077
   2.6793427  -0.32940155  0.5100414   2.8461113   2.519604    1.8789742
   2.6566036   0.39084676 -0.7260815  -0.68030494 -2.5542037   2.6020284
   0.18576197 -0.9990298  -1.4650049   1.3944088  -0.2653261   2.8976653
  -0.24158402  1.3159349  -1.7784598  -0.2268918  -1.0791097  -1.3937721
  -0.4482876   0.06053035]]

Final Loss: 0.4424
Distance Metric: 43.4408
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 115

================================================================================

baselineCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.42035007  1.3051387   1.225167   ...  0.9013446  -0.9306265
  -0.80896455]
 [-0.08123484 -0.17508255  0.16138422 ...  0.07854193 -0.15978885
  -0.02580605]
 [-1.1857449   1.517196   -2.8797274  ... -0.95958793  0.6802885
   1.6797017 ]
 ...
 [-0.11101967 -0.18285565 -0.01668139 ... -0.30046302 -0.06747013
  -0.11372753]
 [-0.07055281 -0.15738325  0.21819662 ...  0.01249842 -0.06081602
  -0.12586863]
 [ 0.74210775 -0.27370566  2.1607745  ...  0.21032053  1.4221917
   0.940311  ]]
layers.1.weight: [[-1.07677817e+00 -1.09418519e-01 -9.87356365e-01 ...  6.27407283e-02
  -8.27130899e-02 -1.17708123e+00]
 [-4.13046926e-02 -3.75895873e-02 -3.91746731e-03 ... -3.32267433e-02
   7.24146813e-02  8.25629570e-04]
 [ 1.10577764e-02 -1.79320313e-02 -1.11009860e-02 ... -1.85383111e-02
  -2.43437216e-02  1.09990351e-02]
 ...
 [ 1.72219896e+00 -1.18189536e-01  1.33524859e+00 ... -3.87800545e-01
  -3.40963662e-01  9.25454140e-01]
 [ 5.85658252e-02  1.80537123e-02  3.92783955e-02 ... -1.77601986e-02
  -9.00065303e-02 -1.51479458e-02]
 [ 1.40781258e-03 -5.61414883e-02 -1.28453793e-02 ...  2.83491444e-02
   4.66727689e-02 -8.36334657e-03]]
layers.2.weight: [[ 9.5246203e-02 -1.8859928e-02 -2.7176111e-03 -4.1404698e-02
   1.3863561e-02 -3.4028841e-03  3.8712646e-03  3.4084648e-04
   5.1547214e-02  1.1324750e-02  1.9430697e-02  1.1718582e-02
  -1.2011161e-01 -1.2551745e-02  2.1809766e-02 -4.3491114e-02
  -9.3817767e-03  1.2899158e-02 -2.4942802e-02 -2.6336348e-02
   8.9735478e-02 -2.5443442e-03 -1.8416587e-02  1.1025641e-02
   2.1797583e-02 -6.0744728e-03  1.0807996e-01 -1.4194177e-04
  -1.2030407e-02  2.2994018e-01 -9.0153232e-02 -7.2061792e-03]]

Final Loss: 0.2073
Distance Metric: 99.6910
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 1999

================================================================================

baselineCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.23940983  0.12015726 -0.10168061 ...  0.10160846  0.03564546
  -0.06820711]
 [-0.4241661  -0.15709208 -0.03389093 ... -0.15501198 -0.05913218
   0.06612165]
 [ 0.25248757  0.0253127   0.11774121 ... -0.36220667 -0.00569574
  -0.06139095]
 ...
 [ 0.13671316  0.12485024 -0.02429975 ... -0.32391948  0.04719005
  -0.13534077]
 [ 0.9335846   0.0025997   0.12408974 ...  0.04483314 -0.09398009
   0.02430275]
 [-0.06157387 -0.09712025 -0.10119316 ... -0.2643834  -0.1259038
   0.04654758]]
layers.1.weight: [[-0.12103035 -0.01472043 -0.10173263 ... -0.16609351 -0.14516671
   0.01801734]
 [-0.12118717  0.14424022 -0.14480528 ... -0.00701863  0.03153817
  -0.02763717]
 [-0.05076645  0.19357252  0.11750005 ...  0.11483515  0.14134823
   0.06223488]
 ...
 [-0.14342254  0.18105137 -0.14217316 ...  0.01574077  0.05195098
  -0.07570889]
 [ 0.08567162 -0.3159762   0.28721872 ...  0.10887337  0.2147178
   0.11457502]
 [-0.02286575  0.10831368 -0.06365754 ...  0.12314727 -0.16179588
  -0.13051888]]
layers.2.weight: [[-2.2225559  -1.656525   -1.818049   -1.2701832  -0.5685692   3.2233531
   4.1326017   0.70183384  4.830845    0.53748196 -3.8188658  -0.11146063
   2.792233   -1.9854947   2.3735032  -0.44413185 -2.6558135   3.8937175
  -0.0841106   1.0057492   1.108172    3.9821517  -3.1608305  -5.6703215
  -1.6180956  -0.8888371   4.622542    1.8255239   2.1680408  -1.3683118
   3.7788312  -0.6062216 ]]

Final Loss: 0.2310
Distance Metric: 59.0029
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 1999

================================================================================

baselineCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.14364277 -0.14171664 -0.14979854 ... -0.09886341  0.02929126
  -0.04751918]
 [ 0.2791474  -0.11779758 -0.04985917 ...  0.18315846 -0.07735812
   0.07541818]
 [-0.10906641 -0.00498312  0.00860657 ...  0.01607891  0.11091259
   0.1221939 ]
 ...
 [ 0.11183815 -0.06760968 -0.14521602 ... -0.17289238  0.28423244
   0.53621876]
 [ 0.02805542  0.06865003 -0.04852547 ... -0.12407695  0.04481234
  -0.08843856]
 [-0.10579716  0.02830504  0.07527075 ...  0.00939049 -0.05301351
  -0.27268705]]
layers.1.weight: [[-0.13195305  0.08957729  0.20681548 ...  0.3069496   0.55363667
  -0.16966859]
 [ 0.24419913  0.4061592   0.005389   ...  0.19023128 -0.38340995
   0.24433951]
 [-0.19971041 -0.87715137 -0.00549237 ... -0.04178698 -0.3901624
  -0.0951708 ]
 ...
 [-0.06468122  0.48019037  0.08647181 ... -0.16646987 -0.3259125
   0.20149566]
 [ 0.2680364   0.25481388 -0.5078362  ... -0.39211243 -0.15892072
  -0.604625  ]
 [ 0.28117222  0.43036884  0.19609646 ... -0.13365564  0.02687949
   0.1085306 ]]
layers.2.weight: [[ 7.8277647e-01 -1.2243657e+00  1.9725814e-01 -7.9797494e-01
  -1.3254991e+00  3.1626801e+00  1.9433957e+00 -2.3913405e+00
  -6.2322301e-01  7.5370558e-02  8.9433938e-01  6.6319412e-01
  -7.8382134e-01  3.4259260e-01 -1.3692838e+00 -2.2393374e-01
   2.1629210e-01 -1.6252316e+00  1.0439934e+00 -2.1748583e+00
  -3.9353570e-01  7.6516759e-01 -2.2265767e-03 -7.1663547e-01
   1.7791799e-01  1.6011534e+00 -1.2946838e+00 -4.7292334e-01
  -3.0253556e+00  1.6962553e+00 -1.3513701e-01  2.5343241e-02]]

Final Loss: 0.7364
Distance Metric: 41.4595
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 207

================================================================================

baselineCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-1.9930013   1.277543   -0.76115066 ... -0.04524698  0.17508097
   0.6687265 ]
 [-0.7279951  -1.0660034  -0.90192425 ...  0.90938723  0.21444418
  -1.8325082 ]
 [-0.7019907  -0.6488734   0.651004   ...  0.43617433  0.3381195
  -0.01477541]
 ...
 [-1.2378083  -0.3611326  -1.0888084  ...  2.2410858   1.2532877
   0.26142082]
 [-0.62462497 -0.30038103 -0.8982936  ... -0.32443234  0.19316466
   0.26242942]
 [-1.0754563  -1.3857266   0.43273932 ...  0.34213495  0.52184933
  -0.273852  ]]
layers.1.weight: [[ 1.5501704e-02  1.5411953e-02 -2.7155022e-03 ... -3.7059601e-02
   1.6042730e-02  1.3608797e-02]
 [ 5.1231700e-01  3.7802973e-01 -2.3455025e-01 ... -5.5669004e-01
   6.7654699e-02 -1.1358547e+00]
 [-1.6799837e-02 -9.1702510e-03  5.1030189e-02 ... -1.2243783e-02
  -2.1793235e-02  1.4911156e-02]
 ...
 [-1.7594554e-01  2.3521988e-01 -2.6129085e-01 ... -3.4812379e-01
   6.3782126e-01 -6.3153231e-01]
 [-2.9238448e-02 -1.3320985e-02  6.2203180e-02 ... -4.5708092e-03
  -2.7471676e-04 -7.3503521e-03]
 [ 8.0705035e-01  6.8675107e-01 -4.3657172e-01 ...  7.7073842e-01
  -4.8937538e-01  9.7916913e-01]]
layers.2.weight: [[-8.3172200e-03 -5.8420677e-02  1.0305816e-02 -6.6231570e-04
   2.5902838e-03  6.8449318e-02 -9.7807180e-03  3.7929511e-01
  -8.4378526e-02 -5.1957983e-01 -1.4194901e-03 -3.4645290e-04
  -3.8347813e-01 -2.0654981e-03  5.8768056e-02 -2.6955341e-03
   7.6104607e-03  5.7843763e-02  3.9912667e-02  5.8664583e-02
   7.0814617e-02 -5.2939422e-02 -3.3256894e-03 -2.8286462e-03
  -1.0448069e-02 -8.3234757e-02  4.8424318e-02  4.7597155e-01
  -7.1045302e-02  4.8726290e-02 -1.0100363e-02  5.9324231e-02]]

Final Loss: 0.0777
Distance Metric: 104.4319
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 1999

================================================================================

baselineCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.04959695 -0.04379364 -0.0279716  ...  0.04744258  0.06801784
  -0.09486704]
 [-0.45644203 -0.01423668  0.25507903 ...  0.03314589 -0.06337277
  -0.06193923]
 [ 0.3454076   0.17439625 -0.13077264 ...  0.09267882  0.01188554
   0.13639797]
 ...
 [-0.02690777  0.06296813  0.07585672 ...  0.08151579  0.13098723
  -0.04384182]
 [ 0.28156242  0.17554381 -0.18259788 ...  0.11828691 -0.09351441
   0.07380251]
 [-0.7208001  -0.1883055   0.3216219  ...  0.01283294 -0.0790049
  -0.12275725]]
layers.1.weight: [[ 0.09984413 -0.00411369 -0.08006719 ...  0.09217545  0.04976756
   0.189855  ]
 [-0.0197203   0.04744465  0.10217515 ... -0.00225937  0.10931505
   0.16586399]
 [ 0.04520332  0.05832513  0.07656982 ...  0.11287981 -0.1316446
   0.19255652]
 ...
 [ 0.01229973 -0.10213589 -0.11740756 ...  0.0845583  -0.0527539
   0.05819812]
 [-0.0339128  -0.05404938  0.06950001 ...  0.04901919  0.05308231
   0.00143005]
 [ 0.11775734 -0.01326412  0.02818098 ... -0.09020131  0.01721427
  -0.23646785]]
layers.2.weight: [[-0.6681157   0.6145086   0.68447554  0.52248377  0.63267165 -3.7167468
   0.72619605 -2.1429973  -5.2863545  -2.5759442  -1.4041579  -2.141885
  -0.72747606 -1.2877026   0.701339    0.26714352  0.34739852  0.37690958
  -0.67163205 -1.5984023  -0.2696888  -1.6160157  -7.9950986   3.331858
  -0.9600947  -2.0731404   0.5872974  -0.72297376 -1.0014377   0.55957377
   0.02956779 -2.574443  ]]

Final Loss: 0.1992
Distance Metric: 49.0676
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 1999

================================================================================

baselineCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-0.22914208 -0.08708736  0.1125237  ... -0.08887424 -0.06587723
   0.19408391]
 [ 0.27366763 -0.08746062  0.5804774  ... -0.29394078 -0.42719325
   0.05407121]
 [-0.28077972 -0.03383373  0.23079003 ... -0.16745518  0.21181768
  -0.27468047]
 ...
 [-0.1237748  -0.00475867 -0.09509745 ...  0.12919272  0.11736906
  -0.15496783]
 [-0.27223396 -0.31366694  0.32825857 ...  0.422228    0.24713324
   0.18853126]
 [-0.03092794 -0.41074923  0.2650195  ...  0.09096294  0.23878577
   0.18060926]]
layers.1.weight: [[-2.88702458e-01 -2.60996580e-01 -2.29134172e-01 ... -3.58342201e-01
  -3.28976274e-01 -7.47887269e-02]
 [-1.00479506e-01 -6.79226220e-02 -2.11650759e-01 ...  2.85044700e-01
  -3.61819744e-01 -2.04775080e-01]
 [-1.95220321e-01 -6.27934337e-02  3.96433264e-01 ... -3.17982852e-01
   7.03256652e-02 -8.28637183e-02]
 ...
 [ 2.99745113e-01  1.02357633e-01  9.24434662e-02 ... -5.61833084e-01
   6.69513524e-01 -3.53771597e-02]
 [-1.10027455e-01 -1.27652064e-01 -4.08752531e-01 ... -2.29576632e-01
  -3.98768812e-01  5.22674003e-04]
 [ 1.09780617e-02 -4.40990299e-01  1.84268326e-01 ...  1.02706842e-01
   1.43661320e-01  2.84765542e-01]]
layers.2.weight: [[ 1.3965518  -0.3987379  -0.18652819 -0.31278044 -0.2119916  -1.1831776
   2.666617   -0.35306087  0.5070144   2.841831    2.4949963   1.8573046
   2.671142    0.38096377 -0.7238033  -0.7017541  -2.5778165   2.59386
   0.11953941 -1.0049675  -1.5290636   1.3930281  -0.28254405  2.8993082
  -0.24772038  1.3225666  -1.8357948  -0.27244037 -1.099934   -1.4110892
  -0.46148774  0.05896501]]

Final Loss: 0.3984
Distance Metric: 45.1682
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 227

================================================================================

baselineCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.11020448 -0.00689532  0.0787923  ... -0.0468338  -0.03040223
   0.0292539 ]
 [ 0.1459403   0.17392342 -0.04000492 ... -0.10802622  0.08026581
  -0.04323548]
 [-0.01419227 -0.07023778 -0.01251685 ...  0.16293143 -0.14166965
   0.04907996]
 ...
 [ 0.07976755 -0.10430815  0.06122854 ...  0.01049262  0.07588983
   0.11129772]
 [ 0.19640681 -0.22653666 -0.14266025 ... -0.06582208  0.05370279
  -0.13463815]
 [ 0.03534669  0.08707079 -0.03864255 ...  0.17674203  0.07191505
   0.06383045]]
layers.1.weight: [[-0.22092815 -0.20459834  0.11816432 ... -0.08769064 -0.13167751
  -0.21262033]
 [ 0.05101221  0.0233217  -0.19206783 ...  0.09524061 -0.257079
  -0.12464989]
 [-0.0289514  -0.2183477  -0.05163239 ...  0.14491488  0.03233124
  -0.16695167]
 ...
 [-0.0597811   0.16800538  0.18009005 ... -0.00532229 -0.21350287
  -0.05104056]
 [-0.17307892  0.13949235  0.05220746 ... -0.12183035 -0.09260603
   0.10459629]
 [ 0.03760625 -0.11511864 -0.01235727 ...  0.04232634  0.07023898
   0.04651596]]
layers.2.weight: [[ 0.00266021  0.03095128  0.          0.05039026 -0.33302525  0.00378652
   0.00069941 -0.3663742   0.00129304 -0.00671378 -0.00086938 -0.36623433
  -0.0188336  -0.00169051 -0.00048508 -0.0180281  -0.00700335 -0.00166586
   0.08134232  0.00095842  0.          0.00276264  0.06823856  0.02969656
  -0.0009366   0.          0.00632285 -0.0006504   0.40806797 -0.00914895
   0.01106527 -0.00153644]]

Final Loss: 0.0000
Distance Metric: 21.4467
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 1999

================================================================================

