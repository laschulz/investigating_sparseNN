Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.8619791   0.6471946  -0.02870202]]]
layers.1.weight: [[[-0.21061355 -0.63530934]]]
layers.2.weight: [[[0.9009663 1.2001948]]]

================================================================================

baselineCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.11133331  0.04992704  0.03332576 ...  0.06426405 -0.08625031
  -0.12731989]
 [ 0.00476537  0.13408156  0.05459895 ... -0.09397274  0.13040094
   0.01982615]
 [-0.12416809  0.00149041 -0.14498633 ... -0.08762262  0.08251482
  -0.13959593]
 ...
 [ 0.10611355 -0.05151505  0.08840327 ...  0.04842862  0.10821396
   0.10828859]
 [-0.10913204  0.06627876 -0.05701423 ...  0.04895632  0.03612565
  -0.12607265]
 [-0.01080867  0.11161006  0.13901557 ...  0.12347119 -0.09209455
   0.13066186]]
layers.1.weight: [[-0.04122416 -0.0376389   0.07772304 ...  0.0991145   0.10536114
  -0.03620651]
 [-0.03798727 -0.00696536  0.08101164 ...  0.05576617  0.0429744
  -0.0947103 ]
 [ 0.04634808 -0.10944711  0.13272534 ... -0.057294   -0.06113293
   0.10454381]
 ...
 [ 0.00918463 -0.00747974  0.04367965 ... -0.03880311  0.11230525
  -0.05518609]
 [-0.13642435 -0.09676541  0.1369944  ...  0.12343862  0.1092151
   0.02467678]
 [-0.07206967  0.03168397  0.14101838 ...  0.06870191  0.02394038
   0.01786017]]
layers.2.weight: [[-0.13222998 -0.12840207  0.3689088   0.37251544 -0.27416158  0.10463694
   0.41687617  0.05966961  0.36437887 -0.22702798  0.26268652  0.13253234
  -0.272088    0.22033027 -0.15111504  0.46012357  0.36043626  0.24661787
  -0.35802847  0.16653179 -0.19603373 -0.25504804  0.02007648 -0.3039431
   0.35521913  0.29129538 -0.13644081 -0.3736291  -0.3251642  -0.29415336
  -0.2956919   0.00300055]]

Final Loss: 0.0000
Distance Metric: 15.7474
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 1999

================================================================================

baselineCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.05419131  0.00413741  0.41042572 ... -0.22918521  0.00395408
  -0.11436267]
 [-0.12464753  0.4338595   0.3051624  ... -0.12162495  0.29201245
  -0.06693248]
 [-0.0708655   0.2828372   0.37275115 ...  0.01241231 -0.09799802
   0.05791448]
 ...
 [-0.1255988  -0.35724273 -0.10246983 ...  0.03695565  0.18189164
  -0.09771591]
 [-0.16573492  0.20633104  0.06409603 ... -0.16622823  0.09560166
   0.3512696 ]
 [-0.10583003 -0.17075321  0.17686754 ...  0.1599803   0.1059261
   0.29190487]]
layers.1.weight: [[-0.01269134  0.80289656 -0.30843627 ...  0.12511957 -0.06700978
   0.5193164 ]
 [-0.22882527 -0.3611597   0.21172911 ... -0.7354196   0.05861002
  -0.2409772 ]
 [ 0.07627335  0.17399985 -0.3581711  ... -0.5121543   0.36829036
  -0.0014567 ]
 ...
 [ 0.16130991 -0.04249441  0.18723422 ... -0.5007403  -0.26084098
  -0.24410595]
 [-0.4573345  -0.2923142  -0.1436365  ...  0.04683899  0.22967131
  -0.094213  ]
 [ 0.05644735 -0.1082718   0.32582426 ...  0.05956499  0.10941467
   0.0217663 ]]
layers.2.weight: [[-1.615029    1.9498754  -0.17079766 -1.0115129  -1.0716242   2.86154
  -1.908759   -2.7640235  -1.6840653  -1.0733027  -1.8029313   0.22626156
  -1.5324569  -1.6649935  -0.67847466  0.7276828   2.3762872   1.6713281
   2.0257645   0.06441236 -1.1540891   0.8841652  -0.9065199   2.16865
  -0.31386986 -1.3149656  -0.2779986  -0.9275303  -0.20950785  1.6125264
  -0.13577013 -0.73058575]]

Final Loss: 0.3264
Distance Metric: 45.8931
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 226

================================================================================

baselineCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-3.1653896e-02 -3.3210527e-02 -5.2253017e-03 ... -2.7653549e-03
  -1.9597471e-02  3.0448835e-02]
 [-1.0399933e-01 -2.0920945e-02 -1.7798293e-02 ...  2.9821252e-02
  -4.3916211e-02  1.6902540e-02]
 [ 9.9771589e-02  2.2075132e-02  1.8800862e-02 ... -2.2134466e-02
   4.0769868e-02 -2.7407466e-02]
 ...
 [ 7.2526234e-01  5.5296224e-01  3.1753874e+00 ... -1.0090862e-01
  -4.0892739e+00  3.3505514e-01]
 [-7.5683035e-02  1.1243662e-02 -8.5338596e-03 ...  3.8251519e-02
  -3.3757843e-02 -4.5307666e-02]
 [ 3.7662259e-01 -3.0526221e-01  3.2968843e+00 ... -1.7163036e+00
   1.0341902e+00  1.0356014e+00]]
layers.1.weight: [[ 0.00482972  0.00309661 -0.00176077 ... -0.00380199 -0.00120238
  -0.00152271]
 [-0.00406622 -0.00265324  0.00423202 ...  0.01585951  0.00122229
   0.05864479]
 [-0.00105496 -0.00136255  0.00270292 ... -0.02162793  0.00023089
  -0.01518838]
 ...
 [-0.03301641 -0.0270249   0.0306323  ...  0.12468863  0.00753144
  -0.17445712]
 [-0.00200056 -0.00333478  0.00373953 ... -0.01216006 -0.004966
  -0.030999  ]
 [-0.00323773  0.00299893 -0.00302586 ...  0.03095713  0.01032157
  -0.01259266]]
layers.2.weight: [[ 0.00659738 -0.01278092  0.01035768 -0.1385765  -0.19287594  0.02254834
   0.00516512 -0.01818056 -0.04534509 -0.01900306  0.17043231  0.01550944
   0.03105907 -0.00545073 -0.03121783 -0.01456564 -0.04851187 -0.0569746
  -0.00348838  0.00500686 -0.02491362  0.04310389 -0.02881029  0.00673607
  -0.01371146  0.06333563  0.02350538  0.01089142 -0.02599285  0.04170278
   0.02897132  0.03138516]]

Final Loss: 0.4906
Distance Metric: 104.4834
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 1999

================================================================================

baselineCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.14422241 -0.12926064 -0.05344918 ... -0.07629458  0.06194047
  -0.01810512]
 [ 0.01607462  0.13399024 -0.102508   ... -0.08807596 -0.01473318
   0.09833495]
 [ 0.10276552 -0.03753038 -0.09325689 ... -0.09620003 -0.14131941
  -0.14333463]
 ...
 [-0.09011894  0.06550068 -0.10160069 ... -0.10803432 -0.13237078
   0.10109682]
 [-0.02693523  0.14552838 -0.00414052 ... -0.08775504  0.1430777
   0.00412928]
 [-0.11752567  0.0322952  -0.03014702 ... -0.11134155 -0.05908857
  -0.04500589]]
layers.1.weight: [[-0.15093255 -0.03710825 -0.00390625 ... -0.0376585   0.00426744
  -0.09103619]
 [-0.03859602 -0.14374879 -0.00390625 ...  0.03880445  0.00680304
  -0.12367922]
 [ 0.14866234  0.03848972 -0.02132758 ...  0.11001068  0.1417965
  -0.12000343]
 ...
 [ 0.1203879   0.11907017 -0.13277029 ...  0.00566891  0.07098477
   0.03444452]
 [ 0.02495389 -0.04182974 -0.03315552 ... -0.10196884  0.08335849
   0.09018926]
 [-0.04833706  0.11165819  0.02298548 ...  0.00221661  0.10814656
   0.03932894]]
layers.2.weight: [[ 0.2869784   0.12824138 -0.5268183  -0.125       0.22661562 -0.309613
  -0.46696818  0.17257816 -0.04753843  0.07544105 -0.6636857  -0.5063829
   0.11244725 -0.87379587 -0.0561524   0.3035297   0.03748181 -0.7158127
   0.08513192 -0.275508   -0.73561114 -0.48027033  0.03024278 -0.7863953
  -0.3289032  -0.25       -0.6202722  -0.6352372  -0.25       -0.25
  -0.76490045  0.14658898]]

Final Loss: 0.0000
Distance Metric: 18.1995
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 1999

================================================================================

baselineCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.13553305 -0.14432937  0.05713292 ...  0.0865486   0.02594078
  -0.06740458]
 [-0.01586607  0.11478908  0.10745662 ... -0.08061328  0.00180657
   0.4382481 ]
 [-0.20377082 -0.06143742  0.15538815 ... -0.02912286  0.03400212
  -0.09518351]
 ...
 [-0.06853134 -0.29735655  0.3764259  ...  0.0736264   0.08700144
  -0.2864637 ]
 [ 0.01293236 -0.05365551  0.05763225 ...  0.          0.15173337
   0.05491898]
 [-0.14936283  0.33257186  0.18106872 ... -0.04755881  0.24828158
   0.10249632]]
layers.1.weight: [[ 0.0441691   0.11665013 -0.03559238 ...  0.195896   -0.0547359
   0.3054105 ]
 [ 0.03108036  0.01565599 -0.13557042 ... -0.23758452 -0.1793704
   0.07472515]
 [-0.6191392  -0.30717677  0.23168129 ... -0.12706637 -0.02949622
   0.07506597]
 ...
 [-0.04011332 -0.13402902 -0.02177597 ...  0.05967735 -0.5552331
  -0.33176428]
 [ 0.1491352  -0.21431994 -0.2886642  ... -0.05500985 -0.6636016
  -0.28924087]
 [-0.05056596 -0.34482977 -0.29685286 ... -0.04708653 -0.4647167
  -0.2763011 ]]
layers.2.weight: [[-0.22785431  0.33931503  0.8279245   0.9930268   1.4310092   1.6114793
  -0.45467636  2.466239   -3.6674151  -2.6516159   0.86854875  1.25371
  -2.787661    0.62592065 -1.5046402  -0.14612223 -3.153404   -0.55056703
   1.7097213  -0.31207195 -0.9273952  -1.6690985   2.7080135   0.01099096
  -0.9034209  -0.55117255  2.0770838   1.1068983  -0.23891635 -0.2556408
   2.1902332  -0.6412609 ]]

Final Loss: 0.0000
Distance Metric: 43.5952
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 101

================================================================================

baselineCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.44069365 -0.16787332  0.5358265  ... -0.29964623 -0.623391
   2.0455518 ]
 [ 0.314291    1.5383645   0.5521231  ...  0.644706   -0.43007645
  -0.38742074]
 [-0.05170943  0.2847995  -0.94047314 ... -0.07417616  0.5956773
  -0.7581421 ]
 ...
 [ 0.84760493 -1.7425019  -1.1849259  ...  1.685666   -0.5036319
   2.6699169 ]
 [-0.36779642  1.2585682  -0.64389956 ... -2.3529084  -1.7949004
   0.08897153]
 [-0.32278898 -0.35704434 -0.7732721  ...  0.48236737 -0.3599773
  -1.0040845 ]]
layers.1.weight: [[ 0.46287283 -1.1689458  -0.15657118 ... -0.5629504   1.8381156
  -0.5900704 ]
 [ 0.7714505   0.23553133  0.7444435  ... -0.44576284  0.82219964
   0.04119845]
 [-0.6139651   0.19891077 -0.37865788 ...  0.6017739   0.50259614
  -0.3482222 ]
 ...
 [-0.83213323 -0.63408744  0.01858361 ... -0.54640025 -0.29939792
   0.55533254]
 [ 0.15586844 -0.48341486  1.0465964  ...  0.7298154   0.43513656
   0.7801016 ]
 [ 0.06803289 -0.6140015  -1.3253164  ...  1.6546491  -0.7637839
  -0.2241808 ]]
layers.2.weight: [[ 0.15534273 -0.19939294 -0.07872185  0.4020469  -0.23920214 -0.07506678
  -0.48055214 -0.09487318  0.20036651  0.04774391  0.09998935  1.0813212
  -0.26276892  0.5103237  -0.39355212 -0.41593352  0.0904362  -0.07251469
   0.06805601 -0.04134477  0.36096793 -0.07894114  0.9248941  -0.41561028
   0.19017237 -0.3099368   0.39466542  0.6690973  -0.7038268   0.18827176
   0.06803939  0.4069883 ]]

Final Loss: 0.9641
Distance Metric: 176.0899
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 1999

================================================================================

baselineCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.37355936  0.26226774 -0.1773769  ...  0.12509933 -0.08622992
  -0.03733862]
 [ 0.22079997 -0.17450252  0.07159173 ... -0.02950289  0.13829544
  -0.10906436]
 [-0.6863545   0.3561084  -0.2945641  ...  0.06977831 -0.01327768
  -0.06238171]
 ...
 [ 0.07335974  0.07707748  0.01295662 ... -0.04943094  0.05506279
  -0.08378682]
 [-0.63693726  0.42416885 -0.1691656  ... -0.05790213  0.15144686
  -0.04634099]
 [-0.76319236  0.47272387 -0.31870666 ... -0.1031788   0.0561584
  -0.02243698]]
layers.1.weight: [[-0.02842     0.14526567  0.08579654 ... -0.10631884  0.05515904
  -0.11008672]
 [ 0.00156405  0.0410268   0.05456507 ...  0.03834445 -0.04958039
   0.08930594]
 [-0.33381498 -0.48730096 -0.0107754  ...  0.25612494 -0.25740317
  -0.6244618 ]
 ...
 [ 0.14630382 -0.14316143  0.27750757 ...  0.11711895  0.29640168
   0.31039438]
 [ 0.06992813 -0.04974431  0.10561966 ... -0.00415299 -0.06628917
   0.01818871]
 [-0.05202944  0.01834799  0.02746144 ...  0.0048177  -0.0749707
   0.15535416]]
layers.2.weight: [[-0.0690042   0.16914737 -2.8796566  -3.2256997  -1.2924536   0.6253321
  -0.7006429   0.61451     0.12934121  1.1883768   0.51254576 -1.1024767
   0.68499875  0.3273224  -0.6848683  -0.73639524  0.3228975   0.27190027
   0.7218277  -2.904719   -3.9999895   0.3300903  -1.2903658  -0.9852228
   1.3834639   1.0755296  -8.661598    0.6166431  -1.2508498  -1.748824
  -0.37565422  0.66262686]]

Final Loss: 0.3492
Distance Metric: 50.8029
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 1999

================================================================================

baselineCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.10142656 -0.05585229  0.40044096 ... -0.1864477  -0.0176224
  -0.14427012]
 [-0.13021958  0.46189147  0.26065418 ... -0.1378473   0.2765571
  -0.04051223]
 [-0.06294511  0.24332643  0.3354811  ...  0.09865366 -0.09703406
   0.0476165 ]
 ...
 [-0.17029062 -0.21967848 -0.2105401  ...  0.19265485  0.1338583
  -0.02545382]
 [-0.12230235  0.15924959  0.07573266 ... -0.14172052  0.12038799
   0.3327136 ]
 [-0.07709542 -0.21984972  0.16022506 ...  0.12321322  0.07931194
   0.3406629 ]]
layers.1.weight: [[-2.97503378e-02  8.05439889e-01 -3.07368249e-01 ...  1.32605135e-01
  -6.88354895e-02  5.15447259e-01]
 [-1.78417668e-01 -3.54328483e-01  2.21617803e-01 ... -7.53459334e-01
   6.27710670e-02 -2.33601019e-01]
 [ 8.00080150e-02  1.71833217e-01 -3.58891994e-01 ... -5.14798939e-01
   3.69652718e-01  2.11198392e-04]
 ...
 [ 1.90334707e-01 -5.51829375e-02  1.81303859e-01 ... -5.18752217e-01
  -2.60095030e-01 -2.41189584e-01]
 [-4.57299381e-01 -2.92430550e-01 -1.43648013e-01 ...  4.67853248e-02
   2.29687586e-01 -9.43020657e-02]
 [ 4.72025424e-02 -1.08639084e-01  3.25474411e-01 ...  6.33195713e-02
   1.09102644e-01  2.07270160e-02]]
layers.2.weight: [[-1.6368604   2.0357985  -0.13168022 -1.0121387  -1.0532335   2.8477676
  -1.921985   -2.7801497  -1.6780767  -1.0774628  -1.8002084   0.29738507
  -1.534865   -1.6961001  -0.68269503  0.8172301   2.4651341   1.7110617
   1.9982015   0.06087892 -1.1459239   0.95424694 -0.8311477   2.1732798
  -0.34070897 -1.3250488  -0.21784613 -0.94467807 -0.15507239  1.6531272
  -0.15003414 -0.7164374 ]]

Final Loss: 0.6999
Distance Metric: 45.9081
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 139

================================================================================

baselineCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.00873509 -0.00391642  0.0134036  ...  0.04425444  0.04275829
   0.01238567]
 [ 0.16300865 -0.11477908 -0.06283112 ... -0.09853182 -0.1108629
  -0.12677668]
 [ 0.1532153  -0.08351583 -0.00666126 ...  0.24636486  0.14786802
  -0.17700419]
 ...
 [ 0.15114416 -0.03441931  0.16149294 ...  0.15371448  0.03700389
   0.01096251]
 [-0.20624265 -0.05319055 -0.18245189 ...  0.1714489   0.22051422
  -0.13330269]
 [-0.06438388 -0.00877785  0.1769082  ...  0.12846886  0.11321872
  -0.15154947]]
layers.1.weight: [[-0.194415    0.05283424 -0.07135659 ... -0.14093325  0.01345588
  -0.07770378]
 [-0.12434758  0.07347519 -0.00885438 ...  0.01006412  0.01397347
   0.20044473]
 [ 0.15593894  0.01719755 -0.063686   ... -0.18687542 -0.04477995
   0.0309719 ]
 ...
 [ 0.19994283 -0.06612983  0.15966375 ... -0.0653998  -0.15093473
  -0.15362227]
 [-0.19948281 -0.11404983  0.03568368 ...  0.13774537 -0.2283076
  -0.14527947]
 [ 0.17056467 -0.16838783  0.15283127 ... -0.184241   -0.02059013
   0.17336753]]
layers.2.weight: [[ 7.8577213e-03  9.0540186e-02  9.1769658e-03  1.2136049e-03
   9.4836010e-03 -7.7450986e-04 -5.5124084e-03  2.3289020e-01
   5.3994614e-01 -1.5783718e-02 -3.5709897e-03  2.5305100e-02
   3.1734223e-03 -1.7673034e-03 -3.6414161e-02  3.4041950e-03
   8.6808382e-03 -1.9105769e-03  3.2637797e-03 -1.2895937e-02
  -5.9906226e-02  0.0000000e+00 -1.7354500e-02 -1.4878829e-02
   8.9323344e-03  1.1506772e-02  2.6708358e-04  1.6112572e-03
  -1.1622600e-03  2.0166373e-02  9.4204629e-03 -2.8645534e-03]]

Final Loss: 0.0000
Distance Metric: 20.6154
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 1999

================================================================================

