Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[ 0.41716588 -0.09472561  0.09452415]]]
layers.1.weight: [[[ 0.7615878 -0.5037247]]]
layers.2.weight: [[[-1.0615963   0.72377104]]]

================================================================================

baselineCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.06534284 -0.03738754 -0.03340278 ... -0.12713595 -0.04052057
  -0.01772981]
 [-0.03642821  0.11783864  0.02519765 ... -0.11264479 -0.07630508
   0.02842366]
 [-0.05575949  0.02506726 -0.10094012 ... -0.0202595  -0.11505207
   0.10752948]
 ...
 [ 0.13930666  0.05252035  0.10532971 ...  0.06458305 -0.12258196
  -0.12386639]
 [-0.07253212 -0.13222317 -0.02695999 ... -0.0540732  -0.05152523
   0.00504484]
 [-0.13235137 -0.11922209 -0.02271667 ...  0.11727461 -0.11210977
   0.10919631]]
layers.1.weight: [[-0.02934651 -0.10279319 -0.01274042 ... -0.08968588  0.06265195
   0.10788742]
 [-0.14533491  0.10712159 -0.01775604 ...  0.06946727 -0.00517786
  -0.02349173]
 [ 0.01507626  0.12050251 -0.00259284 ...  0.00518144  0.14273028
   0.08395252]
 ...
 [-0.10158027  0.07220253  0.09564453 ... -0.02207647 -0.00059373
   0.01159472]
 [-0.12896152 -0.00734328  0.06071651 ... -0.02056484  0.09204919
   0.04892796]
 [ 0.12149004 -0.002426    0.07090893 ...  0.02982238  0.0540992
  -0.04767776]]
layers.2.weight: [[ 0.01327099  0.39270398 -0.3349812   0.10154681  0.25287864  0.21855347
  -0.19963023 -0.35325524 -0.24360445  0.22043125  0.2904307  -0.23423018
  -0.02622099 -0.10745973 -0.19567613  0.21483727  0.3597291   0.20003456
   0.00713144 -0.01421562 -0.12558478 -0.06677065  0.05254955  0.28390223
  -0.30693454  0.22664154 -0.19820538 -0.01195086 -0.39082432  0.33271083
   0.26016292  0.31858295]]

Final Loss: 0.0000
Distance Metric: 15.2065
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 1
stopped after epoch: 1999

================================================================================

baselineCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-0.7099836   0.23469211  0.5273658  ... -0.2481377  -0.749892
  -0.36776063]
 [ 0.02995197 -0.22149359 -0.08063748 ...  0.03745901 -0.22106542
  -0.0576865 ]
 [ 0.28955686 -0.17497674  0.00640457 ... -0.05697018  0.11738421
  -0.05050947]
 ...
 [ 0.18595746  0.48561156 -0.03151991 ...  0.25208008 -0.04780759
   0.56010425]
 [ 0.28058264 -0.01652088 -0.27471137 ... -0.07397773  0.10669332
   0.18547116]
 [-0.02827871  0.06961675  0.01706965 ... -0.12515546 -0.03764962
   0.18652025]]
layers.1.weight: [[ 0.26595196 -0.16177002  0.05057966 ... -0.2364704  -0.12664345
   0.20009896]
 [-0.4013466  -0.0461205   0.20461357 ... -0.03244812 -0.18979076
   0.19062586]
 [-0.21296605  0.6293994   0.04132207 ...  0.20936391  0.13053995
   0.09867035]
 ...
 [ 0.16675334 -0.22498976 -0.02286879 ... -0.5346933  -0.11132165
   0.41169456]
 [ 0.00479503  0.05015462 -0.62575495 ... -0.34983638 -0.02853698
  -0.43783665]
 [-0.14979252 -0.03997556 -0.11437184 ... -0.08214179 -0.14448898
   0.12007684]]
layers.2.weight: [[ 0.8853843  -0.08322572 -1.1979743   3.469267    0.4454627   0.36777356
   1.6413157  -0.38537496 -0.71680933 -0.7449052  -2.3351364  -2.08621
   0.00865326 -0.45221555  0.21279447 -2.8834772   0.14341275 -1.467376
  -0.9080239   1.1120666   1.1431574   0.20364453 -0.93304074 -0.6842557
   0.77440405  0.34174225 -0.54439384 -0.7809262   0.10125241  0.84767073
   1.423545   -1.0600487 ]]

Final Loss: 0.0573
Distance Metric: 44.0369
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 1
stopped after epoch: 121

================================================================================

baselineCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 1.8265443e-01  3.0854649e-03 -2.6365256e-01 ...  1.0022720e+00
  -3.5520756e-01  3.0794716e-01]
 [-8.4703845e-01  6.7110175e-01 -7.3051763e-01 ... -5.4534954e-01
  -2.3157153e+00  1.0495460e+00]
 [-7.5114346e-01 -3.1260264e-01  1.4075457e-01 ...  1.4629032e-01
  -5.5266923e-01 -3.7518647e-01]
 ...
 [-4.4020557e-01 -8.2833564e-01  1.0431732e+00 ...  4.5798537e-01
  -2.5648525e-01  8.2769692e-01]
 [ 2.2663090e-01 -3.4441677e-04  4.0670371e-01 ...  1.1794443e+00
  -7.2196567e-01  9.8043382e-01]
 [-6.9376266e-01 -5.2536273e-01  2.7677560e-01 ... -1.0764995e+00
   4.3169603e-01 -5.6575471e-01]]
layers.1.weight: [[ 0.02061944 -0.01218091  0.01194323 ... -0.03294792 -0.01360449
  -0.02489481]
 [-0.00076368  0.00089766  0.07174975 ... -0.01938741 -0.00535179
  -0.03064147]
 [ 0.05022151  0.03121157  0.0320437  ... -0.0267645   0.01985106
  -0.02417052]
 ...
 [ 0.00386703 -0.02073208 -0.01411236 ...  0.02213176 -0.03480928
   0.0294864 ]
 [-0.02314387 -0.0052258   0.0394282  ... -0.0059797  -0.0049336
  -0.00819656]
 [ 0.00070034 -0.00373226  0.10530569 ... -0.03069177 -0.00402342
   0.00875546]]
layers.2.weight: [[-0.00943124  0.00519677 -0.00236153  0.00750445  0.01683954 -0.02091526
  -0.02217065 -0.00229073  0.00217549  0.00315582 -0.1055695   0.00057321
   0.0436714  -0.00652774  0.00961791 -0.05384175  0.02271392 -0.03297247
  -0.00521749  0.01658097  0.02285056  0.07079276 -0.0047694   0.02791633
   0.01487894 -0.00381543 -0.00681912  0.01444023 -0.10023775 -0.02187042
  -0.00142791 -0.00164213]]

Final Loss: 0.0755
Distance Metric: 63.6758
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 1
stopped after epoch: 1999

================================================================================

baselineCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.08980814  0.07427787  0.05042707 ... -0.10361839  0.4466208
   0.17617334]
 [-0.00929805  0.00995672  0.03456448 ...  1.4979256  -3.7337255
  -0.9704234 ]
 [ 0.071621   -0.01659739 -0.11367325 ...  0.15031448 -0.27035394
  -0.06357928]
 ...
 [-0.03384441  0.10946174  0.01837773 ...  0.1430921  -0.40858027
  -0.1392787 ]
 [ 0.06304308  0.1010507  -0.10445595 ... -0.01055981 -0.20980054
   0.12176615]
 [ 0.15329352 -0.12822963 -0.0974097  ... -0.1614868   0.20424466
  -0.07294455]]
layers.1.weight: [[-0.05734315  0.5988165   0.14438559 ...  0.20043965  0.04058905
  -0.04787286]
 [-0.04003767  0.42538986 -0.11174608 ...  0.20764965 -0.08927966
  -0.11577277]
 [ 0.05407415  2.2371697   0.13156246 ...  0.12216065  0.04403249
   0.09271048]
 ...
 [-0.08415332  0.18582201  0.11866608 ...  0.04764999 -0.04676461
  -0.09602363]
 [-0.13416648  0.0774997   0.04559417 ...  0.17585154 -0.16265815
  -0.07986838]
 [ 0.25472856 -0.4763633  -0.24947669 ... -0.14034337 -0.01125333
   0.13088505]]
layers.2.weight: [[ 2.2907538   1.6329666   4.963877   -3.6304398   4.616687   -0.8792023
   2.436982   -2.863169    1.590796   -1.5367703   0.4905739  -0.2419004
   1.3348116   1.8005153  -2.0325942  -0.45296386 -0.48237246 -0.01624104
   2.7017152  -3.5724156  -2.968063   -0.10230289  1.374638   -1.0992746
   1.9726601   1.7609767  -2.427504    2.122076    4.073629    1.935174
   1.816142    3.1428459 ]]

Final Loss: 0.4061
Distance Metric: 55.7434
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 1
stopped after epoch: 1999

================================================================================

baselineCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.09761919 -0.02885276  0.12478246 ... -0.33202228  0.03261249
  -0.2016223 ]
 [-0.09382883  0.3237459  -0.09785957 ...  0.111672   -0.23355557
   0.17114162]
 [-0.3419521   0.34911478  0.15014298 ... -0.01311032 -0.15287499
   0.18724069]
 ...
 [ 0.02217997 -0.02218509 -0.00297423 ... -0.04204419 -0.03895742
  -0.0225736 ]
 [-0.10921507 -0.10564592  0.1338204  ...  0.00386631 -0.00811145
  -0.14274803]
 [-0.12498893  0.4669869  -0.02639804 ...  0.24506575 -0.23087628
  -0.01316707]]
layers.1.weight: [[ 0.02140937  0.475014    0.6669132  ... -0.09314878 -0.03846324
   0.49615788]
 [-0.37380278 -0.4540792   0.20014478 ... -0.10716312 -0.11663301
  -0.02835617]
 [-0.8097971  -0.41835174 -0.12725475 ...  0.29389665 -0.02744967
  -0.56753886]
 ...
 [ 0.23005894 -0.09893554 -0.5048653  ...  0.01469511  0.20108543
   0.17767052]
 [ 0.07903838 -0.24134488  0.39045128 ... -0.01963602  0.44283867
   0.22573079]
 [ 0.20488709 -0.2767325   0.16357306 ... -0.24878676 -0.23542182
  -0.06450603]]
layers.2.weight: [[-2.3031042   1.1698909  -3.0933745  -0.39032367 -3.22267    -0.3963673
  -0.30279785  0.09473183  1.0552505   1.7083845  -1.1734434   0.14565673
   0.61067086 -0.10547604  1.9625572   1.0867282   1.2528815   0.62676924
   1.8831251  -0.13947047  0.69796264 -0.9013629  -0.8641714  -0.67853814
  -0.71006656 -1.245535    2.1774266  -0.46939358 -0.44784898 -0.9281378
  -2.079622    0.16270284]]

Final Loss: 1.1171
Distance Metric: 40.2283
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 1
stopped after epoch: 182

================================================================================

baselineCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.21242592  0.5550307  -0.53516525 ...  0.58854926  0.5240655
  -0.09044712]
 [-0.82342833 -0.04632597 -0.4655378  ... -0.09993419 -0.10600099
   0.4988526 ]
 [-0.04255205  0.7695416   0.2551042  ...  0.16534568  0.93233126
  -0.418256  ]
 ...
 [ 0.02086394 -0.04117378 -0.03473328 ...  0.09657601  0.17450298
  -0.18318307]
 [ 0.00962134 -0.03831439 -0.07899354 ...  0.0512554  -0.08333462
   0.16319433]
 [ 0.06307793  0.01148205  0.06451847 ...  0.03990353 -0.09393501
   0.16408771]]
layers.1.weight: [[-0.3049229  -0.05659106  0.1221923  ...  0.03234341  0.24309833
   0.136832  ]
 [-0.02693527 -0.02699684  0.0394352  ...  0.06921062 -0.01345231
   0.18620804]
 [-0.0498613  -0.01508965  0.04675093 ...  0.01132902  0.13510245
  -0.00868832]
 ...
 [ 0.72847635 -0.6758827  -1.3135034  ...  0.11544084 -0.06083076
  -0.2934167 ]
 [-0.8923946   0.01298854  0.627582   ...  0.31828704 -0.1404203
  -0.10169293]
 [ 0.09547019  0.05894606 -0.01106366 ...  0.10389562  0.1405045
  -0.20378298]]
layers.2.weight: [[-5.9630957e-02  7.6396875e-03 -1.7946320e-04 -1.3283951e-02
   4.7108969e-03  1.1597527e-02  2.7517274e-01 -9.8912902e-03
  -1.1396075e-02  7.6260261e-02  6.2845953e-02  5.8800336e-02
   0.0000000e+00 -7.3004253e-02  1.4388786e-02 -1.7776795e-02
  -6.1799947e-02  6.1685313e-02  2.2552691e-02 -8.2029648e-02
  -5.4060249e-03 -2.2551052e-03  2.2296095e-02 -4.8698750e-03
   1.4598741e-03  7.2728661e-03  4.2936265e-02  9.8909787e-04
  -2.1052396e-02 -5.4278590e-02  2.3462825e-01 -7.3472597e-02]]

Final Loss: 0.0368
Distance Metric: 56.1687
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 1
stopped after epoch: 1999

================================================================================

baselineCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.0539489   0.17236087 -0.01086898 ...  0.00367094  0.6495873
   0.392652  ]
 [ 0.06984836 -0.1359871  -0.02015226 ...  0.01316117 -0.25511408
   0.00319062]
 [-0.01473598 -0.01686323 -0.15527911 ...  0.09342514 -0.40262574
  -0.27543923]
 ...
 [-0.01487996 -0.02738438 -0.09969966 ... -0.0548513   0.23111607
   0.1745306 ]
 [-0.05245126  0.05797765  0.08801164 ...  0.08363292 -0.07350013
  -0.1792347 ]
 [ 0.0106749   0.01094763 -0.03467945 ...  0.1517187  -0.48435548
  -0.36197892]]
layers.1.weight: [[ 0.07383405 -0.21367878  0.03480712 ...  0.07989953  0.04501477
  -0.11180386]
 [ 0.44653246 -0.76050603 -0.14922668 ...  0.22167051  0.01217564
  -0.28124002]
 [ 0.01157986  0.13344657 -0.03726765 ... -0.16986911 -0.00809946
  -0.14746962]
 ...
 [ 0.09967325 -0.1292713  -0.24107218 ...  0.07682863 -0.04281899
  -0.15806162]
 [-0.01415518 -0.05435792  0.14472544 ...  0.11317534 -0.09377046
   0.14358518]
 [-0.07008129 -0.03136034  0.00758114 ...  0.08462267  0.0625868
  -0.0228414 ]]
layers.2.weight: [[-1.5050381  -4.725495    0.88060385  0.7997209  -1.1959552  -6.224228
  -0.2790426   1.9347525   3.1805701   1.1220282   0.31654677  1.5750871
  -2.2572653   1.255138   -2.9154947   0.4058808  -2.917455   -0.43115962
  -2.1273024  -1.4233371  -0.566682   -1.0612999  -0.75890404 -0.7984922
  -2.0998096  -0.63076925 -0.57577956  0.9258096  -2.6480963  -1.6234733
  -0.5691727   0.4183284 ]]

Final Loss: 0.2950
Distance Metric: 48.2701
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 1
stopped after epoch: 1999

================================================================================

baselineCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-0.7831871   0.24665858  0.50577104 ... -0.30368203 -0.8670274
  -0.2051853 ]
 [-0.05807903 -0.21097872 -0.04193588 ...  0.03711494 -0.27328557
  -0.01146736]
 [ 0.36701673 -0.21199957 -0.02231332 ... -0.05784394  0.15351923
  -0.05141129]
 ...
 [ 0.1044011   0.4431188  -0.01149414 ...  0.21225865 -0.19322817
   0.48719424]
 [ 0.28209743 -0.10984898 -0.29983974 ... -0.17485587  0.07638633
   0.18968143]
 [-0.04086751  0.11258478  0.04036281 ... -0.06195865 -0.06824627
   0.21947964]]
layers.1.weight: [[ 0.25086427 -0.16849655  0.04700939 ... -0.24234912 -0.13189861
   0.19658877]
 [-0.4025886  -0.0467507   0.20388775 ... -0.03219535 -0.18960631
   0.19097231]
 [-0.20231053  0.63398105  0.04536874 ...  0.21030018  0.13336143
   0.09947276]
 ...
 [ 0.10277906 -0.23518373 -0.03518556 ... -0.53892565 -0.13612106
   0.3933354 ]
 [-0.02461639  0.04200204 -0.6364498  ... -0.34901974 -0.02921432
  -0.4368154 ]
 [-0.14994976 -0.03997556 -0.11437184 ... -0.08214179 -0.14458896
   0.12007684]]
layers.2.weight: [[ 0.84187543 -0.10658742 -1.2294226   3.3004825   0.38294053  0.36777356
   1.5955335  -0.38689494 -0.79528517 -0.7602095  -2.3752258  -2.0898101
  -0.02108533 -0.5036622   0.2146979  -2.9354842   0.14230467 -1.4764819
  -0.95092154  0.99191046  1.119171    0.1449193  -0.96001357 -0.7478826
   0.71328837  0.31130064 -0.68901336 -0.81100905  0.04983415  0.741267
   1.3794929  -1.058674  ]]

Final Loss: 0.5883
Distance Metric: 46.3285
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 1
stopped after epoch: 105

================================================================================

