Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[ 2.59 -2.83  0.87]]]
layers.1.weight: [[[-1.38  1.29]]]
layers.2.weight: [[[ 0.86 -0.84]]]

================================================================================

baselineCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0.00080145 0.00080093 0.00080151 0.00080118 0.00080101 0.00080121
  0.00080248 0.00080216 0.00080159 0.00080263 0.00080174 0.00080209
  0.00080128 0.0008012  0.00080079 0.00080141 0.00080134 0.00080098
  0.00080177 0.00080078 0.00080125 0.00080152 0.00080197 0.00080093
  0.00080158 0.00080242 0.00080174 0.00080192 0.00080211 0.00080263
  0.00080072 0.00080171]]

Final Loss: 0.0026
Distance Metric: 7.0293
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 5

================================================================================

baselineCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.02233531 -0.08112451  0.00521294 ... -0.11761228  0.11315261
  -0.0173886 ]
 [-0.02612437  0.00015437  0.05305538 ... -0.12390273  0.00957436
   0.0021869 ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[0.         0.21015446 0.00155136 ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 ...
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]]
layers.2.weight: [[-0.4400538   0.          0.          0.          0.          0.
   0.7386808   0.33874044  0.          0.          0.          0.
  -0.43639857  0.25427884  0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.27851108  0.          0.          0.          0.          0.
   0.          0.        ]]

Final Loss: 0.0111
Distance Metric: 8.9093
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 5

================================================================================

baselineCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0.         0.         0.         0.         0.         0.20376611
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.        ]]

Final Loss: 0.2528
Distance Metric: 7.0534
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 5

================================================================================

baselineCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[-3.4467998e-04 -3.4462620e-04 -3.4417197e-04 -3.4352837e-04
  -3.4434116e-04  1.7342606e+01 -3.4351140e-04  6.9270787e+00
  -3.4456872e-04 -3.4389106e-04 -3.4394331e-04 -3.4340151e-04
  -3.4389674e-04 -3.4416557e-04 -3.4403021e-04 -3.4345823e-04
  -3.4286786e-04 -3.4324318e-04 -3.4450451e-04 -3.4290573e-04
  -3.4326786e-04 -3.4467521e-04 -3.4361947e-04 -3.4441653e-04
  -1.4336593e+01 -3.4297025e-04 -3.4292063e-04  6.9689956e+00
  -3.4380733e-04 -3.4282470e-04 -3.4342633e-04 -3.4345817e-04]]

Final Loss: 3.3069
Distance Metric: 66.8371
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 5

================================================================================

baselineCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.         0.         0.         0.         0.         0.
   0.        -1.1570609  0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         1.1967897  0.
   0.         0.         0.         0.         0.         0.
   0.         0.       ]]

Final Loss: 0.0002
Distance Metric: 8.2694
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 5

================================================================================

baselineCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.11233649 -0.1289878   0.14299943 ... -0.03023591 -0.41898865
  -0.07515354]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[0.3323024 0.        0.        ... 0.        0.        0.       ]
 [0.        0.        0.        ... 0.        0.        0.       ]
 [0.        0.        0.        ... 0.        0.        0.       ]
 ...
 [0.        0.        0.        ... 0.        0.        0.       ]
 [0.        0.        0.        ... 0.        0.        0.       ]
 [0.        0.        0.        ... 0.        0.        0.       ]]
layers.2.weight: [[-1.7524478   0.          0.          0.3431929   0.          0.
   0.29469046  0.          0.          0.0950977   0.          0.
   0.          0.          0.54799896  0.          0.          0.
   0.         -1.808251    0.          0.          0.30490345  0.
   0.5427949   0.          0.          0.32842797  0.          0.
   0.          0.        ]]

Final Loss: 3.5500
Distance Metric: 55.2841
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 5

================================================================================

baselineCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.002389   -0.0023888  -0.00238786 ... -0.0023887  -0.00238801
  -0.00238716]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.2.weight: [[-1.3138029e-01 -5.8173263e-03 -5.8169104e-03 -5.8171568e-03
  -5.8172117e-03 -5.8178958e-03 -5.8177304e-03 -5.8180247e-03
   6.0113134e+00 -5.8183074e-03 -5.8175386e-03 -5.8171391e-03
  -5.8162352e-03 -5.8187381e-03 -5.8169365e-03 -2.4685688e+00
  -5.8180452e-03 -9.4001390e-02 -5.7326561e-01 -5.8175530e-03
  -2.1707075e+00 -1.3510521e+01 -6.3531645e-02 -5.8162026e-03
  -5.8172820e-03 -5.8170808e-03 -5.8185337e-03 -5.8186948e-03
  -5.8169216e-03 -3.1398326e-01 -6.9892640e+00 -5.8184075e-03]]

Final Loss: 0.1839
Distance Metric: 50.0701
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 5

================================================================================

baselineCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.06472482  0.00497356  0.11002328 ...  0.13187434  0.01556267
   0.00567693]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.09918329 -0.11999097  0.03934841 ... -0.06632666 -0.06993329
  -0.19749446]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[0.         0.         0.00096577 ... 0.         0.10670809 0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.00251331 ... 0.         0.04957648 0.        ]
 ...
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]]
layers.2.weight: [[-0.59615517  0.         -0.682888   -0.34554833  0.         -0.5704344
  -0.9967246  -0.61582214  0.          0.         -0.52295583  0.28445342
   0.          0.26186985  0.         -0.76637787  0.          0.35940763
   0.          0.          0.          0.          0.          0.
   0.          0.326548    0.          0.         -0.48781943  0.
   0.          0.        ]]

Final Loss: 0.1930
Distance Metric: 15.1611
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 5

================================================================================

baselineCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.         -0.37034643  0.          0.          0.
   0.         -0.47708654  0.          0.          0.          0.
   0.3620775   0.          0.          0.          0.          0.
   0.48890197  0.        ]]

Final Loss: 0.0004
Distance Metric: 11.4339
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 5

================================================================================


