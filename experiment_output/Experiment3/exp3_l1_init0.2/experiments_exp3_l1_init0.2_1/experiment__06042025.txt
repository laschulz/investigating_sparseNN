Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[ 2.59 -2.83  0.87]]]
layers.1.weight: [[[-1.38  1.29]]]
layers.2.weight: [[[ 0.86 -0.84]]]

================================================================================

nonoverlappingCNN_sigmoid -> fcnn_decreasing_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0.00145315 0.0014537  0.00145239 0.00145363 0.001453   0.0014524
  0.00145255 0.00145347 0.00145269 0.00145365 0.00145308 0.00145368
  0.00145353 0.00145314 0.00145251 0.00145286 0.00145306 0.00145252
  0.00145401 0.00145233 0.00145349 0.00145406 0.00145414 0.0014535
  0.00145238 0.00145282 0.00145326 0.00145281 0.00145413 0.00145336
  0.00145303 0.00145431]]

Final Loss: 0.0026
Distance Metric: 7.0328
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 1

================================================================================

nonoverlappingCNN_sigmoid -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.03134348  0.0014     -0.00458728 ...  0.00254512  0.00314334
  -0.07476932]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[0.         0.03579956 0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 ...
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.05364962 0.         ... 0.         0.         0.        ]]
layers.2.weight: [[ 0.3359685   0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.34754437  0.          0.         -0.44205144  0.
   0.7062022   0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.33995077]]

Final Loss: 0.0112
Distance Metric: 8.8954
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 1

================================================================================

nonoverlappingCNN_sigmoid -> fcnn_decreasing_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.16560465 0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.        ]]

Final Loss: 0.2527
Distance Metric: 6.4898
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 1

================================================================================

nonoverlappingCNN_relu -> fcnn_decreasing_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[  0.          0.          0.          0.        -10.902562    0.
   11.194081    0.          0.          0.          0.         -6.1961102
    0.          5.349594    0.          0.          0.          0.
    0.          0.         12.355371    3.499959    0.          0.
    0.          0.          0.         -6.217289    0.          0.
    0.          0.       ]]

Final Loss: 3.3196
Distance Metric: 59.8195
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 1

================================================================================

nonoverlappingCNN_relu -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   1.1774967  0.         0.         0.         0.         0.
   0.         0.        -1.1226934  0.         0.         0.
   0.         0.       ]]

Final Loss: 0.0003
Distance Metric: 8.0388
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 1

================================================================================

nonoverlappingCNN_relu -> fcnn_decreasing_tanh

Student Model Parameters:
layers.0.weight: [[-4.5310707   4.776872   -1.4509333  ...  0.25967997 -0.21374424
   0.14984854]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.          0.          0.          0.         -0.3436162
   0.          0.          0.          0.          0.          0.
   0.7469024   0.          0.04417801  0.          0.          1.2794613
   1.2459862   0.26729718  0.          0.          0.          0.
   0.         -0.61371356  0.          0.          0.69272     0.
   0.          0.        ]]

Final Loss: 3.5616
Distance Metric: 42.5752
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 1

================================================================================

nonoverlappingCNN_tanh -> fcnn_decreasing_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.02735367 -0.05617929 -0.00127657 ... -0.01753821 -0.00127665
  -0.01863356]]
layers.2.weight: [[  0.07510955   0.07511125   0.70681626   0.07510921   0.07510965
    0.07511024   0.9075716    0.30499494   0.07511233 -13.685511
    0.07511046   0.07511023   0.07511053   0.07511199   0.07511061
    0.07511153   0.07511082   0.07511181   0.5994505    0.78216434
   -7.1397896    0.07407501   0.07510865   0.0751124    0.886678
    0.07510921   0.07511085   0.43065748   0.06717835   0.07511132
    0.07510814  -6.6562314 ]]

Final Loss: 0.1863
Distance Metric: 49.1387
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 1

================================================================================

nonoverlappingCNN_tanh -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.         -0.8850728   0.          0.          0.3207809
  -0.9167493   0.          0.         -0.5978949  -0.9472262   0.
   0.         -0.6893486   0.         -0.43261436  0.          0.
   0.          0.          0.3768289   0.          0.2371782   0.
  -0.45860663  0.          0.          0.          0.          0.27895895
   0.          0.        ]]

Final Loss: 0.1954
Distance Metric: 15.3546
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 1

================================================================================

nonoverlappingCNN_tanh -> fcnn_decreasing_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.          0.          0.          0.          0.
   0.          0.          0.         -0.36996114  0.47594926  0.
   0.          0.         -0.3629365   0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.         -0.48946643  0.          0.          0.
   0.          0.        ]]

Final Loss: 0.0004
Distance Metric: 11.4351
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 1

================================================================================


