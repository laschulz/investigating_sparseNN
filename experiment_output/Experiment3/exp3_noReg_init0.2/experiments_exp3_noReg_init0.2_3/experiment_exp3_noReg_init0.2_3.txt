Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.0940784   0.19681509  0.08915999]]]
layers.1.weight: [[[-0.03762013  0.04123275]]]
layers.2.weight: [[[-0.1918266  -0.23791492]]]

================================================================================

baselineCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.00014891  0.0083266  -0.0282703  ... -0.02961185 -0.02942412
   0.01840571]
 [ 0.01386832 -0.02749925  0.0263436  ...  0.01641821 -0.00183741
  -0.01367117]
 [ 0.02738456 -0.00971848  0.02469387 ... -0.00861547  0.02642604
   0.01599442]
 ...
 [ 0.00528194 -0.01294157 -0.00336624 ... -0.00542603 -0.00327953
   0.00189696]
 [ 0.0128298   0.01596864  0.01289697 ...  0.00179841  0.01325928
  -0.01305186]
 [ 0.01425878 -0.01340975 -0.01197021 ...  0.01293208 -0.02747915
   0.01918925]]
layers.1.weight: [[-0.02625632  0.02577486  0.02695403 ... -0.01470688  0.02811676
   0.00059032]
 [ 0.0065038  -0.00325847 -0.02668433 ...  0.02714073  0.01181082
   0.02813848]
 [-0.00343534 -0.01254474  0.01363521 ... -0.00347361  0.00382333
  -0.0192861 ]
 ...
 [ 0.01528104 -0.00468608 -0.00986132 ... -0.00538004  0.0057004
   0.02822474]
 [ 0.00434926  0.02336976  0.01979829 ...  0.00517953  0.00839451
   0.01003493]
 [ 0.0044803  -0.02244262  0.00556156 ...  0.00569275  0.02343899
   0.01534566]]
layers.2.weight: [[-0.04747596 -0.04985728  0.00617335 -0.09228079 -0.0373926   0.0310032
   0.04213745 -0.00535509 -0.03323555 -0.05835499  0.05498717  0.03716154
  -0.00041054  0.0493028   0.04325279  0.00692989  0.06288382 -0.05819744
   0.05659276 -0.04975465 -0.07914463  0.01677785 -0.07310553 -0.00897773
  -0.03265678 -0.10178752  0.015389   -0.04266323  0.03429146 -0.02370722
  -0.00124666 -0.0757008 ]]

Final Loss: 0.0000
Distance Metric: 3.0651
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 1999

================================================================================

baselineCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.13453169  0.21847877  0.09815219 ... -0.09489687 -0.02651029
  -0.0718753 ]
 [-0.07245679 -0.1809827  -0.03705394 ...  0.06147218  0.05629018
   0.09901827]
 [ 0.27413985  0.02118781  0.13345124 ... -0.08070642  0.12632531
   0.17192478]
 ...
 [-0.2899097   0.01371899 -0.03666748 ...  0.33351082  0.19427525
  -0.05481363]
 [ 0.1350283  -0.11246651  0.09707899 ... -0.20326197  0.03678582
   0.16609178]
 [-0.09307034 -0.19062506 -0.11840566 ... -0.01476805  0.21670547
   0.09713425]]
layers.1.weight: [[ 0.15677424  0.02020547  0.09379162 ... -0.25206113 -0.09207425
   0.08265455]
 [-0.0236586  -0.08333534  0.13032033 ...  0.15666807 -0.16668153
  -0.35028404]
 [-0.17303808  0.3721157   0.10741602 ...  0.06390245  0.04201006
   0.06404089]
 ...
 [-0.0371806  -0.04475495  0.34426388 ... -0.32767916  0.19434106
  -0.09720739]
 [ 0.00972703 -0.18460348 -0.23371221 ... -0.26328266 -0.05728377
  -0.10544694]
 [-0.2764228  -0.14723927 -0.11198638 ... -0.07317428  0.1434576
  -0.1165918 ]]
layers.2.weight: [[ 0.11075888  0.10182536 -0.1354797   0.09820761 -0.10014291 -0.1155136
   0.10881943  0.09216735  0.10017692  0.1007784   0.10643615  0.09626548
   0.09752088  0.1494288  -0.14963506 -0.10058871 -0.35725188  0.12095802
   0.10687437 -0.25342968 -0.10463207  0.10557597 -0.11753412  0.10954841
  -0.15814945  0.09901157 -0.23932447  0.10411931 -0.14509907 -0.14139524
  -0.11091628  0.15527868]]

Final Loss: 0.0096
Distance Metric: 28.3618
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 1999

================================================================================

baselineCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.00763272 -0.01713737  0.00397622 ...  0.01232707  0.01254483
  -0.01431696]
 [ 0.0042624   0.0147551   0.01446544 ... -0.00280636 -0.02229965
  -0.001421  ]
 [ 0.03272835  0.03731762 -0.01470279 ...  0.02243555 -0.00196885
   0.01170282]
 ...
 [ 0.00839785  0.02150218  0.00561516 ...  0.01406972  0.02594973
  -0.02070547]
 [ 0.00339117  0.02299186 -0.01039192 ...  0.0290493  -0.01545196
   0.01066183]
 [-0.0242436  -0.01876964  0.00123194 ... -0.00775597 -0.02310943
  -0.01349253]]
layers.1.weight: [[ 0.04377098 -0.0162454  -0.00430077 ...  0.02604005  0.0181972
   0.04332858]
 [-0.02811991 -0.00076538  0.01511274 ... -0.02366811  0.03264832
   0.03010561]
 [-0.00198922  0.00264596  0.02025197 ...  0.01947576 -0.03982184
   0.03611337]
 ...
 [-0.00484492 -0.03984147 -0.04007887 ...  0.02204794 -0.01304151
   0.00024364]
 [-0.01248067 -0.01174952  0.01616349 ...  0.01030276  0.02945421
   0.00503231]
 [ 0.04750826  0.02724689  0.00749387 ... -0.00308485 -0.01079135
  -0.0152156 ]]
layers.2.weight: [[ 0.00662782  0.03551638  0.01694112  0.00105699  0.02802744 -0.01950669
   0.02092639 -0.01297381 -0.03517831 -0.01922585 -0.00051518 -0.02339483
  -0.02411387 -0.00500891  0.03204104 -0.00025756  0.00466441  0.01275547
   0.00258321  0.          0.00612618  0.00229654 -0.02878477  0.01651511
   0.00311148 -0.01968074  0.003758   -0.0024254   0.02268764 -0.00958407
   0.00778681 -0.01472973]]

Final Loss: 0.2782
Distance Metric: 3.8664
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 204

================================================================================

baselineCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.023469    0.01227685 -0.01490486 ...  0.02155822 -0.01788385
  -0.00917429]
 [-0.01867211  0.01852702 -0.00945238 ...  0.01265239  0.01390454
   0.02624809]
 [ 0.00962031 -0.00254237 -0.02870422 ...  0.01616377 -0.01942069
  -0.01423724]
 ...
 [-0.01019837  0.02875046 -0.02423935 ...  0.00345919 -0.01243381
   0.01186192]
 [-0.02528555 -0.00642244 -0.02252096 ...  0.01443008 -0.01293299
  -0.02744918]
 [-0.01780825 -0.00850571 -0.02800282 ...  0.00860989 -0.01937149
   0.02461583]]
layers.1.weight: [[-0.02099187 -0.02136252  0.01821655 ...  0.03024954  0.02077155
   0.0078125 ]
 [ 0.03700084  0.03422589  0.00094694 ... -0.0107559  -0.00219848
  -0.01685092]
 [-0.00945366  0.02439092 -0.02056925 ... -0.02115831  0.02960528
   0.01344122]
 ...
 [ 0.02176647  0.02068126  0.0360962  ...  0.0331956  -0.00986727
  -0.01300289]
 [-0.00035855  0.02475559  0.03171857 ... -0.01741501 -0.01463072
   0.01909193]
 [ 0.02053945 -0.0206533   0.03235049 ...  0.01772818 -0.01422998
   0.0078125 ]]
layers.2.weight: [[-0.2377884  -0.40175018 -0.25       -0.24562614 -0.40428945 -0.41701344
  -0.30651206 -0.29524755 -0.3563855  -0.39718854 -0.35193083 -0.28436258
  -0.30220276 -0.37449428 -0.26699877 -0.34733886 -0.26236844 -0.25
  -0.24984473 -0.2459979  -0.43013555 -0.4316108  -0.35194325 -0.28785866
  -0.3706872  -0.30000764 -0.39975443 -0.4291758  -0.33961362 -0.30049482
  -0.32885554 -0.27038324]]

Final Loss: 0.0000
Distance Metric: 5.3703
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 1999

================================================================================

baselineCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-0.00367083 -0.01795969 -0.00848023 ... -0.01571723 -0.0058508
   0.00841181]
 [ 0.02496666  0.00143333 -0.0045662  ...  0.01779659  0.00424954
   0.0273765 ]
 [-0.01804425 -0.00742498 -0.01130071 ...  0.00347159  0.00963002
  -0.00103282]
 ...
 [-0.01103349 -0.01002531  0.01223619 ...  0.00784862 -0.00881918
   0.00518528]
 [-0.01384426  0.00539262 -0.00801277 ... -0.01970401 -0.00089209
  -0.00347839]
 [-0.01274237  0.0081756   0.00895607 ... -0.00292556 -0.00113846
  -0.02906427]]
layers.1.weight: [[-0.020204    0.02388796  0.04686818 ...  0.06442742  0.11174065
  -0.03320663]
 [ 0.04082271  0.06756186 -0.01613144 ...  0.01984951 -0.0831794
   0.04501745]
 [-0.0392417  -0.174972   -0.00132663 ... -0.00865052 -0.07816328
  -0.01972   ]
 ...
 [-0.01116185  0.0997738   0.02341463 ... -0.03716736 -0.06215689
   0.04020265]
 [ 0.05336137  0.05061766 -0.10170711 ... -0.07868682 -0.03195784
  -0.12097052]
 [ 0.05623415  0.08607222  0.0392186  ... -0.02672668  0.00537502
   0.02170602]]
layers.2.weight: [[ 1.2985232e-01 -1.6786718e-01  3.2696206e-02 -1.3418926e-01
  -1.5683293e-01  7.1275961e-01  3.6738056e-01 -4.7094738e-01
  -6.6004053e-02  7.7352389e-03  1.8498781e-01  4.5916844e-02
  -1.5379906e-01  7.3990084e-02 -2.5100464e-01 -2.3865357e-02
   2.6731769e-02 -3.1879064e-01  1.6507764e-01 -3.6763504e-01
  -6.4493239e-02  1.4754637e-01  1.9691920e-02 -1.3413630e-01
   2.4874827e-02  3.3135855e-01 -1.8684807e-01 -2.8451236e-02
  -5.0218350e-01  3.3190918e-01 -1.4664470e-03  5.8809330e-04]]

Final Loss: 0.0000
Distance Metric: 6.9503
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 1999

================================================================================

baselineCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.03039332  0.02605307 -0.04374632 ...  0.02391537  0.00687672
  -0.03208207]
 [-0.0150807  -0.04628199  0.00877868 ... -0.0372178  -0.02951328
   0.04700091]
 [ 0.05098777 -0.00766075  0.03746276 ... -0.05371221  0.01377911
  -0.01981028]
 ...
 [ 0.02306459  0.03944132 -0.01636229 ... -0.03719044  0.01539438
  -0.0407603 ]
 [ 0.04266129 -0.0379007   0.02610582 ...  0.03903984 -0.04365069
  -0.00724434]
 [-0.00955362 -0.03758488 -0.03709559 ... -0.05329907 -0.04932256
   0.01747562]]
layers.1.weight: [[-0.01567273 -0.01531089  0.00849042 ... -0.03299791 -0.01201704
   0.01598896]
 [-0.02199076  0.0143078  -0.03475396 ... -0.00303907  0.03474205
  -0.01292014]
 [-0.0215562   0.04724392  0.03958787 ...  0.03527347  0.03721496
   0.01141986]
 ...
 [-0.0333556   0.04132527 -0.02486323 ...  0.01538148  0.02777863
  -0.01664067]
 [ 0.013807    0.00599612  0.0412121  ...  0.02258958  0.00922807
   0.02317703]
 [-0.00142993  0.03203778 -0.01828343 ...  0.03999311 -0.045506
  -0.04259023]]
layers.2.weight: [[-0.04804884 -0.04157513 -0.04672442 -0.02982616 -0.01641863  0.10034606
   0.06940665  0.07066973  0.08799812 -0.01205218 -0.05729477 -0.02697025
   0.00501247 -0.09413837  0.08741388  0.0013122  -0.09212986  0.06131803
  -0.02067221  0.0200596   0.09635302  0.04026328 -0.10270739 -0.09717095
  -0.06629944 -0.04215362  0.08308171  0.007786    0.05525482 -0.0538453
   0.0817621   0.01438918]]

Final Loss: 0.0000
Distance Metric: 4.8600
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 1999

================================================================================

baselineCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.01499995 -0.31420925 -0.04132532 ...  0.00565689 -0.34075615
  -0.05027563]
 [ 0.02728927 -0.04354586 -0.00955012 ... -0.00439621 -0.0349257
  -0.02680244]
 [-0.04795508  0.32973745  0.07385817 ... -0.02445566  0.40273163
   0.08733957]
 ...
 [-0.01715185  0.00936474 -0.0163254  ...  0.01589292  0.03440671
   0.02713172]
 [-0.00241356  0.03834742 -0.01383163 ...  0.02071012 -0.02032902
  -0.02115535]
 [ 0.00518816  0.2572321   0.02671107 ... -0.01612057  0.3022263
   0.07090645]]
layers.1.weight: [[-0.15738358 -0.02274952  0.14442642 ... -0.01824154 -0.04049949
   0.06826435]
 [-0.14760411 -0.01509502  0.13435893 ... -0.00142863 -0.04183989
   0.08983872]
 [-0.17543493 -0.02863651  0.15677914 ... -0.00807527 -0.0440875
   0.08778332]
 ...
 [-0.11487747 -0.02554599  0.12630829 ... -0.03867432 -0.0052239
   0.06320295]
 [ 0.04297546 -0.00724802 -0.00582757 ...  0.02342629 -0.00120685
  -0.00346626]
 [-0.12843277 -0.01356289  0.13592301 ... -0.02914537  0.01211581
   0.11065512]]
layers.2.weight: [[-0.68089366 -0.7244196  -0.7127254  -0.8477471  -0.46383137 -0.4203607
  -0.6914284  -0.48307708 -0.3701063  -0.45736128 -0.54093415 -0.96085835
  -0.5648269  -0.43593055 -0.50047755 -0.40793648 -0.39222845 -1.0431063
  -0.32993814 -0.5576309  -0.4058784  -0.5036248  -1.0002602  -0.33989504
  -1.1336306  -0.3825202  -0.4003268  -0.42506903 -0.91748494 -0.5797752
  -0.43684188 -0.6107751 ]]

Final Loss: 0.0004
Distance Metric: 14.2718
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 1999

================================================================================

baselineCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.00641547  0.00630131  0.00022441 ... -0.02557246  0.01173157
   0.00988211]
 [-0.01119945  0.00195459 -0.0146367  ... -0.01123026 -0.00718574
  -0.02059123]
 [ 0.00715324 -0.00897003 -0.01081788 ...  0.01080033  0.0236705
   0.00453353]
 ...
 [-0.00098025 -0.00035961  0.00884315 ... -0.0100865  -0.00300337
  -0.00668778]
 [ 0.00790628  0.01612942  0.00645387 ... -0.01569623  0.00604698
   0.01809676]
 [ 0.00078837 -0.00803313 -0.00488852 ...  0.00626952  0.00672547
  -0.0051253 ]]
layers.1.weight: [[-0.02420568 -0.08630761 -0.04041829 ... -0.08994081  0.01522232
   0.01043543]
 [ 0.02879251  0.00675004  0.0227969  ...  0.01495862 -0.06470381
   0.00440259]
 [ 0.03734214 -0.05596315  0.05373441 ...  0.04113577 -0.0394095
  -0.09241988]
 ...
 [ 0.02843441  0.0292815  -0.06070242 ... -0.042111   -0.05651568
   0.01791017]
 [-0.00536442 -0.02043994 -0.10464833 ...  0.08872766  0.0436901
   0.02786905]
 [ 0.01998382  0.00844077  0.01067952 ...  0.09414233  0.00201615
   0.0656211 ]]
layers.2.weight: [[-0.17414722  0.12916747  0.01250165 -0.08614506 -0.40308222  0.15855934
  -0.5727263   0.15872373 -0.31479478 -0.1542274   0.05163555  0.250157
  -0.22758128 -0.06065654 -0.04905809 -0.28857777 -0.03251984 -0.07060141
   0.2069702   0.05305915  0.04198454  0.25522867 -0.28000194  0.05018146
   0.08970185 -0.16320862 -0.08887389  0.13185078  0.35003418  0.2723526
  -0.2751883  -0.0722897 ]]

Final Loss: 0.0018
Distance Metric: 6.9927
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 1999

================================================================================

baselineCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.01264567 -0.01311111  0.01357407 ... -0.10792164  0.05312314
  -0.12294469]
 [-0.00950962  0.00404497 -0.02808714 ... -0.0068267   0.01764048
  -0.03585258]
 [ 0.         -0.03032916 -0.04471665 ...  0.03666006 -0.00404765
  -0.01872547]
 ...
 [-0.0157541  -0.00763744 -0.0012349  ... -0.00460988  0.05042988
   0.01622069]
 [ 0.02682012 -0.00669306  0.01121426 ...  0.02507728 -0.03436666
  -0.02033094]
 [ 0.02234141  0.01168266 -0.00334266 ... -0.03799645 -0.04058421
  -0.04754729]]
layers.1.weight: [[-0.01873206 -0.04572228 -0.0290666  ... -0.03581779  0.02989623
   0.0090618 ]
 [ 0.00353161 -0.02804939 -0.03843782 ...  0.02910789 -0.01940493
   0.        ]
 [-0.03924215 -0.00957369 -0.0246478  ... -0.01779341  0.01272468
  -0.01098882]
 ...
 [-0.03748915  0.02480982 -0.01232348 ... -0.02301363  0.04385183
  -0.04177177]
 [-0.02880118 -0.04057442 -0.00411675 ... -0.03157349 -0.02900391
  -0.01816599]
 [-0.03110533  0.03246298 -0.01532953 ... -0.01363843  0.01348487
   0.02322045]]
layers.2.weight: [[ 0.05133816  0.07498659 -0.06758546  0.15900083  0.05049595 -0.00548475
   0.03671576  0.03357419 -0.09145287  0.09551797 -0.00123684 -0.0082704
  -0.00603342 -0.01194937  0.00640866 -0.06711227 -0.1566167   0.00164297
   0.0170286  -0.0635607  -0.15942043 -0.14617787  0.05027482 -0.01646391
   0.07133039 -0.09078041  0.08700056  0.12360972 -0.08784346 -0.08735537
   0.03213558 -0.08452253]]

Final Loss: 0.0000
Distance Metric: 5.0225
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 1999

================================================================================

