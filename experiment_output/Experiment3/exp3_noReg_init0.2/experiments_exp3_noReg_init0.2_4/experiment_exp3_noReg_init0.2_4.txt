Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[ 0.15554956 -0.0532649   0.12202001]]]
layers.1.weight: [[[-0.14661655 -0.02391262]]]
layers.2.weight: [[[-0.09776441 -0.23804806]]]

================================================================================

baselineCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.00805063 -0.02544513 -0.01129393 ...  0.003671   -0.02497688
   0.01633505]
 [-0.010164   -0.02866564  0.02679813 ... -0.01668755  0.01085314
  -0.02208887]
 [-0.01625956 -0.0104606   0.01781858 ...  0.00735272  0.00511943
   0.02743906]
 ...
 [-0.01865171 -0.02338171 -0.00532205 ...  0.01894238 -0.00971382
   0.00024468]
 [ 0.01540724  0.0046011   0.01748723 ... -0.00155426 -0.00793447
   0.00077319]
 [ 0.00947537 -0.01801466  0.00250456 ...  0.02564754  0.02515913
   0.01925307]]
layers.1.weight: [[ 0.01711961  0.01379164  0.02815913 ...  0.02007621 -0.01549455
   0.0122396 ]
 [-0.00902235  0.01370719  0.00632654 ...  0.00983388  0.02529021
   0.00989527]
 [-0.02762943  0.00423094 -0.00956266 ... -0.01469493  0.0002226
  -0.02499972]
 ...
 [ 0.00389872 -0.01963521 -0.00448269 ... -0.01296635  0.00868269
   0.02619067]
 [ 0.01196059  0.01711657  0.0155517  ... -0.01598111 -0.01833838
  -0.01730854]
 [-0.00031221 -0.02206165  0.02019796 ... -0.02399156  0.00156348
  -0.02438225]]
layers.2.weight: [[ 0.0088354  -0.10233036  0.03977501  0.03912428  0.04248197 -0.04040643
   0.00664308  0.05359286  0.05419229  0.0065136   0.04364547 -0.07614248
   0.0135151  -0.05048145 -0.0403076  -0.01350135 -0.03342415  0.03861028
  -0.04402324 -0.06952574 -0.04042376 -0.08447087  0.01894267  0.0288289
   0.03837126 -0.07965239  0.01641284  0.01506623  0.01261189 -0.1033807
   0.02426563 -0.03076948]]

Final Loss: 0.0000
Distance Metric: 3.1107
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 1999

================================================================================

baselineCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.09285973  0.09250324  0.08803333 ... -0.2688903   0.04195454
   0.01110341]
 [-0.13402852  0.03415578 -0.41245022 ...  0.04441605  0.05807864
   0.05187759]
 [-0.2266405  -0.11284323 -0.14219311 ... -0.21805023 -0.28368747
   0.08357839]
 ...
 [ 0.0065829  -0.3506454   0.1839176  ... -0.17141747 -0.23263375
  -0.21353894]
 [-0.3518501   0.28715065  0.05497272 ... -0.0009148   0.24799864
   0.08884858]
 [ 0.18324251 -0.01666888 -0.14969945 ...  0.24554065 -0.19413921
  -0.03076301]]
layers.1.weight: [[-0.11425757 -0.03368789 -0.20319025 ... -0.1055789   0.02520461
  -0.11073379]
 [-0.0999173  -0.06060237  0.02004115 ...  0.11455056 -0.04759608
   0.1395301 ]
 [-0.2059904  -0.20439804  0.1093957  ... -0.12101457  0.11654251
   0.01492614]
 ...
 [-0.06820471 -0.08179584 -0.25947842 ... -0.5463472   0.3053302
   0.02845485]
 [-0.22556637 -0.00996443  0.05327607 ... -0.07164769 -0.03929362
   0.04338   ]
 [ 0.03767536  0.5878895   0.08901907 ... -0.2836647  -0.2870623
  -0.27978942]]
layers.2.weight: [[ 0.10907649  0.1067951  -0.11768539 -0.11221989 -0.20009117 -0.32904345
   0.0903952  -0.45080966 -0.14984961 -0.50991935  0.10890399  0.09434386
  -0.17218892  0.0882525  -0.13329998 -0.49884495 -0.13823283 -0.20104358
   0.11927442  0.09444588  0.11150306 -0.13817573 -0.10010508 -0.18072785
  -0.24768308  0.10259215  0.09815274 -0.13109733  0.11405666 -0.19327408
   0.11092158 -0.16941981]]

Final Loss: 0.0083
Distance Metric: 28.2289
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 1999

================================================================================

baselineCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.01340922 -0.02342035 -0.01394375 ...  0.00894176  0.00123949
   0.00495413]
 [-0.00977545  0.02257721  0.00306815 ...  0.01572628 -0.0039176
  -0.01780962]
 [ 0.00963381  0.01214583  0.01318019 ... -0.01935492 -0.01186491
   0.00291951]
 ...
 [-0.03305742  0.0084389  -0.0175518  ... -0.01685518  0.00949059
  -0.02221528]
 [ 0.01212302 -0.00754556  0.00039166 ... -0.00833255 -0.02259806
   0.02120378]
 [-0.0492535  -0.02805947 -0.00097389 ... -0.01668645  0.01083988
   0.03081831]]
layers.1.weight: [[-0.02590126  0.0017701   0.03720459 ... -0.02920645  0.01315266
  -0.02157875]
 [-0.00475057  0.02146635 -0.01643552 ... -0.02137968 -0.02976163
  -0.02676636]
 [-0.0541904   0.02855261 -0.03011782 ... -0.0469832  -0.03957999
  -0.03272272]
 ...
 [-0.00205024  0.04185862  0.02094322 ...  0.02729258  0.00390237
   0.03014388]
 [-0.03209102 -0.01619058  0.03324306 ... -0.00481703  0.02010565
   0.03390007]
 [-0.01414347  0.01477672  0.0322208  ... -0.02485699  0.00733414
   0.0323893 ]]
layers.2.weight: [[ 0.0029046   0.00379972 -0.01255484 -0.00723568  0.00209047 -0.0091457
   0.00156037  0.00235314  0.01110279  0.01412887 -0.01084674 -0.0099458
   0.00306705 -0.0037843   0.01473144  0.01269524  0.00365785 -0.00910295
   0.02163535 -0.01618592 -0.00486723  0.01144045 -0.00887325 -0.00617052
  -0.00106893  0.00537637 -0.00866237  0.00177252 -0.00772669  0.00765949
  -0.00602748  0.00313161]]

Final Loss: 0.2437
Distance Metric: 3.7563
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 410

================================================================================

baselineCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.03011239  0.13165823 -0.02298067 ... -0.10290121  0.13864534
  -0.05737964]
 [-0.05706207  0.10968138 -0.04721011 ... -0.11277208  0.17066804
  -0.07551199]
 [-0.16062665  0.3185874  -0.08975612 ... -0.25723687  0.5164899
  -0.11926588]
 ...
 [-0.05508797  0.11220063 -0.04593616 ... -0.07049379  0.16549496
  -0.03204096]
 [ 0.00192331 -0.00481114  0.01888174 ...  0.0376964  -0.00533219
   0.00247633]
 [-0.11896969  0.2533669  -0.05513745 ... -0.18644302  0.4407047
  -0.12405329]]
layers.1.weight: [[ 0.04782445  0.03351769  0.19386554 ...  0.01465054 -0.03251589
   0.10968674]
 [ 0.02023062  0.05031778  0.12460081 ...  0.03690214 -0.00879017
   0.11412431]
 [ 0.06589252  0.10995177  0.2531456  ...  0.06083421 -0.07456445
   0.25565353]
 ...
 [ 0.05052553  0.08867586  0.2542257  ...  0.0719519  -0.04035442
   0.22708118]
 [ 0.04366166  0.07571571  0.22056171 ...  0.08013132 -0.01987481
   0.17108913]
 [ 0.00293436  0.0225539   0.01165447 ...  0.04066071 -0.00668009
   0.01809535]]
layers.2.weight: [[-0.81273156 -0.5894119  -1.2779033  -0.82207894 -0.5924442  -0.33448437
  -0.33603716 -0.92483914 -0.3600231  -0.33081546 -1.0024016  -0.61086625
  -0.3054955  -0.5559428  -0.5175865  -0.5894373  -0.8610183  -0.27295488
  -1.0733632  -0.99791163 -0.31632313 -0.33463937 -0.34239128 -0.72229296
  -0.6501526  -0.4036775  -0.32743007 -0.3635652  -0.8976724  -1.128621
  -1.0213916  -0.358745  ]]

Final Loss: 0.0010
Distance Metric: 16.3248
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 1999

================================================================================

baselineCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.0069721   0.0206212   0.01943169 ...  0.02971694 -0.00955345
   0.05256101]
 [-0.00093731 -0.00679522  0.00110357 ... -0.00478     0.00341822
  -0.00631464]
 [-0.002076   -0.02758868  0.00453079 ... -0.01172758 -0.00743058
  -0.00746444]
 ...
 [-0.0028387  -0.01813155  0.00414792 ... -0.00454691 -0.00706213
  -0.00204257]
 [ 0.01378904 -0.01027737  0.0008918  ...  0.00040184 -0.00479507
   0.00849569]
 [ 0.00281309  0.00059721  0.00197188 ... -0.0417278   0.00307862
  -0.02176355]]
layers.1.weight: [[ 0.02304361 -0.02671944  0.0601856  ... -0.05667359  0.05113189
   0.09285029]
 [ 0.01882807  0.08343437 -0.01341142 ... -0.01777874  0.06631508
  -0.0399671 ]
 [ 0.05998655  0.07753164 -0.01533548 ...  0.03609368  0.02240217
   0.03056016]
 ...
 [ 0.00867491 -0.0408603   0.01761684 ...  0.02103522  0.00109511
  -0.04405884]
 [-0.00035552 -0.03588329  0.00806421 ...  0.05495975  0.01787225
  -0.14500433]
 [ 0.0604883   0.03425098  0.02198439 ...  0.00753861 -0.03996921
  -0.00830188]]
layers.2.weight: [[-0.3556628   0.13900109  0.09045006  0.2038991  -0.0187714  -0.14494291
  -0.09165508 -0.48796347  0.45068508  0.10217167 -0.05272169  0.00899681
  -0.16768351  0.2905211   0.14790848 -0.03800846  0.0255429  -0.01821299
   0.31572574 -0.16984904  0.25559455  0.11830296 -0.16681878 -0.07953733
  -0.01066151 -0.29971245 -0.08202068  0.14405271  0.1441073   0.46191147
   0.29491222 -0.18634428]]

Final Loss: 0.0003
Distance Metric: 6.7691
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 1999

================================================================================

baselineCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.02988919  0.0090426  -0.01528609 ...  0.04142818  0.03716083
   0.00709747]
 [ 0.01713377  0.04052277 -0.02474408 ...  0.01990755 -0.02561025
   0.04200859]
 [-0.01517536  0.02782673  0.04671918 ... -0.02353634  0.00750542
   0.01359836]
 ...
 [-0.0395057  -0.00165146  0.00154315 ...  0.04718388 -0.02182142
  -0.01794765]
 [-0.04243381  0.03826842  0.02303034 ... -0.01862893 -0.02399184
  -0.0501623 ]
 [-0.02786569 -0.00086957  0.00414779 ...  0.04868134  0.04689787
  -0.01234512]]
layers.1.weight: [[ 0.01586442  0.03646147 -0.02707021 ... -0.02347722  0.02330465
  -0.01486843]
 [ 0.0386835   0.02357187  0.01508608 ...  0.01133357 -0.04357342
   0.01161997]
 [ 0.01815209 -0.00038827 -0.03058772 ... -0.04092867  0.03072554
  -0.01942936]
 ...
 [-0.0130135   0.01464305 -0.04053954 ...  0.03558275 -0.03655222
   0.03532939]
 [-0.02163244  0.02341608  0.02381122 ... -0.03478058 -0.00466801
   0.00394059]
 [-0.02339966 -0.03292898  0.02989938 ... -0.00212405  0.00290562
   0.02259289]]
layers.2.weight: [[ 0.09000935  0.00023549  0.11819363 -0.05208965 -0.07425958 -0.06514885
   0.05485027 -0.06151698 -0.01452866  0.00179098 -0.1131288   0.00906701
   0.09150136 -0.02685423  0.0940005  -0.12885883  0.15571094  0.07450986
   0.00756236 -0.08325758 -0.03615775 -0.1124322  -0.10898805  0.0283514
   0.09180106 -0.04937404 -0.12141091  0.02407881 -0.06658982 -0.02672207
   0.00884106  0.11913567]]

Final Loss: 0.0000
Distance Metric: 4.8325
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 1999

================================================================================

baselineCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.00722366  0.00748486  0.00813866 ... -0.01532883  0.000753
  -0.02540286]
 [ 0.02170786  0.01127607  0.00411293 ... -0.00443914  0.00363106
   0.01630828]
 [ 0.00082675  0.00424613 -0.01701499 ...  0.02448716  0.00301017
   0.0003667 ]
 ...
 [ 0.0239208   0.00400516  0.0227927  ...  0.02087664 -0.0131573
  -0.0225651 ]
 [-0.00238886  0.02569132  0.0064085  ...  0.02631435  0.0262026
  -0.0113386 ]
 [-0.02812984 -0.0132429  -0.00345348 ...  0.02967809 -0.02250223
  -0.0099676 ]]
layers.1.weight: [[ 0.0185348   0.00525032  0.00351677 ...  0.00861746  0.03257439
   0.01875377]
 [ 0.015625    0.00715441 -0.00140484 ...  0.01855451  0.00033685
   0.03088746]
 [ 0.02800942  0.03224329  0.015625   ...  0.01871294  0.00710142
   0.0078125 ]
 ...
 [ 0.00021933 -0.02382998 -0.00315421 ... -0.01925721 -0.01413899
   0.00679086]
 [-0.00208167 -0.00319196  0.01811942 ...  0.00402565 -0.01197754
  -0.0115871 ]
 [ 0.01242264  0.02238313  0.01601331 ...  0.0078125   0.0078125
  -0.0132441 ]]
layers.2.weight: [[-0.3101873  -0.3981775  -0.2644833  -0.24993795 -0.4136361  -0.25
  -0.3159428  -0.35681808 -0.25       -0.41695872 -0.3128041  -0.31285253
  -0.17244923 -0.27826932 -0.43284002 -0.4551213  -0.19206592 -0.36371133
  -0.39945167 -0.413914   -0.42007145 -0.33232492 -0.43649623 -0.32018328
  -0.26863435 -0.24552827 -0.25       -0.31642112 -0.25       -0.25
  -0.40953326 -0.4521952 ]]

Final Loss: 0.0000
Distance Metric: 5.1389
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 1999

================================================================================

baselineCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.02182631 -0.00362369 -0.02374964 ... -0.00918704 -0.00299183
   0.01190848]
 [-0.02175123  0.01814555  0.00452232 ... -0.00885955 -0.01197319
   0.0023115 ]
 [ 0.00996057  0.00182255  0.01571676 ... -0.0040133   0.01190994
  -0.01264276]
 ...
 [-0.00022126  0.0077252   0.02095638 ... -0.01371521 -0.00366132
   0.00040012]
 [ 0.01154684  0.01805314 -0.01590693 ...  0.00750601 -0.02615907
  -0.01276534]
 [ 0.00863559  0.00152208 -0.00954753 ...  0.0033084  -0.01283372
   0.00904018]]
layers.1.weight: [[ 0.08635934  0.06500276  0.01737181 ... -0.00643122 -0.05503911
  -0.05376078]
 [-0.03387404 -0.0516586  -0.08819269 ...  0.07252038 -0.06193607
  -0.03055608]
 [ 0.03588357  0.10438019 -0.05208626 ... -0.02968227  0.03792102
   0.02860908]
 ...
 [ 0.07833305  0.05764317  0.03180003 ...  0.06681526 -0.02917012
   0.10925475]
 [-0.00248182  0.0184786  -0.0897892  ...  0.0524457   0.03043872
   0.05999723]
 [-0.01145538  0.07627364  0.09437614 ... -0.00237214  0.05860903
  -0.08520418]]
layers.2.weight: [[-4.1549826e-01 -2.0229807e-02 -3.0386161e-02 -1.0603305e-01
   1.2830493e-01 -5.4985404e-02 -1.8383026e-01  4.3391037e-01
   2.1913329e-01 -5.3626376e-01 -3.9012814e-03 -1.0312037e-02
   1.6673008e-02 -4.8030671e-01  1.8610895e-01 -5.8136678e-01
  -4.0879318e-01 -3.3941932e-04  1.1151604e-02  7.2832261e-03
   2.6964810e-01 -2.6956323e-01  2.6713425e-02 -2.1768785e-01
  -2.4975413e-02  1.8347952e-01 -1.4089242e-01 -1.6793150e-01
   3.0056857e-02 -4.3943161e-01 -2.4518861e-01 -1.8403685e-02]]

Final Loss: 0.0000
Distance Metric: 6.9330
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 1999

================================================================================

baselineCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.01868857 -0.03887547 -0.01025444 ... -0.01198698  0.03508911
  -0.02813342]
 [ 0.04270563 -0.03895921  0.04505134 ...  0.00934943 -0.01636736
  -0.00799198]
 [-0.04762465  0.04830229 -0.00401374 ...  0.04609907 -0.00733563
  -0.04775104]
 ...
 [ 0.04777234  0.02348927  0.04694403 ...  0.02666637 -0.01789059
  -0.03734962]
 [-0.02430631  0.0212309   0.02165889 ...  0.00686169 -0.00455213
  -0.01131652]
 [ 0.00072679 -0.04502166 -0.01859194 ...  0.03851717 -0.00333258
  -0.03048628]]
layers.1.weight: [[-0.03057985  0.02675314 -0.04727125 ...  0.01066681  0.00034378
  -0.02438951]
 [ 0.0411303   0.03228689 -0.04505523 ... -0.02194134 -0.03336393
   0.04417654]
 [-0.02259137 -0.02266232  0.0370908  ... -0.03366394 -0.04301708
   0.01574095]
 ...
 [ 0.02327459 -0.03794243  0.00802825 ...  0.01901679 -0.04128149
   0.04723274]
 [ 0.02424505 -0.03915522 -0.01321615 ...  0.01124252 -0.04734946
  -0.01975131]
 [ 0.04568025 -0.02593478  0.04698195 ...  0.00501851  0.03002445
   0.00038084]]
layers.2.weight: [[-0.06577658 -0.0451461  -0.04448453 -0.03373678  0.0952324  -0.00368302
   0.10182992  0.09569782 -0.02546952 -0.06235795 -0.06092257  0.11343451
   0.05089888  0.11104505 -0.01236393 -0.08253784 -0.05890033  0.06395802
  -0.02037488  0.02812605 -0.07305323 -0.10145086  0.09036031 -0.12099236
   0.01077005 -0.00516151 -0.11761423 -0.05475669  0.01680551 -0.11736419
  -0.04948254 -0.06028474]]

Final Loss: 0.0000
Distance Metric: 5.1081
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 1999

================================================================================

