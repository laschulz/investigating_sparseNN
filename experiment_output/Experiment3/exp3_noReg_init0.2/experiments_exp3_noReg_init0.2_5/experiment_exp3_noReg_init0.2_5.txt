Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[ 0.18215744 -0.05971599  0.04684201]]]
layers.1.weight: [[[0.06803157 0.1369415 ]]]
layers.2.weight: [[[ 0.22338672 -0.12639771]]]

================================================================================

baselineCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.02435827 -0.01830606 -0.00443117 ...  0.01671107  0.00676773
   0.02640894]
 [ 0.02799744  0.023093    0.00598211 ... -0.02634297  0.0021474
  -0.02038253]
 [-0.01232263  0.01144745 -0.0001959  ... -0.02741918  0.02107635
  -0.00587324]
 ...
 [-0.01951717 -0.02699462  0.00086859 ...  0.00586893 -0.00572327
  -0.01809064]
 [ 0.0090235   0.00404515  0.02048045 ... -0.0167354   0.02375745
   0.01185713]
 [ 0.01294862  0.01226423  0.00975007 ...  0.01121948  0.0209232
  -0.00182509]]
layers.1.weight: [[ 0.02364209  0.00169374  0.00343608 ...  0.02057169  0.01562547
   0.00714783]
 [ 0.00922854 -0.0114022   0.00130413 ...  0.00696583  0.01785989
   0.01882229]
 [-0.01328535  0.00981998 -0.01042812 ... -0.02697673 -0.00502687
   0.0179491 ]
 ...
 [-0.00201586 -0.02270319  0.02383612 ...  0.01013056 -0.0107715
  -0.01699915]
 [ 0.00542927  0.02315571 -0.0050949  ...  0.02686174  0.00172154
   0.00935721]
 [ 0.02049949 -0.01764151 -0.02354238 ...  0.0110664  -0.02842245
   0.00824679]]
layers.2.weight: [[ 0.07514219  0.06229355 -0.03609089 -0.03209797 -0.03699606 -0.08838557
  -0.0640898  -0.02729502  0.06769985 -0.06074524 -0.07579761  0.05332128
   0.06905095  0.00837813  0.02832727  0.07069856  0.03923984  0.0042446
  -0.08258072  0.04174069  0.02889626  0.0089322  -0.01570268  0.05571082
  -0.03637397  0.02758839 -0.0451238   0.00199596  0.02841018  0.08285674
   0.04083496 -0.0739348 ]]

Final Loss: 0.0000
Distance Metric: 3.1354
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 1999

================================================================================

baselineCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.12418226  0.2084678  -0.21845424 ... -0.12205333 -0.09957963
   0.05963666]
 [ 0.05451247 -0.31012708  0.21965984 ...  0.12800269  0.08193462
  -0.23494053]
 [-0.00552056 -0.32122695 -0.12910822 ... -0.15500112 -0.18089063
  -0.05823217]
 ...
 [ 0.10669833  0.27759075  0.15396869 ... -0.01443045  0.18915355
  -0.08165669]
 [ 0.00194446 -0.1845507   0.07503343 ...  0.21678375  0.24719152
   0.09583938]
 [ 0.06607648  0.03923511 -0.19742872 ... -0.34299594 -0.09820261
   0.10798504]]
layers.1.weight: [[ 0.30701607  0.17199813  0.2576698  ...  0.24336651  0.31053704
  -0.26734576]
 [-0.35099208  0.3104355  -0.30769497 ...  0.43013266  0.04122031
   0.03958302]
 [ 0.089817    0.18575272 -0.1605231  ...  0.22228949  0.16438176
  -0.2566174 ]
 ...
 [-0.10244426 -0.1116541   0.05508364 ...  0.07784258  0.05020256
  -0.01041812]
 [-0.08308874  0.1030754  -0.26268026 ... -0.10617802  0.15147935
   0.04852662]
 [ 0.10635098  0.04997608  0.13207388 ...  0.05495708  0.02343587
  -0.11984712]]
layers.2.weight: [[-0.48971507 -0.12888706 -0.1076417   0.097396    0.10440903 -0.45444056
  -0.2525862   0.09434669 -0.09587     0.12086581 -0.1147534   0.1039125
   0.09448179  0.10560458 -0.24316974 -0.5784262   0.09764198  0.09528835
  -0.3143254   0.09785628 -0.2344707  -0.23539448  0.08881294  0.08756685
  -0.415194    0.09793787 -0.25205308 -0.36827153 -0.37076488  0.08912632
   0.09460942  0.09916755]]

Final Loss: 0.0085
Distance Metric: 28.6192
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 1999

================================================================================

baselineCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.02758144 -0.01121967 -0.00958649 ...  0.03807775  0.00691078
  -0.03633851]
 [ 0.00283673  0.02245662 -0.02620496 ...  0.00611961 -0.03570824
   0.01005833]
 [ 0.00314698  0.01110325 -0.00029032 ...  0.00596569 -0.01658862
  -0.00438061]
 ...
 [ 0.02494864 -0.00195998 -0.02223919 ...  0.0178916  -0.01474825
  -0.00250082]
 [ 0.02757372 -0.02642301 -0.03045595 ... -0.00301419  0.04009512
  -0.01109101]
 [-0.02622559  0.03670409 -0.02698322 ...  0.02165861  0.00868736
  -0.03148962]]
layers.1.weight: [[-0.03155249 -0.00694898  0.0125953  ... -0.00503203 -0.04222399
   0.004884  ]
 [-0.0395149   0.03826531  0.02279387 ... -0.02384995  0.00950968
   0.05600247]
 [-0.04612644  0.01690843  0.03806585 ... -0.04456801 -0.02070279
   0.01368865]
 ...
 [ 0.00539374  0.00968976  0.01243862 ... -0.03543716  0.01351751
   0.03957089]
 [-0.02089493 -0.01035004  0.02493556 ... -0.00014003 -0.04715279
   0.0101504 ]
 [-0.00318804  0.00069608  0.03169276 ...  0.02902981  0.03141193
  -0.00379617]]
layers.2.weight: [[ 0.001012   -0.00211598 -0.00540735 -0.00868907  0.0027194   0.00810915
   0.00447114 -0.00645669  0.00365855 -0.01154071  0.00299816 -0.01077629
  -0.00667707 -0.0063995   0.00307496  0.00957436  0.00429022 -0.0005306
   0.00053045  0.01704808 -0.00112385  0.00307399 -0.01172548 -0.01977253
  -0.00011688 -0.00802441  0.00169667  0.00638242  0.00146541  0.00499274
  -0.00940446 -0.01403498]]

Final Loss: 0.2491
Distance Metric: 4.2689
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 125

================================================================================

baselineCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.0236315  -0.02961461  0.02051793 ... -0.02356039  0.01249481
  -0.02192339]
 [-0.04493811 -0.12110531 -0.03283612 ... -0.0331714  -0.03517754
  -0.02210503]
 [-0.01631738 -0.05902065 -0.00841746 ... -0.00576728 -0.01165821
   0.02029241]
 ...
 [ 0.01653815  0.11779056  0.03400631 ...  0.01699605  0.02144819
   0.01402146]
 [-0.03033266 -0.1429722  -0.04372386 ...  0.01775927 -0.00887277
   0.01446549]
 [ 0.01871318  0.02154721 -0.00562777 ... -0.01702768  0.00164382
   0.01688604]]
layers.1.weight: [[-0.01687304  0.01990779  0.0133586  ... -0.03863218  0.02113718
  -0.01253805]
 [-0.02473936  0.00170414  0.02501238 ... -0.03484881  0.0247694
  -0.02155781]
 [-0.03829522  0.05365028  0.0228001  ... -0.0890094   0.05415773
  -0.02540735]
 ...
 [-0.0248546  -0.00298534 -0.00434836 ... -0.0376314  -0.00143309
  -0.03323587]
 [-0.00460793  0.02501002  0.00965975 ... -0.0732453   0.03228799
  -0.02186666]
 [ 0.01734987 -0.01458233  0.01742489 ... -0.04324378  0.0064418
   0.01149486]]
layers.2.weight: [[-0.05613374 -0.22897464 -0.65096647 -0.4342296  -0.6772155  -0.73940384
  -0.5449329  -0.31881294 -0.6618069  -0.38754347 -0.29520413 -0.68571365
  -0.43618974 -0.5890694  -0.36949912 -0.5389579  -0.5199744  -0.2338634
  -0.4492992  -0.49003792 -0.28150913 -0.24263042 -0.61018705 -0.7078
  -0.15254116 -0.7493451  -0.3718154  -0.15906495 -0.62783945 -0.19484282
  -0.44604862 -0.13232052]]

Final Loss: 0.0003
Distance Metric: 9.8689
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 1999

================================================================================

baselineCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.00452679 -0.00823137  0.0159487  ...  0.00228062 -0.0287778
   0.00609147]
 [-0.00448235  0.01847623 -0.02501762 ... -0.02297168  0.02196849
   0.02006274]
 [-0.00110855 -0.00603709  0.00318449 ... -0.01192297 -0.00537595
   0.00928964]
 ...
 [-0.01516225  0.01766017  0.00405582 ... -0.01989302 -0.02359161
  -0.02482129]
 [-0.01287362 -0.02414997  0.01292992 ... -0.01004719  0.02667941
  -0.01639645]
 [-0.00341402 -0.0138238   0.00885741 ... -0.02917833  0.0045281
  -0.00591228]]
layers.1.weight: [[-0.01395978  0.02922497  0.01718917 ...  0.03201638  0.01700177
  -0.01697487]
 [ 0.03421305  0.03534354 -0.00130785 ...  0.0078125  -0.00047301
   0.01491562]
 [ 0.02494361  0.02127155  0.03000798 ... -0.01169809 -0.02184113
   0.02160082]
 ...
 [ 0.03350116  0.01411438  0.00160172 ...  0.0091593   0.00647591
   0.01198201]
 [ 0.0078125   0.03016923  0.01706735 ... -0.01312367  0.02103575
  -0.02527235]
 [-0.01377241 -0.00258602 -0.00099489 ...  0.03203604  0.0078125
  -0.0142926 ]]
layers.2.weight: [[-0.25       -0.30140522 -0.25       -0.39168724 -0.33459625 -0.4377819
  -0.40975672 -0.36080703 -0.36371383 -0.33866683 -0.25       -0.33756885
  -0.3263151  -0.3869917  -0.37867993 -0.41043526 -0.30812308 -0.36877415
  -0.32665485 -0.35638526 -0.28415924 -0.39560786 -0.25       -0.31277925
  -0.37660173 -0.28275427 -0.29002854 -0.34490144 -0.25       -0.26273224
  -0.22272861 -0.27192137]]

Final Loss: 0.0000
Distance Metric: 5.4263
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 1999

================================================================================

baselineCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-0.02261866  0.0033788  -0.02390273 ...  0.01283156  0.00576723
   0.00155405]
 [ 0.01275309 -0.00605854  0.01775961 ... -0.00334557  0.00206974
   0.01727987]
 [ 0.00905043 -0.00280012  0.02852323 ...  0.01158172  0.03462208
   0.00592138]
 ...
 [-0.00536052 -0.01083012 -0.01045704 ... -0.00835927 -0.01709308
   0.00899988]
 [ 0.00904138 -0.00539087 -0.00719731 ... -0.00638015  0.01403548
   0.00292343]
 [-0.00532733  0.00157827 -0.00112524 ... -0.01640363 -0.03053996
  -0.00135721]]
layers.1.weight: [[-0.06827228  0.04516122  0.11178918 ... -0.03964931  0.0218885
  -0.03207272]
 [-0.01174657 -0.00300087 -0.04360378 ... -0.01786827 -0.02152461
  -0.02591817]
 [-0.02418692 -0.03966912 -0.0098316  ... -0.02518813  0.00502772
   0.02605119]
 ...
 [-0.0590952  -0.02921149  0.03606275 ... -0.04822547 -0.03023552
   0.0360561 ]
 [ 0.09354555  0.03278861 -0.07599072 ...  0.04115205 -0.03887642
  -0.08114985]
 [-0.10267916 -0.04744527  0.01774644 ... -0.0330053  -0.03490577
   0.00569451]]
layers.2.weight: [[-0.03084149 -0.20168823 -0.1150934  -0.29071856  0.3696044  -0.3576053
  -0.0188766  -0.12702939  0.3648725  -0.01689794 -0.6938318   0.22712868
   0.09325451  0.309236   -0.14614002  0.15578784  0.25809574  0.3525183
   0.43607995  0.36808223 -0.50145257  0.06015006  0.01551053  0.12015975
  -0.23687248 -0.20642737 -0.05288672  0.23328926 -0.2965847  -0.3564557
   0.20252146  0.17055914]]

Final Loss: 0.0000
Distance Metric: 7.1822
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 1999

================================================================================

baselineCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.03347889 -0.0254961  -0.04129328 ...  0.04977397 -0.03985703
   0.04804479]
 [ 0.02259321  0.04813762 -0.0086654  ...  0.03758673 -0.04248619
   0.04695848]
 [ 0.04089669 -0.00377141 -0.03665907 ...  0.02814984 -0.03109243
  -0.01601644]
 ...
 [ 0.03219733  0.02588213 -0.03482169 ...  0.02393214  0.04674461
  -0.03751692]
 [ 0.0303467   0.00152219 -0.02481612 ...  0.04188749  0.03428124
  -0.0344996 ]
 [-0.01638088  0.00564575 -0.02221304 ... -0.02211928 -0.0135308
  -0.00997888]]
layers.1.weight: [[ 0.03657701  0.0368083  -0.02300373 ... -0.02739514 -0.01236913
  -0.02682072]
 [-0.01972766 -0.00282895  0.01520626 ...  0.03302638  0.01820276
  -0.03663811]
 [ 0.01039987  0.01409159  0.03143687 ...  0.03588153  0.01746697
   0.02309548]
 ...
 [ 0.00592838 -0.04117952  0.         ... -0.0008519  -0.00473459
   0.01739035]
 [-0.00805476 -0.01527542 -0.03732982 ...  0.0049      0.00288108
  -0.03877556]
 [-0.02032918  0.03243631  0.00445085 ...  0.01172647 -0.0067618
   0.03054945]]
layers.2.weight: [[ 0.07636669 -0.03488562  0.06161564 -0.07775423  0.04880805  0.00977254
   0.07207354 -0.07357591 -0.05873124  0.06562353  0.00155846  0.04373457
   0.06553749 -0.01014539 -0.02094791 -0.05201429 -0.05536867  0.01014746
   0.00425455  0.0451441  -0.03017927  0.04380824  0.08324299 -0.03658473
  -0.00524373 -0.09047909  0.06291097  0.00865901 -0.05098609  0.06982682
  -0.07945568  0.04607585]]

Final Loss: 0.0000
Distance Metric: 4.8085
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 1999

================================================================================

baselineCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.15141995 -0.1002494   0.03929203 ...  0.04590697 -0.14108771
   0.27790937]
 [ 0.48842213 -0.6713004   0.06102278 ...  0.01381473  0.22834773
   0.1652982 ]
 [ 0.56547815 -0.4260789   0.04903672 ...  0.29018712 -0.07659446
  -0.17905085]
 ...
 [-0.23857066  0.05946045  0.13137455 ...  0.28646338 -0.1745096
  -0.20802255]
 [ 0.16746564 -0.52873677  0.08348516 ... -0.09544606  0.08005883
  -0.09769301]
 [-0.1528354  -0.27313477  0.12905975 ... -0.00486539  0.076988
   0.14477056]]
layers.1.weight: [[-0.00345561 -0.19576804  0.28780466 ...  0.11424535 -0.24058652
   0.2130974 ]
 [-0.02483853  0.03477898  0.1513467  ...  0.02969377 -0.25134885
  -0.00344258]
 [-0.15248668 -0.19262347  0.04466502 ...  0.02764261 -0.18348242
   0.62679094]
 ...
 [-0.12474299 -0.19935736  0.08056549 ...  0.12309863 -0.08195069
  -0.05559904]
 [ 0.0369329   0.2566599   0.04660783 ... -0.264296   -0.01931641
  -0.00150719]
 [-0.02082377 -0.19731206 -0.07115359 ... -0.23931254 -0.5129141
   0.17631707]]
layers.2.weight: [[-0.12805812 -0.323032    0.19429031  0.1472318  -0.13518806 -0.29840812
  -0.3282753  -0.19045345 -0.22780484 -0.17241888  0.15552825 -0.16833888
  -0.16770944 -0.19385935  0.19112195 -0.13893315 -0.4485095   0.16069523
  -0.15674976  0.1312832   0.13317813  0.17716157 -0.27094254 -0.24269485
   0.13918082  0.14648135  0.18197599  0.1387731   0.17538425 -0.19682357
  -0.34304044  0.13627112]]

Final Loss: 0.1897
Distance Metric: 40.9165
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 1999

================================================================================

baselineCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.07045217  0.03498113 -0.0377893  ...  0.02821941  0.00861741
   0.00217888]
 [ 0.13603324 -0.13989536  0.03643423 ...  0.0069904   0.01235362
   0.01226929]
 [-0.22318758  0.2506699  -0.06950834 ...  0.01951112  0.01423011
   0.00174514]
 ...
 [ 0.15761594 -0.1606887   0.04597165 ... -0.01067152  0.02556208
   0.00831348]
 [ 0.00682761  0.0420757  -0.00488156 ... -0.05058811  0.05342073
  -0.03109959]
 [ 0.01439641 -0.00332551  0.02909845 ...  0.1158854  -0.12168777
   0.04239867]]
layers.1.weight: [[ 0.0069259  -0.01586527 -0.0333188  ... -0.00955589 -0.03752921
   0.03307694]
 [-0.01926851 -0.04813397 -0.03401879 ...  0.02024821  0.01321808
   0.04791974]
 [-0.03154054  0.02555789 -0.00754987 ...  0.00572821  0.01167679
  -0.01789314]
 ...
 [-0.01723786  0.00706098  0.04402215 ...  0.01554432  0.03788995
   0.00905649]
 [-0.01237735  0.04990523 -0.01972703 ... -0.00405295 -0.0140905
   0.00373525]
 [-0.08964031  0.17224571 -0.2747422  ...  0.17287433 -0.05572939
  -0.00643695]]
layers.2.weight: [[-0.0010119   0.07118969  0.64790857  0.01378676  0.16442253  0.00431634
  -0.02770754 -0.04371363  0.05561964  0.16586064  0.04130013 -0.03031177
  -0.51080203  0.035094   -0.0078066  -0.01626984 -0.01239049  0.02591434
   0.01018962 -0.18027076  0.04235015 -0.07728778  0.01570061  0.25360236
  -0.01377829  0.01428227  0.16632935 -0.23564741  0.0231378   0.19260803
   0.04371399 -0.4569728 ]]

Final Loss: 0.0000
Distance Metric: 13.5108
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 1999

================================================================================

