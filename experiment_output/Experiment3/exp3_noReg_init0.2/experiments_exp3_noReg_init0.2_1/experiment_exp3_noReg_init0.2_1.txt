Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.17835541  0.04079077 -0.00449364]]]
layers.1.weight: [[[0.21136792 0.07794283]]]
layers.2.weight: [[[0.12111546 0.10689389]]]

================================================================================

baselineCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.00213379  0.00762023 -0.0162429  ...  0.02065486 -0.01284493
   0.00693647]
 [-0.02039748 -0.00225792  0.01096878 ... -0.01058257  0.00584093
   0.00195313]
 [-0.00479947  0.01763769 -0.01358179 ... -0.01738754  0.00191363
   0.01288577]
 ...
 [-0.0189606   0.01549406  0.01259799 ...  0.01762756 -0.02303751
  -0.02941325]
 [-0.01610074  0.00430566  0.01451142 ...  0.01588157 -0.00465981
   0.02426027]
 [-0.02253137 -0.02547115 -0.01567561 ...  0.00740162 -0.01102753
   0.02170204]]
layers.1.weight: [[-0.00268377 -0.00027818  0.01667668 ... -0.00314375  0.02364449
   0.02715985]
 [-0.0162887   0.01356668  0.01624911 ... -0.01209518  0.01703363
   0.0217396 ]
 [-0.00466079 -0.00787618 -0.00816786 ...  0.0251738   0.01785075
   0.0133975 ]
 ...
 [ 0.01997947 -0.02377018 -0.00536455 ... -0.00373076 -0.00879613
   0.01523002]
 [ 0.00637296 -0.00650917  0.02045577 ...  0.014392   -0.01563206
  -0.01766326]
 [-0.02117006  0.01284188 -0.0119097  ...  0.00279275  0.02823039
  -0.01174678]]
layers.2.weight: [[-0.06494553 -0.05487347  0.0900896   0.05705652  0.02752115 -0.00164199
  -0.04226454 -0.03997608  0.05876042 -0.02610454  0.03336477  0.08793247
  -0.06046488 -0.01360202  0.07274229 -0.01254432 -0.03656453  0.00112011
   0.04422572  0.07189435 -0.03320174  0.04814186 -0.02444513  0.00286996
  -0.00424394  0.05784767 -0.00493234  0.04292559 -0.02817942 -0.05663342
   0.01115173  0.03537549]]

Final Loss: 0.0000
Distance Metric: 3.0405
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 1999

================================================================================

