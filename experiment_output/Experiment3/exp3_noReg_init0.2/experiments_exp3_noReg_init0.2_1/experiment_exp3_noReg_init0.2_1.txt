Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.17835541  0.04079077 -0.00449364]]]
layers.1.weight: [[[0.21136792 0.07794283]]]
layers.2.weight: [[[0.12111546 0.10689389]]]

================================================================================

baselineCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.00213379  0.00762023 -0.0162429  ...  0.02065486 -0.01284493
   0.00693647]
 [-0.02039748 -0.00225792  0.01096878 ... -0.01058257  0.00584093
   0.00195313]
 [-0.00479947  0.01763769 -0.01358179 ... -0.01738754  0.00191363
   0.01288577]
 ...
 [-0.0189606   0.01549406  0.01259799 ...  0.01762756 -0.02303751
  -0.02941325]
 [-0.01610074  0.00430566  0.01451142 ...  0.01588157 -0.00465981
   0.02426027]
 [-0.02253137 -0.02547115 -0.01567561 ...  0.00740162 -0.01102753
   0.02170204]]
layers.1.weight: [[-0.00268377 -0.00027818  0.01667668 ... -0.00314375  0.02364449
   0.02715985]
 [-0.0162887   0.01356668  0.01624911 ... -0.01209518  0.01703363
   0.0217396 ]
 [-0.00466079 -0.00787618 -0.00816786 ...  0.0251738   0.01785075
   0.0133975 ]
 ...
 [ 0.01997947 -0.02377018 -0.00536455 ... -0.00373076 -0.00879613
   0.01523002]
 [ 0.00637296 -0.00650917  0.02045577 ...  0.014392   -0.01563206
  -0.01766326]
 [-0.02117006  0.01284188 -0.0119097  ...  0.00279275  0.02823039
  -0.01174678]]
layers.2.weight: [[-0.06494553 -0.05487347  0.0900896   0.05705652  0.02752115 -0.00164199
  -0.04226454 -0.03997608  0.05876042 -0.02610454  0.03336477  0.08793247
  -0.06046488 -0.01360202  0.07274229 -0.01254432 -0.03656453  0.00112011
   0.04422572  0.07189435 -0.03320174  0.04814186 -0.02444513  0.00286996
  -0.00424394  0.05784767 -0.00493234  0.04292559 -0.02817942 -0.05663342
   0.01115173  0.03537549]]

Final Loss: 0.0000
Distance Metric: 3.0405
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 1999

================================================================================

baselineCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.01959586 -0.02400878 -0.01880422 ... -0.00565845 -0.00496525
  -0.01877237]
 [ 0.00946775 -0.01463427 -0.0124016  ... -0.01227525 -0.02949742
   0.00353794]
 [-0.01337985  0.0073627  -0.00095431 ... -0.04679991 -0.00630331
   0.00287829]
 ...
 [-0.00053131 -0.00136958  0.02723198 ... -0.02286235  0.00873009
   0.00064688]
 [-0.02692453 -0.02570675 -0.02109043 ...  0.00251841  0.01464713
   0.00250599]
 [-0.00681536  0.0029871   0.00982568 ... -0.04616666  0.02418942
  -0.03472969]]
layers.1.weight: [[ 0.00358468  0.01757282  0.0317979  ...  0.02003379  0.02339547
   0.03595852]
 [-0.00825043 -0.02218632 -0.02009846 ...  0.00988233  0.02217281
  -0.01675888]
 [ 0.01016606  0.02761706  0.01175106 ... -0.00156789 -0.00239035
   0.00039611]
 ...
 [ 0.00525242  0.00320875  0.00828713 ... -0.01396574 -0.02564373
   0.03905128]
 [ 0.02848125  0.01513896  0.02108329 ... -0.00849793  0.02489001
   0.03446871]
 [ 0.03299711  0.00072357 -0.01906331 ...  0.03319269 -0.01641668
   0.03685039]]
layers.2.weight: [[-0.3636879  -0.1694597  -0.24581273 -0.23586997 -0.23553674 -0.31952786
  -0.38720337 -0.41465765 -0.3932285  -0.3043219  -0.17620893 -0.36935145
  -0.35416794 -0.35853314 -0.3567913  -0.19809575 -0.19807482 -0.36786062
  -0.36569795 -0.274683   -0.26802897 -0.26581144 -0.21957697 -0.4263834
  -0.30635783 -0.3760834  -0.23987436 -0.21561249 -0.2749452  -0.29946142
  -0.21581097 -0.29782704]]

Final Loss: 0.0004
Distance Metric: 5.4532
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 1999

================================================================================

baselineCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-0.01126168 -0.01544146  0.00914177 ...  0.02031126 -0.00977955
   0.04695551]
 [-0.01400083  0.0438642  -0.00286154 ... -0.00015944 -0.01210521
  -0.03505193]
 [-0.00247216 -0.00736445 -0.01555894 ... -0.01573106  0.0010614
  -0.01468597]
 ...
 [ 0.00087466  0.01569116 -0.00108313 ... -0.00211416 -0.01055185
  -0.00903508]
 [ 0.00626283  0.00651152 -0.00704708 ...  0.04297647  0.00561278
   0.00309419]
 [-0.00898631  0.0006996   0.02197956 ... -0.00879372  0.01611663
   0.00880087]]
layers.1.weight: [[-0.01036413  0.05939489  0.01135985 ... -0.01227481  0.00471698
  -0.06160695]
 [-0.01850272 -0.00712347  0.01902788 ...  0.01489848 -0.07129131
   0.01819706]
 [-0.04673295 -0.00521964 -0.05541037 ...  0.01913518 -0.04415063
  -0.00288003]
 ...
 [-0.01634817  0.01767479 -0.02263782 ... -0.01116011 -0.04204668
  -0.01676463]
 [ 0.0438985   0.04687252 -0.03591618 ...  0.07933198  0.01162064
  -0.05295625]
 [-0.00265685  0.07219787 -0.02276155 ... -0.03938855  0.00964848
   0.07844827]]
layers.2.weight: [[-0.1598514   0.2171303  -0.4571931   0.01137457 -0.11971911 -0.26871556
   0.05590852 -0.5931973   0.0708698  -0.44858903  0.0563478  -0.79261774
   0.00518148  0.00446812 -0.2579905   0.44327077 -0.02179699  0.21508642
  -0.20690173 -0.27137798  0.18022121  0.15990204 -0.17681697 -0.04519306
  -0.00201166 -0.03646274 -0.00718484 -0.32471463  0.08576132  0.04248682
  -0.11046652  0.00394116]]

Final Loss: 0.0000
Distance Metric: 6.9835
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 1999

================================================================================

baselineCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.02447562  0.02683519  0.01142515 ... -0.00052852 -0.01622169
  -0.01269417]
 [-0.01956187  0.02121876  0.00902678 ... -0.02232313  0.00175244
   0.01700378]
 [-0.017437    0.01807701 -0.00105755 ... -0.0070092   0.01956486
   0.00561884]
 ...
 [ 0.01088769 -0.01453164 -0.01797726 ... -0.01709704 -0.00781329
   0.01082045]
 [-0.0110513  -0.01991597  0.02756017 ... -0.0271303   0.00155301
  -0.00497761]
 [ 0.02125785  0.01062489 -0.01947762 ...  0.00975024  0.02248895
  -0.02065128]]
layers.1.weight: [[ 0.03137751  0.00823132  0.02247016 ...  0.00982035 -0.00433748
  -0.00984502]
 [ 0.03653188  0.00603512  0.00683953 ...  0.01997416  0.01291004
   0.00306548]
 [-0.00882392 -0.01485022  0.03591258 ...  0.00154642 -0.00333608
   0.00798996]
 ...
 [ 0.01100631  0.00341819 -0.02000451 ... -0.01191915  0.02211533
  -0.01392922]
 [ 0.01201759  0.00885143 -0.01546486 ...  0.00445352  0.0162479
   0.00344078]
 [ 0.03127615  0.01247182 -0.01126452 ...  0.00727982 -0.00332623
  -0.02002884]]
layers.2.weight: [[-0.36115023 -0.33439058 -0.35867107 -0.25244874 -0.32546413 -0.3917515
  -0.26892972 -0.2488436  -0.18750209 -0.33518687 -0.27070478 -0.13995326
  -0.3321402  -0.2275318  -0.24017927 -0.29589498 -0.20104189 -0.40223235
  -0.16000326 -0.19384754 -0.1489809  -0.33996236 -0.36081088 -0.2783554
  -0.26272953 -0.2640614  -0.29339018 -0.2502369  -0.29536965 -0.38242364
  -0.30313674 -0.32127646]]

Final Loss: 0.0000
Distance Metric: 4.8539
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 1999

================================================================================

baselineCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.00919634 -0.00030831  0.00570535 ...  0.01201014  0.00169564
  -0.01761676]
 [-0.0280879  -0.00855044  0.0047521  ...  0.01228422  0.00617386
   0.00847215]
 [-0.00869725 -0.00585678  0.00508166 ... -0.00281585 -0.00051324
  -0.00382541]
 ...
 [-0.00382817  0.00460275  0.0026371  ...  0.00181059  0.00066602
   0.00953934]
 [-0.0014008   0.00754227  0.00341182 ... -0.00525045  0.01106187
  -0.01485419]
 [-0.00631269 -0.00615952 -0.00237563 ... -0.00873718 -0.00118221
   0.00296773]]
layers.1.weight: [[-0.00268565  0.03375032  0.05272845 ... -0.04898309 -0.01877634
  -0.00830408]
 [ 0.041976   -0.02996361 -0.03066557 ...  0.00637481  0.05807358
  -0.00990473]
 [ 0.07801121 -0.03445248 -0.09029863 ...  0.05508444  0.0658439
   0.01993631]
 ...
 [-0.06605302 -0.03118571  0.00981162 ...  0.01732241  0.04218002
  -0.00418799]
 [-0.01736129  0.02597108 -0.03992326 ... -0.04921054  0.04607521
  -0.09472319]
 [ 0.02307353 -0.00412069 -0.04713212 ...  0.00449404  0.0009849
   0.01247359]]
layers.2.weight: [[ 0.1021888   0.11472432 -0.09478322  0.4884177  -0.1186158  -0.00624736
   0.134533   -0.25058937  0.069083   -0.00506549  0.13886023  0.08278935
  -0.32910728  0.00058372 -0.07999131  0.11658766  0.          0.06775425
  -0.39794523 -0.1658499   0.28934026  0.37328902  0.4546448  -0.54363745
  -0.14938633 -0.14126234  0.4351266  -0.01239385  0.14007764 -0.1652494
  -0.00415286  0.00188124]]

Final Loss: 0.0000
Distance Metric: 6.7770
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 1999

================================================================================

baselineCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.0396487   0.01773288 -0.03205051 ...  0.00435194  0.00551578
   0.00559294]
 [ 0.04349136  0.03770362  0.02894284 ...  0.00635387 -0.04360921
  -0.03573138]
 [ 0.00308718  0.03529692  0.02102685 ...  0.04750974 -0.01370647
  -0.01240449]
 ...
 [-0.01264987 -0.02813531 -0.00393845 ... -0.04286711 -0.00773226
   0.04102827]
 [ 0.0339918  -0.0319472   0.00755588 ...  0.02551728  0.03399847
  -0.02530539]
 [-0.02231336 -0.02496488  0.00837527 ...  0.00688831 -0.01083824
   0.03466811]]
layers.1.weight: [[ 0.01416023  0.01211271 -0.01815496 ... -0.0140645  -0.03367748
   0.02291095]
 [ 0.01062724 -0.01933964 -0.02709277 ...  0.01093846 -0.01004509
   0.04361785]
 [-0.01040386  0.01558667 -0.02271061 ... -0.04441712 -0.03560708
  -0.00651388]
 ...
 [-0.02470495  0.02739597  0.00859412 ...  0.01754884  0.00194984
  -0.03489937]
 [ 0.04254673 -0.0413339  -0.01232457 ... -0.02136684 -0.0188629
   0.03121664]
 [-0.04111073  0.01318462  0.01575526 ...  0.01745795 -0.00746386
   0.0004687 ]]
layers.2.weight: [[-0.1298777   0.12215524  0.09413205 -0.11392538  0.00943211 -0.12912372
  -0.12312281  0.13385811  0.10819399 -0.0992424  -0.02749009  0.11997026
   0.09127864 -0.01018859 -0.0176651   0.11695298  0.10109363  0.12375307
   0.04109691  0.11461195  0.10082398 -0.1429974   0.05228757  0.0251268
  -0.06733764  0.10953651  0.06376103  0.0903326  -0.1294742   0.10974663
   0.13040794  0.00368415]]

Final Loss: 0.0000
Distance Metric: 5.2905
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 1999

================================================================================

baselineCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.02759734 -0.02536565 -0.0267636  ... -0.03953035 -0.04380468
  -0.00614679]
 [ 0.01369693  0.01173455  0.00131321 ... -0.03567881 -0.02733929
   0.00137468]
 [-0.01837044 -0.0304842   0.03573903 ... -0.04048046  0.03803232
   0.03134048]
 ...
 [-0.01408575 -0.03895044 -0.03879788 ... -0.02348686  0.03705914
   0.00946548]
 [ 0.01183246  0.00736227  0.02115709 ... -0.01838074 -0.00737016
   0.01176485]
 [-0.01812602  0.01608155  0.01856748 ...  0.01889032  0.03326001
   0.0267492 ]]
layers.1.weight: [[-0.03467444  0.01476569  0.03922819 ...  0.02652256 -0.01434824
  -0.01217184]
 [-0.01793467  0.03697257  0.00382877 ... -0.00864349 -0.0137901
   0.01404168]
 [-0.01437909 -0.01607566 -0.00147135 ... -0.03775106  0.03776008
   0.00895556]
 ...
 [-0.03606494  0.04158715  0.01131603 ... -0.00138647  0.02769261
  -0.00625857]
 [ 0.0015778  -0.04471279  0.03263932 ...  0.01432299 -0.02667013
  -0.02166622]
 [ 0.01281386  0.04452815 -0.02353679 ... -0.04162533  0.0171877
   0.01003828]]
layers.2.weight: [[-0.1288825  -0.09763249 -0.08461754 -0.07823083 -0.04389061  0.07118271
   0.03724899 -0.09418536 -0.11857255  0.00812865  0.05202107 -0.01761174
  -0.11679364  0.03766097 -0.13079531  0.11046406  0.05896104 -0.11818039
  -0.12531245 -0.03730726 -0.09970389 -0.0681687   0.05462521 -0.10564365
  -0.00606686  0.00598852 -0.0667014   0.03134404 -0.13389826 -0.05355187
   0.10362382 -0.1274381 ]]

Final Loss: 0.0000
Distance Metric: 4.8253
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 1999

================================================================================

baselineCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.02078505 -0.01546735  0.24323434 ... -0.01407364 -0.33059052
  -0.12948383]
 [-0.12855673  0.3151081  -0.01252633 ... -0.16603324 -0.05358672
  -0.11508372]
 [ 0.26466605 -0.32469156  0.08006322 ...  0.00844301 -0.08411755
  -0.20781036]
 ...
 [ 0.02259582  0.1860301  -0.12912236 ...  0.19344433 -0.18576421
  -0.20773984]
 [ 0.07387649 -0.06204959 -0.19355004 ...  0.14562012 -0.18292685
  -0.11319371]
 [ 0.0024652  -0.07115798  0.0987026  ... -0.24833012  0.20070462
  -0.0322783 ]]
layers.1.weight: [[ 0.17183259  0.07151064  0.08140884 ...  0.07880531  0.00303416
  -0.16944796]
 [ 0.03432955  0.32125357  0.10622559 ...  0.25616848  0.03751872
  -0.01909145]
 [ 0.16215672  0.1893516  -0.00275118 ...  0.14979273  0.03042648
   0.11758088]
 ...
 [ 0.03094368 -0.23608325  0.1682264  ...  0.41368297 -0.18968385
  -0.21265604]
 [-0.17932601  0.13710263 -0.07375963 ... -0.08835908  0.28486055
   0.09585594]
 [ 0.25328204 -0.0907125  -0.25042826 ...  0.04374641 -0.22887363
   0.092194  ]]
layers.2.weight: [[ 0.09030256 -0.1976198  -0.18794228  0.10194466  0.0875555   0.14452232
   0.1569671  -0.508195    0.1008378   0.09375066 -0.17852046  0.09791194
  -0.11493066  0.08581681  0.09659661  0.10447398 -0.62218165  0.1043786
  -0.10748167  0.09717141  0.08608726 -0.10065734  0.12541658  0.10025214
  -0.3283964  -0.29195648  0.09885974 -0.20454381  0.10218349 -0.2696412
   0.10616304  0.09190491]]

Final Loss: 0.0072
Distance Metric: 26.6877
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 1999

================================================================================

baselineCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.00489987  0.02306502  0.00312323 ...  0.00205501  0.03846873
  -0.02612788]
 [-0.01121184  0.03550588 -0.00176533 ... -0.01083635  0.00756222
   0.0211009 ]
 [ 0.00726655  0.01123379 -0.02235785 ... -0.00839775 -0.01658762
   0.02838739]
 ...
 [ 0.01076728 -0.01705326  0.02255727 ... -0.01471464  0.02205293
   0.00052474]
 [-0.03632412 -0.01659932  0.01574872 ... -0.01714896  0.0052662
   0.01621282]
 [ 0.02478824  0.01959659  0.00590294 ... -0.00605087  0.00593028
  -0.01129481]]
layers.1.weight: [[-0.04340961  0.04068088  0.02055225 ... -0.03512735  0.02880663
   0.01200659]
 [ 0.0050247   0.03950109 -0.0014405  ... -0.04984777  0.03339015
  -0.0148537 ]
 [ 0.00076156 -0.04270091  0.04459205 ... -0.03651552  0.05195566
  -0.02400144]
 ...
 [ 0.00734959  0.0434786   0.01535704 ... -0.01094434 -0.033663
   0.015308  ]
 [-0.03286305 -0.02609082  0.03966226 ... -0.02864767 -0.04571823
  -0.0066559 ]
 [-0.04321916  0.02548558  0.04878987 ...  0.01867433  0.02843247
   0.04508276]]
layers.2.weight: [[-0.00107771  0.01363517  0.00198246 -0.0058367  -0.00090402  0.00739335
  -0.01376755 -0.00197877  0.00511893 -0.01478792 -0.00087768  0.00444779
  -0.01388217  0.01319025 -0.01345006 -0.01095189 -0.00197314  0.00692766
  -0.02880466 -0.01337298  0.00176137 -0.01421023 -0.01020322  0.00645903
  -0.00425328  0.0020631  -0.01750289 -0.00387303  0.00672467  0.00386174
   0.01423398 -0.02734001]]

Final Loss: 0.2211
Distance Metric: 4.2828
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 175

================================================================================

