Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.1287463  -0.09171551 -0.07787361]]]
layers.1.weight: [[[-0.21395592  0.17209068]]]
layers.2.weight: [[[-0.17255014  0.22421281]]]

================================================================================

baselineCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.02972268  0.02074325 -0.01387409 ...  0.01253077  0.01354871
   0.02729126]
 [ 0.0068832  -0.01467879 -0.01111699 ... -0.01084211  0.01205792
  -0.01580895]
 [-0.0277852  -0.01937056 -0.00830079 ...  0.02137988  0.02029693
  -0.01621203]
 ...
 [ 0.00226836  0.00951383  0.0212095  ... -0.02870375  0.00391966
   0.02747277]
 [ 0.01705282  0.00685038  0.01448826 ...  0.02090087  0.00620872
  -0.0051541 ]
 [ 0.01253997 -0.01985061  0.0052318  ... -0.02983377 -0.02840533
  -0.0010024 ]]
layers.1.weight: [[-0.00646921  0.02018994 -0.01841434 ... -0.01192068 -0.0036685
  -0.02585616]
 [ 0.00953299  0.02030904  0.01490474 ...  0.02346323  0.0201408
   0.00649713]
 [-0.01808359  0.00569438 -0.00036576 ... -0.02326477  0.02157161
   0.02336745]
 ...
 [-0.02458226 -0.0288485  -0.0196827  ...  0.00082189  0.01880387
  -0.01319273]
 [-0.01030213  0.01656631  0.00942787 ...  0.02576306 -0.01043891
  -0.00808777]
 [ 0.02862528 -0.02412853 -0.00448435 ...  0.01340411  0.02002293
   0.01348406]]
layers.2.weight: [[ 0.00010651 -0.07895661 -0.02873865  0.03585929 -0.07293653  0.06517543
   0.0758978   0.02355136  0.07307839 -0.05398481 -0.02686802  0.04921499
  -0.02923906  0.03514754  0.07332494  0.00704907  0.06763462 -0.01572016
   0.02575226 -0.02557834  0.06166076 -0.01505629 -0.03921458  0.03471009
  -0.09475248  0.06307745 -0.06162161 -0.00908433  0.00118397 -0.00810173
  -0.00090918 -0.07727409]]

Final Loss: 0.0000
Distance Metric: 3.2537
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 1999

================================================================================

baselineCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.14181408  0.24996816  0.08201164 ...  0.06629416 -0.11302233
   0.01611744]
 [-0.23412135  0.03719322 -0.17072652 ...  0.28293613 -0.04326679
   0.01880475]
 [ 0.15299962 -0.02938855  0.26021874 ...  0.25062263  0.22040994
   0.18532561]
 ...
 [-0.21773896 -0.02311127  0.18957755 ...  0.07956621  0.1060221
   0.01971133]
 [ 0.0852237  -0.13895528 -0.14517453 ...  0.03889269  0.11430144
   0.3939869 ]
 [-0.04108684  0.00851039 -0.02821608 ... -0.03659096 -0.08441645
  -0.03422815]]
layers.1.weight: [[ 0.03069209  0.01116055 -0.20396462 ...  0.35041988 -0.02080986
   0.04986168]
 [-0.2518542  -0.39477658  0.26199773 ... -0.19614655  0.21261466
  -0.09669704]
 [ 0.17016244  0.25256783  0.116681   ...  0.01430751 -0.0103819
   0.06905688]
 ...
 [ 0.06988718  0.01621392  0.07264984 ... -0.06941903 -0.25842232
   0.10003296]
 [-0.42867684  0.05401708  0.02302316 ...  0.27477083  0.25360402
  -0.1723484 ]
 [ 0.00082205 -0.48354465  0.27855256 ...  0.02962311 -0.04040468
   0.1217239 ]]
layers.2.weight: [[-0.1147217   0.1034793   0.10374583 -0.11645907 -0.11415353  0.10976173
  -0.33622894 -0.45266533 -0.335795   -0.17908217 -0.24851654  0.10754199
  -0.17699885 -0.31884968 -0.09575532  0.1067651   0.11528431  0.10866003
   0.11750854  0.09612429 -0.16921285  0.10769673 -0.10696755  0.23202875
  -0.09668691 -0.23643155  0.10385966 -0.10971932  0.09915883  0.09328457
   0.10531759 -0.10728825]]

Final Loss: 0.0093
Distance Metric: 27.9877
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 1999

================================================================================

baselineCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.01239572 -0.01256636 -0.01319713 ...  0.03764426 -0.03144669
  -0.00909942]
 [ 0.00746293 -0.01115272  0.00307309 ...  0.00193226  0.02960178
  -0.02130779]
 [-0.02866727 -0.02374003 -0.01441465 ...  0.0273718  -0.00980791
  -0.02157196]
 ...
 [ 0.01688965  0.01724553  0.0050666  ... -0.01906301  0.01253896
  -0.02479101]
 [-0.03235213  0.0014376   0.00901312 ...  0.00014134  0.0381858
   0.00156165]
 [ 0.00247497 -0.02545533 -0.03592845 ... -0.02430964  0.00498555
  -0.00630845]]
layers.1.weight: [[-0.00835291  0.04140843  0.02975924 ... -0.03983871  0.02620775
  -0.02951455]
 [ 0.00744106  0.01394764  0.0186636  ...  0.01245213  0.00082179
   0.04196515]
 [-0.02790974 -0.013559    0.0113442  ...  0.01380075 -0.03618379
  -0.04261768]
 ...
 [ 0.01790753 -0.02837304  0.02316045 ...  0.0424055   0.02197188
   0.03644724]
 [ 0.04072178 -0.00859552  0.0438739  ... -0.00762832 -0.0111951
   0.0425582 ]
 [-0.02411848 -0.01979691  0.01092712 ... -0.0105242  -0.01737308
   0.05406214]]
layers.2.weight: [[ 0.02183407  0.03094111 -0.00670314 -0.009159    0.00480904  0.01486995
   0.00298077  0.03629436  0.00632737  0.03406842  0.00969738  0.00321567
   0.00029316  0.00520888 -0.0001353   0.00522162  0.03033505  0.00056136
   0.03159376 -0.01758813 -0.00594335  0.00602842 -0.00037343  0.01890808
   0.03775651  0.0228743  -0.04706784  0.02222734 -0.01701382 -0.01554986
   0.00231935  0.01051366]]

Final Loss: 0.2669
Distance Metric: 4.1916
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 164

================================================================================

baselineCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.02406265  0.02657232 -0.0076216  ... -0.02720197  0.01037418
  -0.02717698]
 [ 0.02921082 -0.00169399  0.04204215 ... -0.01847157 -0.01886011
  -0.00551645]
 [ 0.01992908  0.03125001  0.00391467 ... -0.02247113 -0.00254858
   0.0098666 ]
 ...
 [ 0.02150603 -0.02872011  0.01753179 ...  0.00840119  0.01671479
  -0.00431622]
 [-0.00087458  0.01769595  0.00461174 ... -0.00371749 -0.02961878
  -0.00785097]
 [-0.01840907 -0.02541279 -0.00609527 ...  0.01973689  0.02290996
  -0.00639789]]
layers.1.weight: [[-0.02596677  0.02572048  0.01818931 ...  0.01526946 -0.00340413
  -0.02402708]
 [-0.00846274  0.00338024  0.02487682 ... -0.00909451  0.01637501
   0.01001873]
 [ 0.02360598  0.02966827 -0.00494941 ...  0.01472058  0.02734309
   0.00962778]
 ...
 [-0.02184761 -0.00479755  0.01157307 ... -0.00415768 -0.0224363
   0.02741038]
 [ 0.01989031  0.00665945  0.02751051 ...  0.01162199 -0.01574349
  -0.01103936]
 [-0.00705787 -0.00460512  0.0315053  ... -0.01488165  0.
   0.01559685]]
layers.2.weight: [[-0.19932666 -0.22885674 -0.40387198 -0.2673376  -0.26211226 -0.23922072
  -0.24769615 -0.19663356 -0.26239523 -0.25948843 -0.1681027  -0.3289681
  -0.29183835 -0.26968938 -0.3652918  -0.22766773 -0.24272111 -0.24037294
  -0.2175213  -0.37423345 -0.2994247  -0.21595192 -0.37677205 -0.36661077
  -0.26451558 -0.25358024 -0.2739409  -0.2538629  -0.30593142 -0.15702434
  -0.36762857 -0.19647364]]

Final Loss: 0.0000
Distance Metric: 5.0060
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 1999

================================================================================

baselineCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.04293444  0.00027832 -0.00464382 ...  0.00716873 -0.0148032
   0.00805432]
 [-0.00604845 -0.00521266  0.02498704 ... -0.01105429  0.01873599
   0.0346445 ]
 [-0.00732807  0.01013462  0.02009128 ... -0.00632088  0.00289433
   0.00061808]
 ...
 [ 0.02813522 -0.02139574  0.0559051  ...  0.00938661 -0.00034097
  -0.02788375]
 [ 0.01391972 -0.00149332  0.0013842  ...  0.0042786   0.02357172
   0.0083386 ]
 [ 0.00613186  0.01935531 -0.00562293 ...  0.01465682  0.01784811
   0.01359299]]
layers.1.weight: [[ 0.008078    0.02337008 -0.00708957 ...  0.03904824 -0.0108896
   0.06056112]
 [ 0.00817399  0.00411784 -0.02695755 ... -0.04565478 -0.03484241
   0.01952221]
 [-0.12383009 -0.06144852  0.04632625 ... -0.02541527 -0.00590543
   0.01495809]
 ...
 [-0.00796176 -0.02710493 -0.0044117  ...  0.01133391 -0.11155294
  -0.06659584]
 [ 0.03238576 -0.0372927  -0.0418648  ...  0.02135746 -0.12616988
  -0.03504023]
 [-0.01282376 -0.06888645 -0.05928438 ... -0.01002646 -0.09338804
  -0.05732772]]
layers.2.weight: [[-0.0382557   0.08511935  0.16552356  0.19856499  0.3698879   0.32191825
  -0.05372863  0.54770666 -0.6933687  -0.5014284   0.18556903  0.37478256
  -0.5282996   0.15323195 -0.29002464 -0.02080689 -0.6090103  -0.05634969
   0.35196084 -0.02362276 -0.16051087 -0.32672378  0.56116664  0.02368439
  -0.14422819 -0.03769713  0.45092314  0.3134073  -0.03549441 -0.0483444
   0.4925878  -0.12560332]]

Final Loss: 0.0000
Distance Metric: 7.4907
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 1999

================================================================================

baselineCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.04632368 -0.04023164 -0.01675768 ... -0.02486803  0.02004033
  -0.00657004]
 [ 0.00473586  0.04386524 -0.03446291 ... -0.0290063  -0.00541155
   0.0324639 ]
 [ 0.0340088  -0.01206115 -0.03142212 ... -0.03182691 -0.04711327
  -0.04766798]
 ...
 [-0.02936082  0.02309122 -0.03290337 ... -0.0352994  -0.04340499
   0.03301215]
 [-0.00933198  0.04845167 -0.00101881 ... -0.02913349  0.04768834
   0.00126704]
 [-0.03762287  0.0099578  -0.00918169 ... -0.03607976 -0.01842084
  -0.01496118]]
layers.1.weight: [[-0.04490283 -0.00757144  0.00578526 ... -0.00802881  0.00698854
  -0.02591023]
 [-0.00904649 -0.04484535  0.00279319 ...  0.01611944  0.0058046
  -0.03774253]
 [ 0.04430142  0.00747204 -0.01302049 ...  0.0316701   0.04243073
  -0.04508577]
 ...
 [ 0.03846822  0.03804489 -0.04559748 ... -0.00202226  0.02206007
   0.00971011]
 [ 0.         -0.02043347 -0.01804372 ... -0.04016368  0.02120267
   0.02326776]
 [-0.01281217  0.03972691  0.01071209 ...  0.00383787  0.03864789
   0.01565674]]
layers.2.weight: [[ 0.12242272  0.08203997 -0.04534768  0.04646772  0.10260251  0.0123362
  -0.01940702  0.09657567  0.06997341  0.07270218 -0.10235054 -0.08754645
   0.08937861 -0.111021    0.06205167  0.13569689  0.10855037 -0.13281555
   0.09571045 -0.00847139 -0.09313471  0.00209789  0.12367398 -0.10992357
   0.01259955  0.02782052 -0.095899   -0.06119811  0.00552286  0.01206301
  -0.10602211  0.07414463]]

Final Loss: 0.0000
Distance Metric: 5.2546
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 1999

================================================================================

baselineCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.01422329  0.01889302  0.0170152  ...  0.02764496 -0.0085992
   0.02192502]
 [ 0.00440431  0.01987495 -0.02360479 ... -0.02461506 -0.00311225
   0.02901939]
 [-0.01935723  0.00105    -0.0291106  ... -0.0116281   0.01035889
  -0.02306925]
 ...
 [-0.00639265 -0.0224201   0.01290083 ...  0.02760205  0.01753454
   0.02374512]
 [ 0.00719786  0.02407804  0.00210007 ...  0.02710867 -0.00118549
  -0.00921597]
 [-0.00135748 -0.01427443  0.010095   ...  0.01775111 -0.00487125
   0.01535493]]
layers.1.weight: [[ 0.02774906  0.02149144 -0.01721218 ... -0.01106164  0.02562053
  -0.00072922]
 [ 0.02041778 -0.0120093   0.03397178 ... -0.0019755  -0.02060041
   0.01137749]
 [ 0.03125     0.00248768  0.00983518 ...  0.00980938 -0.00985741
   0.01490279]
 ...
 [-0.02455267  0.015625   -0.01035581 ... -0.00392774 -0.00797565
  -0.02267914]
 [-0.0132494   0.00329563  0.00191407 ...  0.01253687 -0.01123204
   0.0076741 ]
 [-0.00034727 -0.0010893  -0.01274774 ...  0.02103739  0.01106863
  -0.00949674]]
layers.2.weight: [[-0.29873532 -0.3363202  -0.25000358 -0.39001572 -0.3444506  -0.40271452
  -0.39233038 -0.250789   -0.40095726 -0.4031247  -0.35045728 -0.25080636
  -0.36472976 -0.29078433 -0.35723674 -0.4676771  -0.2871681  -0.25356036
  -0.2512566  -0.31207708 -0.47207105 -0.42516547 -0.3599307  -0.33463478
  -0.27615765 -0.37221688 -0.3517999  -0.28089327 -0.24911425 -0.18880019
  -0.42501923 -0.3129544 ]]

Final Loss: 0.0000
Distance Metric: 5.1031
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 1999

================================================================================

baselineCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.02163273 -0.00324467 -0.03367931 ...  0.00535662  0.00712282
  -0.01855391]
 [-0.01209783  0.01813302  0.00365888 ... -0.01475962  0.01631474
   0.00543564]
 [-0.02354001 -0.0235753  -0.00097353 ...  0.01488668  0.00706637
   0.02252027]
 ...
 [-0.0174532  -0.00274001 -0.00027127 ... -0.01851318  0.00559128
   0.02314224]
 [ 0.00044548 -0.00720532 -0.01673148 ...  0.00181205 -0.01235241
  -0.00194941]
 [ 0.0087463   0.0072205   0.00600542 ... -0.00646042 -0.00942844
  -0.01395079]]
layers.1.weight: [[-0.05724012  0.04331477 -0.00872774 ... -0.02837732  0.06600443
  -0.00388382]
 [-0.03491856  0.04907522  0.05306787 ... -0.03802281  0.01095437
  -0.0375057 ]
 [-0.00089688 -0.022185    0.00045399 ...  0.04962654  0.10937306
   0.10234067]
 ...
 [-0.06802137  0.08730499  0.02998286 ... -0.0437158  -0.05950209
   0.03653   ]
 [ 0.00172394 -0.01930025  0.07540267 ... -0.0005022  -0.00653713
   0.05561828]
 [ 0.05064457  0.03535927  0.05923897 ... -0.02532458  0.05067453
   0.01923721]]
layers.2.weight: [[-0.1935343   0.04726386 -0.23829475  0.427574   -0.20687778 -0.0505877
   0.17391251 -0.02909074 -0.02275548  0.39383954  0.04140069 -0.6487789
   0.0555299  -0.03638737 -0.05201647  0.22097363  0.01085268  0.2542004
   0.0233448  -0.09241877 -0.2864517   0.06661187 -0.30121335  0.18964611
  -0.01856026  0.12224174  0.3999636  -0.22837368 -0.22943653  0.33811653
   0.01584765  0.0505468 ]]

Final Loss: 0.0010
Distance Metric: 7.0112
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 1999

================================================================================

baselineCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.0013149  -0.04465651  0.03520147 ... -0.02020132  0.03813526
   0.03445784]
 [ 0.03461663 -0.03102607 -0.02466732 ... -0.03468351  0.00732628
   0.03282966]
 [ 0.01428004  0.03018516 -0.01917978 ... -0.02097823  0.03567624
  -0.04523084]
 ...
 [ 0.04755597 -0.0413846   0.00529889 ...  0.03202749 -0.01422522
  -0.01358788]
 [ 0.03458374  0.0480844  -0.00381713 ... -0.03745429  0.04921024
  -0.02717983]
 [-0.03879197  0.01430921  0.02112197 ... -0.04819338 -0.03534237
  -0.01100629]]
layers.1.weight: [[-0.01118852  0.04137699  0.00261133 ... -0.04570779  0.01374483
  -0.04194671]
 [-0.01390892  0.02081962 -0.01425916 ... -0.02464135  0.00037966
  -0.04390556]
 [-0.02344346 -0.04016789  0.00702542 ... -0.01624783 -0.03054902
  -0.03121962]
 ...
 [-0.04057217 -0.03717201  0.00388576 ... -0.01381215  0.01694375
  -0.04278967]
 [-0.0322667   0.00457019 -0.02500228 ... -0.02452327 -0.0316008
   0.04072278]
 [ 0.03504709 -0.02335535 -0.00986423 ... -0.02812232  0.03113948
  -0.0089367 ]]
layers.2.weight: [[-0.08503652  0.12498012 -0.08092596  0.09836741 -0.13225053 -0.08894231
  -0.05251213 -0.04221081  0.05983416 -0.08386217 -0.01020927  0.13290085
   0.04812341  0.01081389 -0.12934303  0.1237396  -0.08629028  0.12740757
   0.14081492 -0.07919885  0.04720453 -0.01609686  0.06158615 -0.12000646
  -0.07781203 -0.14625195  0.08781162 -0.1247971   0.13095894 -0.01442183
  -0.03796155 -0.14406285]]

Final Loss: 0.0000
Distance Metric: 4.9465
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 1999

================================================================================

