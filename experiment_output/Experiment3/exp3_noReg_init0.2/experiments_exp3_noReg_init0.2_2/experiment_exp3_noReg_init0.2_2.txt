Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.1287463  -0.09171551 -0.07787361]]]
layers.1.weight: [[[-0.21395592  0.17209068]]]
layers.2.weight: [[[-0.17255014  0.22421281]]]

================================================================================

baselineCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.02972268  0.02074325 -0.01387409 ...  0.01253077  0.01354871
   0.02729126]
 [ 0.0068832  -0.01467879 -0.01111699 ... -0.01084211  0.01205792
  -0.01580895]
 [-0.0277852  -0.01937056 -0.00830079 ...  0.02137988  0.02029693
  -0.01621203]
 ...
 [ 0.00226836  0.00951383  0.0212095  ... -0.02870375  0.00391966
   0.02747277]
 [ 0.01705282  0.00685038  0.01448826 ...  0.02090087  0.00620872
  -0.0051541 ]
 [ 0.01253997 -0.01985061  0.0052318  ... -0.02983377 -0.02840533
  -0.0010024 ]]
layers.1.weight: [[-0.00646921  0.02018994 -0.01841434 ... -0.01192068 -0.0036685
  -0.02585616]
 [ 0.00953299  0.02030904  0.01490474 ...  0.02346323  0.0201408
   0.00649713]
 [-0.01808359  0.00569438 -0.00036576 ... -0.02326477  0.02157161
   0.02336745]
 ...
 [-0.02458226 -0.0288485  -0.0196827  ...  0.00082189  0.01880387
  -0.01319273]
 [-0.01030213  0.01656631  0.00942787 ...  0.02576306 -0.01043891
  -0.00808777]
 [ 0.02862528 -0.02412853 -0.00448435 ...  0.01340411  0.02002293
   0.01348406]]
layers.2.weight: [[ 0.00010651 -0.07895661 -0.02873865  0.03585929 -0.07293653  0.06517543
   0.0758978   0.02355136  0.07307839 -0.05398481 -0.02686802  0.04921499
  -0.02923906  0.03514754  0.07332494  0.00704907  0.06763462 -0.01572016
   0.02575226 -0.02557834  0.06166076 -0.01505629 -0.03921458  0.03471009
  -0.09475248  0.06307745 -0.06162161 -0.00908433  0.00118397 -0.00810173
  -0.00090918 -0.07727409]]

Final Loss: 0.0000
Distance Metric: 3.2537
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 1999

================================================================================

baselineCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.14181408  0.24996816  0.08201164 ...  0.06629416 -0.11302233
   0.01611744]
 [-0.23412135  0.03719322 -0.17072652 ...  0.28293613 -0.04326679
   0.01880475]
 [ 0.15299962 -0.02938855  0.26021874 ...  0.25062263  0.22040994
   0.18532561]
 ...
 [-0.21773896 -0.02311127  0.18957755 ...  0.07956621  0.1060221
   0.01971133]
 [ 0.0852237  -0.13895528 -0.14517453 ...  0.03889269  0.11430144
   0.3939869 ]
 [-0.04108684  0.00851039 -0.02821608 ... -0.03659096 -0.08441645
  -0.03422815]]
layers.1.weight: [[ 0.03069209  0.01116055 -0.20396462 ...  0.35041988 -0.02080986
   0.04986168]
 [-0.2518542  -0.39477658  0.26199773 ... -0.19614655  0.21261466
  -0.09669704]
 [ 0.17016244  0.25256783  0.116681   ...  0.01430751 -0.0103819
   0.06905688]
 ...
 [ 0.06988718  0.01621392  0.07264984 ... -0.06941903 -0.25842232
   0.10003296]
 [-0.42867684  0.05401708  0.02302316 ...  0.27477083  0.25360402
  -0.1723484 ]
 [ 0.00082205 -0.48354465  0.27855256 ...  0.02962311 -0.04040468
   0.1217239 ]]
layers.2.weight: [[-0.1147217   0.1034793   0.10374583 -0.11645907 -0.11415353  0.10976173
  -0.33622894 -0.45266533 -0.335795   -0.17908217 -0.24851654  0.10754199
  -0.17699885 -0.31884968 -0.09575532  0.1067651   0.11528431  0.10866003
   0.11750854  0.09612429 -0.16921285  0.10769673 -0.10696755  0.23202875
  -0.09668691 -0.23643155  0.10385966 -0.10971932  0.09915883  0.09328457
   0.10531759 -0.10728825]]

Final Loss: 0.0093
Distance Metric: 27.9877
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 1999

================================================================================

baselineCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.01239572 -0.01256636 -0.01319713 ...  0.03764426 -0.03144669
  -0.00909942]
 [ 0.00746293 -0.01115272  0.00307309 ...  0.00193226  0.02960178
  -0.02130779]
 [-0.02866727 -0.02374003 -0.01441465 ...  0.0273718  -0.00980791
  -0.02157196]
 ...
 [ 0.01688965  0.01724553  0.0050666  ... -0.01906301  0.01253896
  -0.02479101]
 [-0.03235213  0.0014376   0.00901312 ...  0.00014134  0.0381858
   0.00156165]
 [ 0.00247497 -0.02545533 -0.03592845 ... -0.02430964  0.00498555
  -0.00630845]]
layers.1.weight: [[-0.00835291  0.04140843  0.02975924 ... -0.03983871  0.02620775
  -0.02951455]
 [ 0.00744106  0.01394764  0.0186636  ...  0.01245213  0.00082179
   0.04196515]
 [-0.02790974 -0.013559    0.0113442  ...  0.01380075 -0.03618379
  -0.04261768]
 ...
 [ 0.01790753 -0.02837304  0.02316045 ...  0.0424055   0.02197188
   0.03644724]
 [ 0.04072178 -0.00859552  0.0438739  ... -0.00762832 -0.0111951
   0.0425582 ]
 [-0.02411848 -0.01979691  0.01092712 ... -0.0105242  -0.01737308
   0.05406214]]
layers.2.weight: [[ 0.02183407  0.03094111 -0.00670314 -0.009159    0.00480904  0.01486995
   0.00298077  0.03629436  0.00632737  0.03406842  0.00969738  0.00321567
   0.00029316  0.00520888 -0.0001353   0.00522162  0.03033505  0.00056136
   0.03159376 -0.01758813 -0.00594335  0.00602842 -0.00037343  0.01890808
   0.03775651  0.0228743  -0.04706784  0.02222734 -0.01701382 -0.01554986
   0.00231935  0.01051366]]

Final Loss: 0.2669
Distance Metric: 4.1916
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 164

================================================================================

baselineCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.02406265  0.02657232 -0.0076216  ... -0.02720197  0.01037418
  -0.02717698]
 [ 0.02921082 -0.00169399  0.04204215 ... -0.01847157 -0.01886011
  -0.00551645]
 [ 0.01992908  0.03125001  0.00391467 ... -0.02247113 -0.00254858
   0.0098666 ]
 ...
 [ 0.02150603 -0.02872011  0.01753179 ...  0.00840119  0.01671479
  -0.00431622]
 [-0.00087458  0.01769595  0.00461174 ... -0.00371749 -0.02961878
  -0.00785097]
 [-0.01840907 -0.02541279 -0.00609527 ...  0.01973689  0.02290996
  -0.00639789]]
layers.1.weight: [[-0.02596677  0.02572048  0.01818931 ...  0.01526946 -0.00340413
  -0.02402708]
 [-0.00846274  0.00338024  0.02487682 ... -0.00909451  0.01637501
   0.01001873]
 [ 0.02360598  0.02966827 -0.00494941 ...  0.01472058  0.02734309
   0.00962778]
 ...
 [-0.02184761 -0.00479755  0.01157307 ... -0.00415768 -0.0224363
   0.02741038]
 [ 0.01989031  0.00665945  0.02751051 ...  0.01162199 -0.01574349
  -0.01103936]
 [-0.00705787 -0.00460512  0.0315053  ... -0.01488165  0.
   0.01559685]]
layers.2.weight: [[-0.19932666 -0.22885674 -0.40387198 -0.2673376  -0.26211226 -0.23922072
  -0.24769615 -0.19663356 -0.26239523 -0.25948843 -0.1681027  -0.3289681
  -0.29183835 -0.26968938 -0.3652918  -0.22766773 -0.24272111 -0.24037294
  -0.2175213  -0.37423345 -0.2994247  -0.21595192 -0.37677205 -0.36661077
  -0.26451558 -0.25358024 -0.2739409  -0.2538629  -0.30593142 -0.15702434
  -0.36762857 -0.19647364]]

Final Loss: 0.0000
Distance Metric: 5.0060
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 1999

================================================================================

baselineCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.04293444  0.00027832 -0.00464382 ...  0.00716873 -0.0148032
   0.00805432]
 [-0.00604845 -0.00521266  0.02498704 ... -0.01105429  0.01873599
   0.0346445 ]
 [-0.00732807  0.01013462  0.02009128 ... -0.00632088  0.00289433
   0.00061808]
 ...
 [ 0.02813522 -0.02139574  0.0559051  ...  0.00938661 -0.00034097
  -0.02788375]
 [ 0.01391972 -0.00149332  0.0013842  ...  0.0042786   0.02357172
   0.0083386 ]
 [ 0.00613186  0.01935531 -0.00562293 ...  0.01465682  0.01784811
   0.01359299]]
layers.1.weight: [[ 0.008078    0.02337008 -0.00708957 ...  0.03904824 -0.0108896
   0.06056112]
 [ 0.00817399  0.00411784 -0.02695755 ... -0.04565478 -0.03484241
   0.01952221]
 [-0.12383009 -0.06144852  0.04632625 ... -0.02541527 -0.00590543
   0.01495809]
 ...
 [-0.00796176 -0.02710493 -0.0044117  ...  0.01133391 -0.11155294
  -0.06659584]
 [ 0.03238576 -0.0372927  -0.0418648  ...  0.02135746 -0.12616988
  -0.03504023]
 [-0.01282376 -0.06888645 -0.05928438 ... -0.01002646 -0.09338804
  -0.05732772]]
layers.2.weight: [[-0.0382557   0.08511935  0.16552356  0.19856499  0.3698879   0.32191825
  -0.05372863  0.54770666 -0.6933687  -0.5014284   0.18556903  0.37478256
  -0.5282996   0.15323195 -0.29002464 -0.02080689 -0.6090103  -0.05634969
   0.35196084 -0.02362276 -0.16051087 -0.32672378  0.56116664  0.02368439
  -0.14422819 -0.03769713  0.45092314  0.3134073  -0.03549441 -0.0483444
   0.4925878  -0.12560332]]

Final Loss: 0.0000
Distance Metric: 7.4907
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 1999

================================================================================

baselineCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.04632368 -0.04023164 -0.01675768 ... -0.02486803  0.02004033
  -0.00657004]
 [ 0.00473586  0.04386524 -0.03446291 ... -0.0290063  -0.00541155
   0.0324639 ]
 [ 0.0340088  -0.01206115 -0.03142212 ... -0.03182691 -0.04711327
  -0.04766798]
 ...
 [-0.02936082  0.02309122 -0.03290337 ... -0.0352994  -0.04340499
   0.03301215]
 [-0.00933198  0.04845167 -0.00101881 ... -0.02913349  0.04768834
   0.00126704]
 [-0.03762287  0.0099578  -0.00918169 ... -0.03607976 -0.01842084
  -0.01496118]]
layers.1.weight: [[-0.04490283 -0.00757144  0.00578526 ... -0.00802881  0.00698854
  -0.02591023]
 [-0.00904649 -0.04484535  0.00279319 ...  0.01611944  0.0058046
  -0.03774253]
 [ 0.04430142  0.00747204 -0.01302049 ...  0.0316701   0.04243073
  -0.04508577]
 ...
 [ 0.03846822  0.03804489 -0.04559748 ... -0.00202226  0.02206007
   0.00971011]
 [ 0.         -0.02043347 -0.01804372 ... -0.04016368  0.02120267
   0.02326776]
 [-0.01281217  0.03972691  0.01071209 ...  0.00383787  0.03864789
   0.01565674]]
layers.2.weight: [[ 0.12242272  0.08203997 -0.04534768  0.04646772  0.10260251  0.0123362
  -0.01940702  0.09657567  0.06997341  0.07270218 -0.10235054 -0.08754645
   0.08937861 -0.111021    0.06205167  0.13569689  0.10855037 -0.13281555
   0.09571045 -0.00847139 -0.09313471  0.00209789  0.12367398 -0.10992357
   0.01259955  0.02782052 -0.095899   -0.06119811  0.00552286  0.01206301
  -0.10602211  0.07414463]]

Final Loss: 0.0000
Distance Metric: 5.2546
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 1999

================================================================================

