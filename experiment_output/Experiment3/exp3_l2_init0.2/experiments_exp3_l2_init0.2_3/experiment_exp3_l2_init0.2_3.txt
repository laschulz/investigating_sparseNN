Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.06099727 -0.12747054  0.15070868]]]
layers.1.weight: [[[-0.19082111  0.19470395]]]
layers.2.weight: [[[-0.06340884 -0.0414081 ]]]

================================================================================

baselineCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[-0.00327844 -0.00327867 -0.00327824 -0.00327781 -0.00327809 -0.00327713
  -0.00327726 -0.00327843 -0.00327786 -0.00327717 -0.00327804 -0.00327765
  -0.00327796 -0.00327775 -0.00327728 -0.00327714 -0.00327805 -0.00327724
  -0.00327853 -0.00327721 -0.00327748 -0.00327776 -0.00327814 -0.00327772
  -0.00327819 -0.00327831 -0.00327786 -0.00327803 -0.00327814 -0.00327724
  -0.00327815 -0.00327752]]

Final Loss: 0.0000
Distance Metric: 0.5684
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 1234

================================================================================

baselineCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-0.01020774  0.02628615  0.07257956 ...  0.01449299 -0.03899844
   0.00333937]
 [-0.06961529  0.08218882 -0.02994667 ... -0.04978021  0.02693474
  -0.03313733]
 [ 0.03682991 -0.02913744 -0.01470452 ...  0.02863908  0.07279217
   0.06980892]
 ...
 [ 0.00833065 -0.00274507  0.00942222 ...  0.02310249 -0.03014521
   0.04083183]
 [ 0.00494836  0.08946623 -0.01769692 ... -0.12736294  0.01276594
   0.04018735]
 [ 0.00235378  0.078452   -0.01314529 ... -0.01840171  0.00519821
   0.04169753]]
layers.1.weight: [[-0.0198489  -0.0472416   0.10729339 ...  0.05987734  0.01652574
   0.10930653]
 [-0.02640704 -0.00220283  0.06797358 ... -0.05161712 -0.00463996
  -0.00391037]
 [-0.00833225  0.02245295  0.02890826 ...  0.00867935  0.00922886
   0.01806509]
 ...
 [-0.11883084  0.01267076  0.03155972 ...  0.02652303 -0.05540166
   0.09965085]
 [-0.00712207  0.01919321  0.02471209 ...  0.00741913  0.00788899
   0.01544238]
 [-0.00816551  0.02795954  0.02241347 ... -0.01640479 -0.08439516
  -0.01982638]]
layers.2.weight: [[-0.37694672 -0.43939742  0.13965678 -0.46151093  0.25309795  0.26863825
   0.18630801 -0.507823    0.2501771  -0.41379476  0.23063041  0.25734308
  -0.53619415 -0.48019534  0.20254397  0.19117832 -0.48905024  0.2894
  -0.40220958  0.22712012  0.3368117  -0.41018045  0.31234765 -0.5143463
   0.20553443 -0.4894024  -0.49374497  0.18973267 -0.43125716 -0.5359319
   0.11938186 -0.3364025 ]]

Final Loss: 0.0094
Distance Metric: 9.1960
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 1373

================================================================================

baselineCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.00163598 -0.00305889  0.00441513 ...  0.00100483 -0.00182817
   0.00261088]
 [ 0.00378595  0.00748252 -0.01082695 ... -0.0028857   0.00447422
  -0.00626794]
 [ 0.00502093  0.00965597 -0.01411073 ... -0.00355468  0.00580532
  -0.00790072]
 ...
 [-0.00234136 -0.00413707  0.00611757 ...  0.0014469  -0.00255007
   0.00369755]
 [-0.00081583 -0.00120717  0.00141365 ...  0.00053845 -0.00079656
   0.00086943]
 [ 0.00091479  0.00188224 -0.00256585 ... -0.00085071  0.0009878
  -0.00157078]]
layers.1.weight: [[ 0.00095916 -0.00160895  0.00137636 ... -0.00030778  0.00049849
  -0.00143227]
 [ 0.00243464 -0.00150363 -0.00053202 ...  0.00224988  0.00066454
   0.        ]
 [ 0.00095724 -0.00412918 -0.00370929 ...  0.00202484  0.00100122
  -0.001277  ]
 ...
 [-0.00013641  0.00228142  0.00094841 ... -0.00208713  0.00122893
  -0.00093669]
 [-0.00098444  0.00268189  0.0022101  ... -0.00159803 -0.00209412
  -0.00060932]
 [ 0.         -0.00130941 -0.00470141 ... -0.00034042  0.00048857
  -0.00112743]]
layers.2.weight: [[ 0.00050586  0.01961243  0.04060431  0.01101503  0.04219765  0.00907448
  -0.00832645  0.02562031 -0.04490731 -0.01687161  0.01370586 -0.00114113
   0.01085649 -0.00511949  0.0093552   0.01469263  0.02866895 -0.04783545
  -0.01321965  0.04006751  0.01062633 -0.00288315  0.01698476  0.01502396
  -0.01408593  0.02393487 -0.03741246 -0.03893882  0.02787388 -0.00838985
  -0.02503636  0.03503466]]

Final Loss: 0.2605
Distance Metric: 1.0457
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 341

================================================================================

baselineCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.00031572 -0.00026143 -0.00017831 ... -0.00089684  0.00060728
   0.00061304]
 [ 0.00014598  0.         -0.00016694 ... -0.00048707  0.00032609
   0.00050301]
 [ 0.00067012 -0.00053132 -0.00048575 ... -0.00207564  0.00136833
   0.00159914]
 ...
 [ 0.          0.          0.         ...  0.00010966  0.
  -0.00011562]
 [ 0.00048964 -0.00029534 -0.00037808 ... -0.00138017  0.00104976
   0.00119072]
 [ 0.00093245 -0.00060304 -0.00072324 ... -0.00302282  0.00211071
   0.00228237]]
layers.1.weight: [[-0.00038735 -0.00027542 -0.00068171 ...  0.         -0.00050509
  -0.00100985]
 [-0.00038254 -0.00018951 -0.00080284 ...  0.00012021 -0.00055067
  -0.00095495]
 [ 0.00022649  0.          0.00038863 ...  0.          0.00034887
   0.00064317]
 ...
 [ 0.00042141  0.00025744  0.00098973 ...  0.          0.0007787
   0.00155003]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.00031981  0.00022926  0.00073335 ... -0.00010998  0.00048881
   0.00096388]]
layers.2.weight: [[-0.00760679 -0.00784912  0.00429498 -0.01065593  0.00804809  0.00967571
   0.00835385  0.00409404  0.00468943 -0.00662586  0.00075699 -0.0067228
   0.00399421 -0.01225295 -0.00248017 -0.0099783  -0.00732298 -0.00487419
   0.00909515  0.00945811 -0.00753926 -0.00777043  0.00743916 -0.00830927
   0.00776557 -0.0034756   0.00085275 -0.00183294 -0.00651658  0.01124725
   0.          0.0069776 ]]

Final Loss: 0.0000
Distance Metric: 0.4604
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 673

================================================================================

baselineCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.00094694 -0.00278732 -0.00209005 ... -0.00010796 -0.00031224
  -0.00025729]
 [-0.00094786 -0.00278839 -0.0020891  ... -0.00010669 -0.00031242
  -0.00025628]
 [-0.00094712 -0.00278696 -0.00208989 ... -0.00010897 -0.0003094
  -0.00025616]
 ...
 [-0.00094946 -0.00278753 -0.00209097 ... -0.00010749 -0.00031166
  -0.00025564]
 [-0.00094777 -0.00278719 -0.00208813 ... -0.0001087  -0.00031215
  -0.00025852]
 [-0.00094855 -0.00278745 -0.00209057 ... -0.00010797 -0.00031229
  -0.00025528]]
layers.1.weight: [[0.00834561 0.0083444  0.00834638 ... 0.00834602 0.00834612 0.00834751]
 [0.00834671 0.00834734 0.00834667 ... 0.00834771 0.00834471 0.00834545]
 [0.00834517 0.00834506 0.00834485 ... 0.00834658 0.00834475 0.0083438 ]
 ...
 [0.00834019 0.00833999 0.00833983 ... 0.00834002 0.00833869 0.00834125]
 [0.00834831 0.00834524 0.00834843 ... 0.00834603 0.00834493 0.00834796]
 [0.00833886 0.00834171 0.00833906 ... 0.00834083 0.00834187 0.00834079]]
layers.2.weight: [[-0.25519812 -0.2551996  -0.25517148 -0.25509658 -0.25501    -0.25511324
  -0.25491264 -0.255197   -0.25521907 -0.25508946 -0.25492892 -0.25506982
  -0.255145   -0.25507295 -0.2552572  -0.254863   -0.2550561  -0.25510564
  -0.2549636  -0.2551809  -0.2551098  -0.25507247 -0.25511274 -0.25501743
  -0.255074   -0.2549538  -0.2551764  -0.25497085 -0.2551933  -0.25504228
  -0.2552289  -0.2550608 ]]

Final Loss: 0.0001
Distance Metric: 3.1644
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 1035

================================================================================

baselineCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-0.00019042  0.00064825  0.00040248 ... -0.00037385  0.00162866
   0.00086954]
 [ 0.00010969 -0.00059615 -0.0003414  ...  0.00015788 -0.00069264
  -0.00042386]
 [ 0.         -0.00046752 -0.0002642  ...  0.00011897 -0.00052046
  -0.00032303]
 ...
 [ 0.00025977 -0.00020265  0.00025728 ... -0.00021989  0.
   0.00018634]
 [ 0.00012695 -0.00056922 -0.00031365 ...  0.00021737 -0.00093451
  -0.00054981]
 [-0.00021874  0.00071165  0.00033607 ...  0.00103179 -0.00423296
  -0.00257858]]
layers.1.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.00029774 -0.0001597  -0.00017671 ...  0.         -0.00017225
  -0.00085572]
 [ 0.          0.          0.         ...  0.          0.00015205
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
  -0.00011987]
 [-0.00147824 -0.00065819 -0.00049127 ...  0.00021734 -0.00066047
  -0.00408107]
 [-0.00110449 -0.00047356 -0.00033722 ...  0.0002431  -0.0004833
  -0.00259493]]
layers.2.weight: [[-0.00075877  0.0379554  -0.00064251  0.02354858  0.00724876  0.00029048
  -0.00039685 -0.00021842  0.06229216  0.12458187  0.          0.04375448
  -0.00035151 -0.00057155 -0.00017731  0.03557585 -0.0009797   0.05612691
   0.07318735  0.03794099  0.0117105  -0.00098127  0.09374991  0.04508881
   0.00190658 -0.00123672 -0.00031763 -0.00020889  0.          0.00663352
   0.17098436  0.10806225]]

Final Loss: 0.0003
Distance Metric: 1.6693
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 719

================================================================================

baselineCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.00236105 -0.00234081 -0.00111867 ... -0.00157728 -0.00162074
  -0.00063913]
 [-0.0008662  -0.00085879 -0.00041046 ... -0.00058065 -0.00059668
  -0.00023532]
 [-0.00120845 -0.00119812 -0.00057265 ... -0.00080964 -0.00083197
  -0.00032811]
 ...
 [ 0.00020284  0.0002011   0.         ...  0.00013603  0.00013979
   0.        ]
 [ 0.00033036  0.00032753  0.00015654 ...  0.00022154  0.00022765
   0.        ]
 [-0.00085424 -0.00084689 -0.00040477 ... -0.00057259 -0.00058839
  -0.00023205]]
layers.1.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.00037312 -0.00013712 -0.00019124 ...  0.          0.
  -0.00013521]
 [ 0.00031174  0.00011456  0.00015978 ...  0.          0.
   0.00011297]
 ...
 [ 0.00074357  0.00027325  0.0003811  ...  0.         -0.00010423
   0.00026945]
 [-0.00087099 -0.00032006 -0.00044642 ...  0.          0.00012209
  -0.00031563]
 [ 0.00121713  0.00044728  0.00062382 ... -0.00010476 -0.00017062
   0.00044106]]
layers.2.weight: [[ 0.00613061  0.02423961 -0.02024822  0.0356458   0.04545238  0.00386936
  -0.05065432 -0.06550117  0.04091289 -0.0892283  -0.03987501  0.0627116
   0.00615204  0.07218605 -0.1434884  -0.01776827 -0.03253144 -0.10183944
   0.05134762  0.02347255  0.07463001 -0.08070602  0.05684017  0.01482886
   0.02588152 -0.04567754  0.02376677 -0.00219702 -0.02688219 -0.04840626
   0.05676198 -0.07961751]]

Final Loss: 0.0000
Distance Metric: 1.3443
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 2690

================================================================================

baselineCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0.00875463 0.00876182 0.00875371 ... 0.00876425 0.00815338 0.00876545]
 [0.00816059 0.00877009 0.00816062 ... 0.00830931 0.00877616 0.00816052]
 [0.00877729 0.00877724 0.00870079 ... 0.00877726 0.00876926 0.00827495]
 ...
 [0.0078125  0.00788793 0.0078125  ... 0.00841372 0.0078125  0.00799129]
 [0.00815979 0.00815981 0.00816775 ... 0.00815981 0.00876585 0.00815972]
 [0.0078125  0.00839572 0.0078125  ... 0.00790229 0.00839576 0.00839575]]
layers.2.weight: [[-0.26414135 -0.26393238 -0.26389882 -0.24702434 -0.2641813  -0.26414686
  -0.24561314 -0.24562168 -0.24556167 -0.24531753 -0.26406705 -0.24684516
  -0.26407298 -0.26387408 -0.24674328 -0.26393476 -0.2641084  -0.26401225
  -0.24611057 -0.24510534 -0.26398557 -0.24499089 -0.26420966 -0.2642668
  -0.2456655  -0.26404354 -0.26397467 -0.26172566 -0.24561207 -0.2467758
  -0.26395458 -0.24551007]]

Final Loss: 0.0000
Distance Metric: 2.8985
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 1548

================================================================================

baselineCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0.]]

Final Loss: 0.0000
Distance Metric: 0.7570
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 5199

================================================================================

