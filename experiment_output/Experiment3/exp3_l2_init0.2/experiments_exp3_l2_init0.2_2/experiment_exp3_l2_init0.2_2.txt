Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[ 0.18807589 -0.1654224   0.15099297]]]
layers.1.weight: [[[ 0.01132582 -0.14517887]]]
layers.2.weight: [[[-0.2419682   0.01295648]]]

================================================================================

baselineCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[-0.00691535 -0.00690761 -0.00690607 -0.00690796 -0.006912   -0.00691148
  -0.00690762 -0.00690864 -0.00691346 -0.00691297 -0.00691365 -0.00691663
  -0.00691422 -0.00690788 -0.00690689 -0.0069157  -0.0069067  -0.00691028
  -0.0069138  -0.00691685 -0.00691187 -0.00691328 -0.00690731 -0.00690572
  -0.00690703 -0.00691068 -0.00691335 -0.00691679 -0.00691517 -0.00691161
  -0.0069115  -0.00691671]]

Final Loss: 0.0000
Distance Metric: 0.7118
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 1025

================================================================================

baselineCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-0.09104477  0.13020563 -0.00088033 ...  0.04721856  0.07145032
   0.00162966]
 [ 0.05208336 -0.03725921 -0.00249637 ... -0.04117267 -0.01678711
  -0.0014886 ]
 [-0.02917343 -0.03265613 -0.09699253 ... -0.06624956 -0.04970697
   0.02904628]
 ...
 [ 0.02581824 -0.00526842  0.0162982  ... -0.04809431 -0.00968269
   0.095833  ]
 [ 0.01792178  0.0056812   0.03054023 ...  0.03720525 -0.11391757
   0.05483698]
 [ 0.10701792  0.03433071  0.01295023 ...  0.04826943 -0.02453203
  -0.11143452]]
layers.1.weight: [[-0.01966276  0.04002841  0.00558429 ... -0.00582914 -0.03768802
   0.03075608]
 [-0.10484688  0.00069945  0.00044709 ...  0.01206003 -0.02227099
  -0.03195417]
 [ 0.03323643 -0.06716986  0.04795128 ... -0.15324166 -0.01769004
   0.01872098]
 ...
 [ 0.06157443  0.00456931  0.02697579 ...  0.00281544 -0.0315037
   0.04168301]
 [ 0.02886652 -0.00479798  0.03636302 ... -0.00846424 -0.00376508
   0.03782195]
 [ 0.01924972 -0.00319584  0.02419817 ... -0.00562278 -0.00251501
   0.02516646]]
layers.2.weight: [[-0.5488255  -0.46540755  0.31367382 -0.46406248  0.3138927  -0.42459688
   0.32263124  0.10030621  0.20608851 -0.47561276  0.30528995  0.23296218
   0.17031124  0.21837504 -0.5417467  -0.29509765 -0.40099114  0.38350698
  -0.5049366   0.236962   -0.40185654 -0.4625955   0.13371116 -0.501562
   0.21864028  0.187924   -0.48158115  0.11520458 -0.4933832   0.27042708
   0.27060476  0.18029965]]

Final Loss: 0.0097
Distance Metric: 8.8841
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 820

================================================================================

baselineCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0.00801641 0.00830911 0.00802627 ... 0.00802428 0.00802397 0.00833415]
 [0.00852177 0.00852634 0.00820351 ... 0.00834101 0.00819685 0.00849951]
 [0.00849602 0.00851793 0.00852625 ... 0.00852327 0.0085079  0.00836698]
 ...
 [0.00819886 0.00851264 0.00820267 ... 0.00819849 0.00852973 0.00820584]
 [0.00846964 0.00816824 0.00847616 ... 0.00848754 0.00817162 0.00849428]
 [0.00849638 0.00822892 0.00850112 ... 0.00819483 0.00849892 0.00818394]]
layers.2.weight: [[-0.25000033 -0.25892457 -0.258245   -0.25839168 -0.25823608 -0.25000048
  -0.25814348 -0.24948272 -0.25900453 -0.25000042 -0.24936378 -0.25773895
  -0.2580608  -0.25       -0.2583092  -0.25799733 -0.25834295 -0.252821
  -0.2500003  -0.2500003  -0.25000012 -0.24920271 -0.2500006  -0.25831747
  -0.25       -0.25794718 -0.25837627 -0.2587579  -0.25814044 -0.25866613
  -0.25661442 -0.25789782]]

Final Loss: 0.0000
Distance Metric: 2.9995
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 688

================================================================================

baselineCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.00139047  0.00118998  0.00127766 ...  0.00437489  0.00365708
   0.00436935]
 [ 0.00035569  0.00033575  0.00036983 ...  0.00125581  0.00104524
   0.00118422]
 [ 0.00057693  0.00047723  0.00064429 ...  0.          0.
   0.00013313]
 ...
 [ 0.00069308  0.0006416   0.00084154 ...  0.00011144  0.0001792
   0.0002355 ]
 [-0.0086971  -0.00687835 -0.00826708 ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ... -0.00304155 -0.00241511
  -0.00289382]]
layers.1.weight: [[ 0.          0.          0.00011846 ...  0.00015716  0.
   0.        ]
 [ 0.00318025  0.00075271 -0.00147588 ... -0.00199375  0.00105461
  -0.00024392]
 [ 0.          0.          0.00013132 ...  0.0001232   0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.00309174  0.00073743 -0.0013479  ... -0.00172272  0.00109599
  -0.00019417]]
layers.2.weight: [[-5.0037436e-04  2.4075650e-02 -4.1163087e-04 -1.0244559e-03
  -1.7365927e-04  1.3668694e-04  1.3829598e-01  0.0000000e+00
   4.5187566e-02  1.8140286e-02  1.2383033e-01 -2.9765989e-04
   1.2339937e-04  4.1288134e-02 -1.7997273e-03  1.1996230e-01
  -6.7538966e-04  0.0000000e+00  1.3607240e-01  1.2962210e-01
   1.0115197e-01  3.3207465e-02  5.7812344e-02 -6.1917363e-04
   1.9100714e-01  7.9470254e-02  7.8874342e-03  2.9407660e-02
   9.9340053e-03  0.0000000e+00 -7.6162029e-04  2.3615256e-02]]

Final Loss: 0.0000
Distance Metric: 1.7736
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 801

================================================================================

