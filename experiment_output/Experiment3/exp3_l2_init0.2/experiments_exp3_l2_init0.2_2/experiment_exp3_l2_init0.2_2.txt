Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[ 0.18807589 -0.1654224   0.15099297]]]
layers.1.weight: [[[ 0.01132582 -0.14517887]]]
layers.2.weight: [[[-0.2419682   0.01295648]]]

================================================================================

baselineCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[-0.00691535 -0.00690761 -0.00690607 -0.00690796 -0.006912   -0.00691148
  -0.00690762 -0.00690864 -0.00691346 -0.00691297 -0.00691365 -0.00691663
  -0.00691422 -0.00690788 -0.00690689 -0.0069157  -0.0069067  -0.00691028
  -0.0069138  -0.00691685 -0.00691187 -0.00691328 -0.00690731 -0.00690572
  -0.00690703 -0.00691068 -0.00691335 -0.00691679 -0.00691517 -0.00691161
  -0.0069115  -0.00691671]]

Final Loss: 0.0000
Distance Metric: 0.7118
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 1025

================================================================================

baselineCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-0.09104477  0.13020563 -0.00088033 ...  0.04721856  0.07145032
   0.00162966]
 [ 0.05208336 -0.03725921 -0.00249637 ... -0.04117267 -0.01678711
  -0.0014886 ]
 [-0.02917343 -0.03265613 -0.09699253 ... -0.06624956 -0.04970697
   0.02904628]
 ...
 [ 0.02581824 -0.00526842  0.0162982  ... -0.04809431 -0.00968269
   0.095833  ]
 [ 0.01792178  0.0056812   0.03054023 ...  0.03720525 -0.11391757
   0.05483698]
 [ 0.10701792  0.03433071  0.01295023 ...  0.04826943 -0.02453203
  -0.11143452]]
layers.1.weight: [[-0.01966276  0.04002841  0.00558429 ... -0.00582914 -0.03768802
   0.03075608]
 [-0.10484688  0.00069945  0.00044709 ...  0.01206003 -0.02227099
  -0.03195417]
 [ 0.03323643 -0.06716986  0.04795128 ... -0.15324166 -0.01769004
   0.01872098]
 ...
 [ 0.06157443  0.00456931  0.02697579 ...  0.00281544 -0.0315037
   0.04168301]
 [ 0.02886652 -0.00479798  0.03636302 ... -0.00846424 -0.00376508
   0.03782195]
 [ 0.01924972 -0.00319584  0.02419817 ... -0.00562278 -0.00251501
   0.02516646]]
layers.2.weight: [[-0.5488255  -0.46540755  0.31367382 -0.46406248  0.3138927  -0.42459688
   0.32263124  0.10030621  0.20608851 -0.47561276  0.30528995  0.23296218
   0.17031124  0.21837504 -0.5417467  -0.29509765 -0.40099114  0.38350698
  -0.5049366   0.236962   -0.40185654 -0.4625955   0.13371116 -0.501562
   0.21864028  0.187924   -0.48158115  0.11520458 -0.4933832   0.27042708
   0.27060476  0.18029965]]

Final Loss: 0.0097
Distance Metric: 8.8841
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 820

================================================================================

baselineCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0.00801641 0.00830911 0.00802627 ... 0.00802428 0.00802397 0.00833415]
 [0.00852177 0.00852634 0.00820351 ... 0.00834101 0.00819685 0.00849951]
 [0.00849602 0.00851793 0.00852625 ... 0.00852327 0.0085079  0.00836698]
 ...
 [0.00819886 0.00851264 0.00820267 ... 0.00819849 0.00852973 0.00820584]
 [0.00846964 0.00816824 0.00847616 ... 0.00848754 0.00817162 0.00849428]
 [0.00849638 0.00822892 0.00850112 ... 0.00819483 0.00849892 0.00818394]]
layers.2.weight: [[-0.25000033 -0.25892457 -0.258245   -0.25839168 -0.25823608 -0.25000048
  -0.25814348 -0.24948272 -0.25900453 -0.25000042 -0.24936378 -0.25773895
  -0.2580608  -0.25       -0.2583092  -0.25799733 -0.25834295 -0.252821
  -0.2500003  -0.2500003  -0.25000012 -0.24920271 -0.2500006  -0.25831747
  -0.25       -0.25794718 -0.25837627 -0.2587579  -0.25814044 -0.25866613
  -0.25661442 -0.25789782]]

Final Loss: 0.0000
Distance Metric: 2.9995
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 688

================================================================================

baselineCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.00139047  0.00118998  0.00127766 ...  0.00437489  0.00365708
   0.00436935]
 [ 0.00035569  0.00033575  0.00036983 ...  0.00125581  0.00104524
   0.00118422]
 [ 0.00057693  0.00047723  0.00064429 ...  0.          0.
   0.00013313]
 ...
 [ 0.00069308  0.0006416   0.00084154 ...  0.00011144  0.0001792
   0.0002355 ]
 [-0.0086971  -0.00687835 -0.00826708 ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ... -0.00304155 -0.00241511
  -0.00289382]]
layers.1.weight: [[ 0.          0.          0.00011846 ...  0.00015716  0.
   0.        ]
 [ 0.00318025  0.00075271 -0.00147588 ... -0.00199375  0.00105461
  -0.00024392]
 [ 0.          0.          0.00013132 ...  0.0001232   0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.00309174  0.00073743 -0.0013479  ... -0.00172272  0.00109599
  -0.00019417]]
layers.2.weight: [[-5.0037436e-04  2.4075650e-02 -4.1163087e-04 -1.0244559e-03
  -1.7365927e-04  1.3668694e-04  1.3829598e-01  0.0000000e+00
   4.5187566e-02  1.8140286e-02  1.2383033e-01 -2.9765989e-04
   1.2339937e-04  4.1288134e-02 -1.7997273e-03  1.1996230e-01
  -6.7538966e-04  0.0000000e+00  1.3607240e-01  1.2962210e-01
   1.0115197e-01  3.3207465e-02  5.7812344e-02 -6.1917363e-04
   1.9100714e-01  7.9470254e-02  7.8874342e-03  2.9407660e-02
   9.9340053e-03  0.0000000e+00 -7.6162029e-04  2.3615256e-02]]

Final Loss: 0.0000
Distance Metric: 1.7736
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 801

================================================================================

baselineCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.00862898  0.0001682   0.00167443 ... -0.00107349 -0.00133129
  -0.00444131]
 [ 0.02825213  0.00072477  0.00560413 ... -0.00361034 -0.00411739
  -0.01443328]
 [ 0.01873321  0.00042428  0.00361228 ... -0.00235445 -0.00285975
  -0.00961661]
 ...
 [ 0.00040471  0.          0.         ...  0.          0.
  -0.0002248 ]
 [-0.02231393 -0.00055441 -0.004399   ...  0.00285849  0.00335752
   0.01144256]
 [ 0.00604517  0.00013961  0.00113459 ... -0.00073882 -0.00095404
  -0.00307474]]
layers.1.weight: [[-0.00068542 -0.00101821 -0.00044155 ... -0.00019296  0.00109666
  -0.00025859]
 [-0.00090947 -0.00415958 -0.00285234 ... -0.00013418  0.0036396
  -0.00106602]
 [-0.00108863 -0.0023711  -0.00130956 ...  0.00012946  0.00174504
  -0.00022922]
 ...
 [-0.00105441 -0.00308949 -0.00234915 ...  0.00021758  0.00226974
  -0.00086093]
 [ 0.00082     0.00401035  0.00225798 ...  0.         -0.0033481
   0.00053261]
 [-0.00061653 -0.00167148 -0.00133288 ... -0.00054635  0.00177721
  -0.00028407]]
layers.2.weight: [[ 0.00616545  0.02884095  0.01456212 -0.00938336  0.01197592 -0.01389476
   0.01460827 -0.0203993   0.00023509  0.04577301 -0.01925249  0.01024004
   0.04003707 -0.01466356  0.01780639 -0.02558164  0.01605862 -0.01181028
   0.01982154 -0.00444414 -0.00228801  0.00360599  0.01943513  0.02127621
  -0.04265365 -0.04504409 -0.02722973  0.00212939  0.03217779  0.02268753
  -0.02645123  0.0128115 ]]

Final Loss: 0.2380
Distance Metric: 0.9146
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 484

================================================================================

baselineCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0.]]

Final Loss: 0.0000
Distance Metric: 0.8912
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 5148

================================================================================

baselineCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.00082146 -0.00211486 -0.00170493 ... -0.00357208  0.00892639
   0.00744739]
 [ 0.00080308 -0.00210171 -0.00168662 ... -0.00353849  0.00874193
   0.00732457]
 [ 0.00081016 -0.0021361  -0.00170215 ... -0.00358045  0.0088302
   0.00741629]
 ...
 [ 0.00082394 -0.00214225 -0.00170463 ... -0.00355946  0.00884315
   0.00740885]
 [ 0.00078641 -0.00214065 -0.00169816 ... -0.00356738  0.00882445
   0.00736334]
 [ 0.00080007 -0.00213321 -0.00167351 ... -0.00352217  0.00878294
   0.00734452]]
layers.1.weight: [[0.00834511 0.00829137 0.00834734 ... 0.00832199 0.00833639 0.00829566]
 [0.00841629 0.00834389 0.00840036 ... 0.00836993 0.00837213 0.0083445 ]
 [0.0083727  0.0083642  0.00837185 ... 0.00838149 0.00837581 0.00832474]
 ...
 [0.00838873 0.00834011 0.00838937 ... 0.00839228 0.00838242 0.0083402 ]
 [0.00842584 0.00833933 0.00836588 ... 0.00837919 0.00837686 0.00834573]
 [0.00834782 0.00828143 0.00833038 ... 0.00834097 0.00831764 0.00830692]]
layers.2.weight: [[-0.25200498 -0.25312918 -0.25283185 -0.25375754 -0.25239855 -0.25331646
  -0.25253597 -0.25271425 -0.25166944 -0.25264013 -0.25197455 -0.25359282
  -0.25170335 -0.25371742 -0.25209242 -0.25339335 -0.2535829  -0.2528282
  -0.25208986 -0.25308132 -0.2535654  -0.25184733 -0.2525133  -0.25311518
  -0.25238568 -0.25346074 -0.2533906  -0.25363815 -0.25251332 -0.2530512
  -0.2532275  -0.25167626]]

Final Loss: 0.0011
Distance Metric: 3.7848
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 752

================================================================================

baselineCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-0.00231616 -0.00445503  0.00299948 ...  0.          0.00017874
  -0.00011597]
 [-0.00048591 -0.00093449  0.00062931 ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.00278236 -0.0053519   0.00360336 ...  0.00011286  0.00021474
  -0.00013932]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[0.00185732 0.00038967 0.         ... 0.         0.00223306 0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 ...
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.00394255 0.00082631 0.         ... 0.         0.00473503 0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]]
layers.2.weight: [[0.0385795  0.         0.         0.         0.         0.
  0.05430563 0.         0.01857397 0.06651281 0.0540592  0.
  0.         0.03200419 0.         0.         0.         0.01345868
  0.03633657 0.08381388 0.         0.05620158 0.05227046 0.
  0.         0.05251155 0.         0.         0.01648964 0.
  0.0818074  0.        ]]

Final Loss: 0.0000
Distance Metric: 1.1673
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 1187

================================================================================

baselineCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.00012017 ...  0.          0.
  -0.00014675]
 [ 0.          0.          0.00015472 ...  0.         -0.00010668
  -0.00018894]
 ...
 [ 0.          0.          0.00012089 ...  0.          0.
  -0.00014764]
 [ 0.          0.00020327  0.00036078 ...  0.         -0.00024878
  -0.0004406 ]
 [ 0.         -0.00011904 -0.00021127 ...  0.          0.00014569
   0.00025801]]
layers.1.weight: [[ 0.          0.          0.         ...  0.          0.00010384
   0.        ]
 [ 0.          0.         -0.0001061  ...  0.         -0.00024741
   0.00014488]
 [ 0.          0.          0.         ...  0.         -0.00011881
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.00012897
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.2.weight: [[-0.04094762  0.09789168  0.04685798 -0.03998083  0.1099709  -0.06307821
  -0.01270916  0.00440356 -0.09553789 -0.07724297  0.11072658 -0.03890795
  -0.00542778 -0.01031817  0.05960508 -0.00864071  0.05203757 -0.04291588
  -0.05808527  0.05999797 -0.03112959  0.07209408 -0.0471597   0.00863773
  -0.06963479  0.04891468  0.05429999 -0.05131256 -0.08497154  0.03029856
  -0.05087461 -0.03156395]]

Final Loss: 0.0000
Distance Metric: 1.2455
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 6170

================================================================================

