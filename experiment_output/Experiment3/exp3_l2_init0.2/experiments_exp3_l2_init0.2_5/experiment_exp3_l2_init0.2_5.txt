Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[ 0.13686724  0.01444254 -0.16963851]]]
layers.1.weight: [[[ 0.06392922 -0.08888977]]]
layers.2.weight: [[[-0.2104857   0.00641397]]]

================================================================================

baselineCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[-0.00633194 -0.00633384 -0.00633392 -0.00633467 -0.00633569 -0.00633401
  -0.00633152 -0.00633449 -0.00633459 -0.00633436 -0.00633557 -0.00633161
  -0.00633356 -0.00633193 -0.00633349 -0.00633602 -0.0063313  -0.00633612
  -0.00633352 -0.00633505 -0.00633212 -0.00633508 -0.00633288 -0.0063358
  -0.00633458 -0.00633127 -0.00633471 -0.00633565 -0.00633292 -0.00633545
  -0.00633608 -0.00633273]]

Final Loss: 0.0000
Distance Metric: 0.5672
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 1112

================================================================================

baselineCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-0.06148637 -0.01587317 -0.08021557 ...  0.02445159  0.00375585
   0.01145833]
 [ 0.08013421 -0.05703451  0.07216338 ... -0.06929658  0.04674952
  -0.00560239]
 [ 0.03950664  0.05814687  0.02145772 ... -0.00541925 -0.00391466
   0.00244758]
 ...
 [-0.00900117 -0.05473616  0.04943376 ...  0.05457684  0.05438627
  -0.04147791]
 [-0.07351907  0.07414588 -0.00409516 ... -0.03660582 -0.03528111
  -0.01813885]
 [ 0.04848823  0.01348038 -0.0840343  ...  0.05414614 -0.01296347
  -0.06172571]]
layers.1.weight: [[-0.05843181  0.06749834 -0.02930977 ... -0.04592205  0.01279495
  -0.00872953]
 [ 0.01317088 -0.00694606 -0.0177222  ... -0.00320966  0.00744263
  -0.09721715]
 [-0.02004823  0.05640897  0.03697829 ...  0.04598196 -0.01514577
  -0.05552699]
 ...
 [ 0.01686994 -0.03449751 -0.02629709 ... -0.01712295  0.
   0.06278466]
 [ 0.01422745  0.00407048 -0.00537393 ... -0.00117502  0.01613755
   0.00987943]
 [ 0.0127502   0.00134338 -0.00760946 ...  0.02103854  0.01615666
   0.00112495]]
layers.2.weight: [[-0.49628386 -0.50181365  0.36182293  0.14667033  0.10355103 -0.50478536
   0.38581607  0.2209683   0.32745445  0.32645753 -0.3164413  -0.47501835
   0.25569022  0.2519519   0.21427263 -0.36609966  0.38687593  0.2074577
  -0.46393383 -0.5595119  -0.47271645  0.2490835   0.1625512  -0.49417478
  -0.5275146   0.26178765 -0.49985766  0.20007706  0.29048312  0.23967873
   0.07775091  0.2102858 ]]

Final Loss: 0.0082
Distance Metric: 8.5961
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 1164

================================================================================

baselineCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.0001442  -0.00015641 -0.0001199  ...  0.          0.
   0.        ]
 [ 0.0001444  -0.00015655 -0.00011988 ...  0.          0.
   0.        ]
 [ 0.00014438 -0.00015567 -0.0001194  ...  0.          0.
   0.        ]
 ...
 [ 0.00014397 -0.00015554 -0.00011891 ...  0.          0.
   0.        ]
 [ 0.00014444 -0.00015641 -0.00011917 ...  0.          0.
   0.        ]
 [ 0.00014411 -0.0001559  -0.00011884 ...  0.          0.
   0.        ]]
layers.1.weight: [[0.00826767 0.00826499 0.00826842 ... 0.00826634 0.00826837 0.00826773]
 [0.0082661  0.0082637  0.00826432 ... 0.00826362 0.00825831 0.00826094]
 [0.00825292 0.00824688 0.00824891 ... 0.00824788 0.00825287 0.00824774]
 ...
 [0.00826361 0.00827099 0.00826892 ... 0.00826977 0.00826781 0.00826825]
 [0.00828108 0.00827683 0.00828178 ... 0.00828041 0.00827787 0.00828121]
 [0.00825265 0.00825259 0.00825945 ... 0.00825956 0.00825394 0.00825183]]
layers.2.weight: [[-0.253208   -0.25314507 -0.25280303 -0.25316513 -0.25344023 -0.25314933
  -0.2529344  -0.2528498  -0.253505   -0.25288427 -0.25288132 -0.2527914
  -0.25281507 -0.25267947 -0.2534205  -0.25345746 -0.25268412 -0.25350025
  -0.25280035 -0.2534065  -0.25336313 -0.25327852 -0.25357547 -0.25279322
  -0.25286794 -0.25283217 -0.2533909  -0.2528504  -0.25280014 -0.25327316
  -0.2535872  -0.25297055]]

Final Loss: 0.0000
Distance Metric: 3.1832
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 1147

================================================================================

baselineCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.          0.00281327 -0.00248709 ... -0.00220129 -0.00224842
  -0.00117099]
 [ 0.          0.00677518 -0.00613828 ... -0.00524261 -0.00549928
  -0.00291199]
 [ 0.         -0.00713245  0.00648347 ...  0.00550339  0.00584336
   0.00307802]
 ...
 [-0.00021647  0.01434337 -0.01313811 ... -0.01110105 -0.01182516
  -0.006199  ]
 [ 0.          0.0022181  -0.00205466 ... -0.00175472 -0.0018533
  -0.00095268]
 [ 0.         -0.01068511  0.00968837 ...  0.00825079  0.00874571
   0.00454948]]
layers.1.weight: [[-0.00037022  0.00127579 -0.0005554  ...  0.00115634  0.00028183
  -0.00184997]
 [ 0.00062392  0.00060421 -0.000537   ...  0.00225447  0.00107077
  -0.0019603 ]
 [ 0.00033572 -0.00040327  0.0010436  ... -0.00011393 -0.00045697
   0.0005341 ]
 ...
 [-0.00062591  0.         -0.00013138 ... -0.00186005 -0.00033533
   0.00118918]
 [ 0.00034264  0.00084946 -0.00012278 ...  0.00145992  0.00038892
  -0.00029508]
 [-0.00054856 -0.00225299  0.00215382 ... -0.00329001 -0.00022645
   0.00322523]]
layers.2.weight: [[-0.0200594  -0.01769161  0.00893988 -0.02655436  0.03643774 -0.00068434
  -0.0100601  -0.03360906 -0.00447115 -0.00169159  0.0313944   0.00549081
   0.0371728  -0.0251414  -0.00760075  0.02640708 -0.00359009 -0.02366203
   0.00196072  0.01017058 -0.03917431 -0.02021634  0.01280764  0.01508879
  -0.01770262 -0.00155558 -0.02375737  0.02655576 -0.01824855  0.01322973
  -0.00864379  0.03762706]]

Final Loss: 0.2990
Distance Metric: 1.1915
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 432

================================================================================

baselineCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.         -0.00094677 -0.0005203  ...  0.         -0.00060203
  -0.0003363 ]
 [ 0.         -0.00337574 -0.00188462 ...  0.         -0.00212976
  -0.00118674]
 [ 0.          0.00023753  0.00013367 ...  0.          0.00016435
   0.        ]
 ...
 [ 0.          0.00194241  0.00107318 ...  0.          0.00120917
   0.00067545]
 [ 0.          0.00033309  0.00019221 ...  0.          0.00020217
   0.00012363]
 [ 0.          0.00259897  0.00143578 ...  0.          0.00161111
   0.00092458]]
layers.1.weight: [[ 0.          0.00020951  0.         ...  0.          0.
  -0.00015149]
 [-0.00036287 -0.00131251  0.         ...  0.00074612  0.00013227
   0.00102898]
 [ 0.00010351  0.0004119   0.         ... -0.00021561  0.
  -0.00032374]
 ...
 [-0.00065871 -0.00242427  0.00016362 ...  0.00137916  0.00021709
   0.00186024]
 [-0.00100731 -0.00356275  0.0002592  ...  0.00205096  0.00035348
   0.00274034]
 [-0.00027679 -0.00106118  0.         ...  0.00061384  0.
   0.00080149]]
layers.2.weight: [[ 0.00271276 -0.01766348  0.00533079  0.02086025 -0.01924746 -0.0105067
   0.01958913 -0.01601485 -0.03826894 -0.00233972  0.05657951 -0.02376039
   0.01409518  0.02631279  0.03829135  0.0286198   0.06579328  0.01203827
   0.01921886  0.02796467 -0.0001486  -0.02337649 -0.04492557 -0.05068702
  -0.04199737  0.0123121   0.00526688 -0.03007117 -0.01280792 -0.03204508
  -0.04720266 -0.01389528]]

Final Loss: 0.0000
Distance Metric: 1.2711
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 832

================================================================================

baselineCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.01056287 -0.01509023  0.01696103 ... -0.00315063  0.00472275
  -0.00524908]
 [ 0.01085051 -0.01550798  0.01742974 ... -0.00323992  0.00485405
  -0.0053904 ]
 [ 0.01130445 -0.01615333  0.01815347 ... -0.00337093  0.00505684
  -0.00561721]
 ...
 [ 0.01056917 -0.01510432  0.01697379 ... -0.00315228  0.00472499
  -0.00525078]
 [ 0.01111238 -0.01587681  0.01784484 ... -0.0033151   0.0049707
  -0.0055227 ]
 [ 0.0109699  -0.0156747   0.01761871 ... -0.00327359  0.00490414
  -0.00545193]]
layers.1.weight: [[0.00822368 0.0083905  0.0086539  ... 0.00822752 0.00854327 0.00846015]
 [0.00822859 0.00839729 0.00865826 ... 0.00823067 0.0085458  0.00846279]
 [0.00822904 0.00839649 0.00865432 ... 0.00823364 0.00854432 0.00846233]
 ...
 [0.00822381 0.00839389 0.00865546 ... 0.00823183 0.00854382 0.00846246]
 [0.0082287  0.00839327 0.0086548  ... 0.00823102 0.00854572 0.00846387]
 [0.00822831 0.0083958  0.00865859 ... 0.00823391 0.0085469  0.00846287]]
layers.2.weight: [[-0.24502991 -0.24519417 -0.24515046 -0.24510856 -0.24512248 -0.24516532
  -0.24520446 -0.24517168 -0.245032   -0.24515685 -0.24520579 -0.24515504
  -0.24508987 -0.2450758  -0.2451117  -0.24521379 -0.2451778  -0.24514127
  -0.24519815 -0.24519114 -0.24520901 -0.24521388 -0.2450289  -0.24515547
  -0.24504484 -0.24512741 -0.24510852 -0.24517207 -0.24520098 -0.2450954
  -0.24512981 -0.24519213]]

Final Loss: 0.0038
Distance Metric: 3.5803
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 1006

================================================================================

baselineCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-0.0024751   0.00162579  0.         ... -0.00496637  0.00448213
  -0.00505744]
 [ 0.00011364  0.00025559  0.0003973  ...  0.00010279  0.00292419
   0.00150945]
 [ 0.00565322 -0.00208953  0.0097555  ... -0.00538114  0.00577196
  -0.0123839 ]
 ...
 [-0.00051    -0.00198742 -0.00040128 ... -0.00083569 -0.00099069
   0.00029459]
 [-0.00090969  0.00079929 -0.00361174 ... -0.00232563  0.00666355
  -0.01116071]
 [ 0.00144644 -0.00109387  0.00358505 ...  0.00333322 -0.00259557
   0.00908132]]
layers.1.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.00205457  0.00083482 -0.00412829 ...  0.00061001 -0.00361312
   0.00364935]
 [ 0.          0.          0.00014792 ...  0.          0.00013382
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.00063625  0.00025817 -0.0012768  ...  0.00018904 -0.00111777
   0.00112877]
 [-0.00255489  0.00103762 -0.0051326  ...  0.00075844 -0.00449099
   0.00453636]]
layers.2.weight: [[ 0.0000000e+00  6.4616993e-02 -1.2739373e-03  0.0000000e+00
  -5.7637919e-04  8.3257727e-02  2.5851836e-02 -5.2948954e-04
   2.3443334e-01 -1.6273699e-04  9.2362732e-02  4.6278544e-02
  -3.3695722e-04  5.3573076e-02  1.0254096e-01  0.0000000e+00
  -8.2608900e-04  1.4038274e-02  0.0000000e+00 -1.9822780e-04
   1.7599751e-01 -1.5809126e-03 -1.8900633e-04  1.3201399e-01
   2.2020617e-02  6.8921976e-02  1.3717431e-01  1.4596387e-02
   1.3183133e-02 -1.4540172e-04  1.9992597e-02  8.0325507e-02]]

Final Loss: 0.0014
Distance Metric: 2.0614
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 1241

================================================================================

baselineCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-7.14259455e-03  7.45537272e-03 -2.25330819e-03 ...  1.86755453e-04
  -3.71881644e-04  1.87141603e-04]
 [-1.12507136e-04  2.20377566e-04  0.00000000e+00 ...  8.24558288e-02
  -9.04933959e-02  2.77763344e-02]
 [-5.95859718e-04  3.44095199e-04  2.76165083e-04 ...  6.12792969e-02
  -6.45190552e-02  2.02921201e-02]
 ...
 [ 0.00000000e+00  1.76796035e-04 -3.96699063e-04 ...  1.61758080e-01
  -1.76158249e-01  5.35660423e-02]
 [-8.20750254e-04  3.76602868e-04 -1.84310746e-04 ... -5.19825425e-03
   5.87789295e-03 -1.75343314e-03]
 [-1.06979464e-03  3.51233059e-04 -1.17565243e-04 ...  3.85103971e-01
  -4.16942626e-01  1.27060443e-01]]
layers.1.weight: [[ 2.8091553e-04  2.7582867e-02  2.0368239e-02 ...  5.4032173e-02
  -6.5493817e-03  1.2882839e-01]
 [ 8.4974863e-02 -4.9040010e-03 -3.3455861e-03 ... -1.2762837e-02
   2.7234147e-03 -2.2823950e-02]
 [ 1.6492237e-04  1.6352414e-04  0.0000000e+00 ...  1.7251092e-04
   0.0000000e+00  0.0000000e+00]
 ...
 [-5.4002029e-04 -9.0366723e-03 -6.3481200e-03 ... -1.6454788e-02
   2.0862708e-03 -4.0968377e-02]
 [ 3.4148520e-04 -1.2432746e-04  0.0000000e+00 ... -1.3834827e-04
   2.1041743e-04 -4.7358809e-04]
 [ 4.9742535e-03 -3.5851912e-04 -2.3610263e-04 ... -8.4817974e-04
   3.2284448e-04 -1.2807675e-03]]
layers.2.weight: [[-4.67925191e-01  1.06891465e+00 -5.36625739e-04  1.21459834e-01
   8.57398808e-02  5.20634837e-02  1.02121055e+00  8.74560654e-01
  -9.56948921e-02  1.30945668e-01  1.02147543e+00 -1.33402785e-03
   2.21844486e-04 -5.68566658e-03  1.15223520e-01  5.77471256e-02
  -6.83599710e-01  3.37465666e-02 -4.60308641e-02 -2.69000046e-02
   1.25500619e-01  2.85701938e-02 -1.76707970e-03 -1.89819804e-03
   2.45559923e-02 -1.77270806e+00 -5.21576703e-01  1.50479493e-03
  -1.83432102e-02 -1.47719681e-01  3.39124212e-03  6.14839345e-02]]

Final Loss: 0.0003
Distance Metric: 13.0155
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 633

================================================================================

baselineCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.00503786  0.00623408 -0.00251874 ...  0.00516291 -0.00477144
   0.00197199]
 [-0.00014927  0.         -0.00037396 ... -0.0017394   0.0018349
  -0.00041032]
 [ 0.00513879 -0.00619227  0.00225638 ... -0.00202168  0.00152069
  -0.00073436]
 ...
 [-0.00022997  0.          0.00014775 ... -0.00144106  0.00137851
  -0.00025455]
 [-0.00532793  0.00513343 -0.00199277 ... -0.01276124  0.01368992
  -0.00411198]
 [-0.00190467  0.0017497  -0.00040023 ... -0.00586173  0.00619203
  -0.00198542]]
layers.1.weight: [[-0.00026365 -0.00018576 -0.00028203 ... -0.00034604  0.00099094
   0.00057346]
 [-0.00266985 -0.00172027 -0.00154123 ... -0.00221334  0.00681886
   0.00434608]
 [ 0.00689368 -0.00571825 -0.00884763 ... -0.00662469 -0.00730125
  -0.00170881]
 ...
 [-0.00037965 -0.0002557  -0.00038149 ... -0.0004796   0.00138325
   0.00080016]
 [ 0.          0.          0.         ... -0.00010412  0.00029664
   0.00017171]
 [ 0.00039321  0.00026307  0.0003915  ...  0.00049395 -0.00142637
  -0.00082499]]
layers.2.weight: [[-8.0208965e-02 -8.5667342e-01  7.6788670e-01  7.7878498e-03
  -7.7711141e-01 -5.5455539e-02 -8.0580994e-02  9.2922052e-04
   2.3962384e-02 -8.4101446e-02  6.8772614e-02  1.8865183e-02
  -3.3444956e-02 -9.8925330e-02 -6.3926332e-02  2.0430365e-01
  -2.3682052e-02  2.2044219e-02  5.4691140e-02  1.6308149e-02
  -5.1328447e-04  2.1396402e-01 -6.9415343e-01 -6.9588983e-01
   4.5375630e-02  9.4115876e-02 -6.1288536e-02  8.7208313e-01
  -8.6589530e-02 -1.1426749e-01 -2.3586035e-02  1.1814845e-01]]

Final Loss: 0.0006
Distance Metric: 11.6181
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 1890

================================================================================

