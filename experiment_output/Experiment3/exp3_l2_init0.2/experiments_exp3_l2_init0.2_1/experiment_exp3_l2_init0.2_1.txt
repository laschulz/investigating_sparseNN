Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.19008093  0.02028959 -0.05225823]]]
layers.1.weight: [[[-0.19594738  0.11096226]]]
layers.2.weight: [[[-0.00805952  0.00197606]]]

================================================================================

baselineCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[-0.00018597 -0.00018578 -0.00018582 -0.00018569 -0.00018571 -0.00018598
  -0.00018593 -0.00018609 -0.00018626 -0.00018623 -0.00018567 -0.00018627
  -0.0001862  -0.00018573 -0.00018576 -0.00018597 -0.00018615 -0.00018606
  -0.00018603 -0.000186   -0.00018631 -0.00018579 -0.00018572 -0.00018575
  -0.00018621 -0.00018599 -0.0001862  -0.00018613 -0.00018621 -0.00018609
  -0.00018582 -0.00018624]]

Final Loss: 0.0000
Distance Metric: 0.4325
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 1327

================================================================================

baselineCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-0.09823859 -0.04351534 -0.03055374 ... -0.06829267 -0.00866843
  -0.01870185]
 [ 0.00990559  0.0966211   0.10396028 ...  0.08442517 -0.0164793
  -0.10743453]
 [ 0.04818346 -0.0355962   0.05517925 ... -0.06850993 -0.01989563
  -0.04139065]
 ...
 [-0.02687899  0.05837251 -0.07548215 ... -0.03295825  0.14283246
   0.04335384]
 [ 0.08041222  0.00319378 -0.05180747 ... -0.06933702 -0.02117176
  -0.08516033]
 [ 0.04380102  0.05391414  0.00125892 ... -0.09911869  0.0717192
  -0.02928081]]
layers.1.weight: [[ 0.00711859  0.01185508  0.00569593 ...  0.01971766  0.02783156
  -0.00687943]
 [ 0.02028389  0.04721474 -0.01374375 ...  0.00214396 -0.03442755
  -0.00174743]
 [ 0.00531337 -0.0121797  -0.0424621  ...  0.04251105 -0.00318371
  -0.00633535]
 ...
 [ 0.02656845  0.06248507  0.02550951 ... -0.01065304  0.00672348
  -0.06963088]
 [ 0.09902842 -0.0581185   0.00629767 ...  0.01040563  0.0358767
   0.10452475]
 [-0.02085665  0.02441738  0.01791332 ...  0.01732423  0.03383765
  -0.00268911]]
layers.2.weight: [[ 0.140652   -0.44502053  0.18756644  0.2559184  -0.54061574  0.1872677
  -0.2815087  -0.44828317  0.16622503 -0.4646383   0.23523903 -0.47776723
  -0.49247545 -0.52786595 -0.42176837 -0.41929036 -0.29785296 -0.3942075
   0.2208905   0.14745681  0.24905396  0.38867545 -0.3926455  -0.31825995
  -0.3824075  -0.53114146 -0.36149618 -0.50764984  0.21477787  0.21438222
  -0.4887675   0.13822256]]

Final Loss: 0.0089
Distance Metric: 9.0352
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 1590

================================================================================

baselineCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.00458291  0.00853639 -0.00512185 ...  0.00417012  0.00271175
   0.00525445]
 [ 0.0011478  -0.00210158  0.00123094 ... -0.00090391 -0.00059609
  -0.00133735]
 [-0.00903914  0.01685683 -0.01022319 ...  0.00807411  0.00540293
   0.01007899]
 ...
 [-0.00225019  0.00419886 -0.00255407 ...  0.00197928  0.00134513
   0.00254224]
 [ 0.00520292 -0.00974737  0.00586198 ... -0.00474997 -0.00309924
  -0.00599102]
 [ 0.0035068  -0.00655547  0.0040807  ... -0.00317735 -0.00215997
  -0.00403796]]
layers.1.weight: [[ 0.00235803 -0.00018416  0.00401555 ...  0.00071742 -0.00219476
  -0.00193958]
 [ 0.         -0.00027742  0.         ...  0.00073959 -0.00063498
  -0.00066799]
 [ 0.          0.          0.00050156 ...  0.00012714 -0.00105245
  -0.00062321]
 ...
 [ 0.0015683  -0.00057721  0.00396094 ...  0.00085597 -0.00264543
  -0.00143194]
 [-0.00261869  0.00031549 -0.00459568 ... -0.00147111  0.00275294
   0.00144845]
 [-0.0011851   0.00056175 -0.00336337 ... -0.00141468  0.00097675
   0.00133717]]
layers.2.weight: [[-0.03265546 -0.0059159  -0.00862312  0.01656452  0.0031993  -0.02150027
   0.01179846 -0.01198033  0.00417771  0.00652044 -0.02345704  0.00947683
  -0.01407308  0.01520339  0.00645346 -0.03219634  0.00360322 -0.01349233
  -0.03582399 -0.02181133  0.00057731  0.01850716  0.01143752 -0.00647679
  -0.00088852 -0.02717656 -0.04036563  0.00142629  0.00424084 -0.03211998
   0.04469305  0.02399603]]

Final Loss: 0.2509
Distance Metric: 0.9520
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 447

================================================================================

baselineCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.          0.00018785  0.00020129 ... -0.00155907  0.00408999
   0.00594246]
 [ 0.          0.          0.         ... -0.00069633  0.00188031
   0.00270014]
 [-0.00014412  0.00034071  0.00035082 ... -0.00272619  0.00721033
   0.0104697 ]
 ...
 [ 0.          0.00020595  0.00020091 ... -0.00171128  0.00449356
   0.00655917]
 [ 0.          0.          0.         ... -0.0005085   0.00137333
   0.00197591]
 [ 0.          0.          0.         ... -0.00032723  0.00083709
   0.00122525]]
layers.1.weight: [[-0.00173286 -0.0007766  -0.00303497 ... -0.00190697 -0.00059355
  -0.00036018]
 [-0.00226967 -0.00103649 -0.00398807 ... -0.00248655 -0.00074459
  -0.00046276]
 [-0.00022138 -0.00010277 -0.00039695 ... -0.0002557   0.
   0.        ]
 ...
 [-0.00019734  0.         -0.0003589  ... -0.00022582  0.
   0.        ]
 [-0.00118361 -0.00055246 -0.00211796 ... -0.00131192 -0.00039191
  -0.00024333]
 [-0.00110612 -0.00049358 -0.00195004 ... -0.00122003 -0.00037567
  -0.00023486]]
layers.2.weight: [[ 0.03631209  0.04734503  0.00488436 -0.03234922  0.01552189 -0.0073892
  -0.02542403 -0.00799643  0.02120563 -0.00360089  0.03541226 -0.04641807
  -0.04235768 -0.05434926 -0.00187615  0.04958237  0.03787252 -0.0047892
  -0.03763239  0.02181911 -0.04990909  0.03305582 -0.02580441  0.00459384
  -0.01060938  0.01130169 -0.03275613 -0.00499159 -0.01803778  0.00417355
   0.02502098  0.02335375]]

Final Loss: 0.0000
Distance Metric: 1.2591
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 844

================================================================================

baselineCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.00023138  0.          0.         ...  0.00075246  0.0002407
  -0.00030004]
 [ 0.00023006  0.          0.         ...  0.00075039  0.00023385
  -0.00030744]
 [ 0.00021933  0.          0.         ...  0.00074978  0.00024233
  -0.00030411]
 ...
 [ 0.00023     0.          0.         ...  0.00075356  0.00023491
  -0.00030294]
 [ 0.00023025  0.          0.         ...  0.00075066  0.00023525
  -0.00029558]
 [ 0.00023259  0.          0.         ...  0.0007538   0.00023192
  -0.00030012]]
layers.1.weight: [[0.00835215 0.00835635 0.00835489 ... 0.00834986 0.00835653 0.00835738]
 [0.00833039 0.00832476 0.00833807 ... 0.00832803 0.0083255  0.00833731]
 [0.00831962 0.0083245  0.00832071 ... 0.00832877 0.00833131 0.00833195]
 ...
 [0.00834966 0.00834914 0.00834921 ... 0.00835594 0.00835642 0.00836109]
 [0.00832269 0.00831316 0.00831432 ... 0.00831838 0.00831562 0.00832142]
 [0.00836144 0.00835891 0.0083585  ... 0.00835661 0.00836477 0.00835671]]
layers.2.weight: [[-0.25556183 -0.25506756 -0.25492796 -0.2555915  -0.2553187  -0.2556371
  -0.2556764  -0.25544825 -0.255587   -0.25469247 -0.25558144 -0.25558153
  -0.25543073 -0.25567976 -0.25507    -0.25561967 -0.25573945 -0.25562224
  -0.2555893  -0.25529882 -0.25533202 -0.25556472 -0.25528175 -0.25458938
  -0.25494143 -0.25484154 -0.25515455 -0.25532123 -0.2556575  -0.25570264
  -0.2547711  -0.25574693]]

Final Loss: 0.0000
Distance Metric: 3.0944
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 881

================================================================================

baselineCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-0.00673305  0.00316482  0.00702107 ...  0.0055417  -0.00261882
  -0.00577233]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.00499268  0.00234911  0.00521688 ...  0.00410941 -0.00194368
  -0.00428079]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.00109062  0.00051857  0.00114264 ...  0.00088223 -0.00042651
  -0.00094396]
 [-0.00327033  0.00154388  0.0034251  ...  0.00267217 -0.00126307
  -0.00280521]]
layers.1.weight: [[0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.0025103  0.         0.00186669 ... 0.         0.00041969 0.00122625]
 ...
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]]
layers.2.weight: [[ 0.          0.          0.02571817  0.02417     0.          0.
   0.01341699  0.09119464  0.0853969   0.          0.          0.
   0.          0.10462569  0.          0.          0.          0.
   0.06024264  0.          0.02633456  0.          0.00415778  0.
   0.          0.          0.          0.          0.0746766   0.
  -0.00011971  0.        ]]

Final Loss: 0.0000
Distance Metric: 1.4180
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 915

================================================================================

baselineCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.         -0.00013223
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[-0.03368204  0.0489447   0.08482435  0.0881722   0.03980218  0.0540403
  -0.02973934  0.02358401 -0.01623445  0.00852013  0.00703621  0.14805058
   0.02032397  0.03990173 -0.04802421  0.02025333 -0.05599322 -0.0249595
   0.07828775  0.0257019   0.03090431  0.01661644 -0.04919357 -0.01519861
  -0.04920478  0.05143671 -0.06862397  0.07463812  0.07110131  0.06214288
  -0.06299225 -0.00906335]]

Final Loss: 0.0000
Distance Metric: 1.0868
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 2746

================================================================================

baselineCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0.00781647 0.00781653 0.00834272 ... 0.0078165  0.00781664 0.00834275]
 [0.00871876 0.00871833 0.00871878 ... 0.00871835 0.00871875 0.00871843]
 [0.0078125  0.00793651 0.0078125  ... 0.0078125  0.0078125  0.00837857]
 ...
 [0.00848316 0.00839085 0.00871539 ... 0.00812146 0.00810559 0.00810549]
 [0.00871311 0.00871316 0.00810889 ... 0.00810714 0.00811037 0.00810709]
 [0.00783713 0.00834658 0.00834657 ... 0.00781528 0.00834655 0.0078125 ]]
layers.2.weight: [[-0.24416547 -0.26270425 -0.24613732 -0.26272616 -0.2628708  -0.24380836
  -0.26270154 -0.26256627 -0.24395967 -0.25037828 -0.24337962 -0.26271644
  -0.26266035 -0.2445739  -0.24426323 -0.26265058 -0.26268667 -0.26286998
  -0.24424638 -0.26258197 -0.26263505 -0.2627266  -0.2625035  -0.26269796
  -0.26292217 -0.26262903 -0.24349518 -0.26258656 -0.25202507 -0.26272008
  -0.26267081 -0.24465834]]

Final Loss: 0.0000
Distance Metric: 2.6906
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 1499

================================================================================

baselineCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-0.00147004  0.01256162  0.01277667 ... -0.00013971  0.00053364
   0.00071626]
 [-0.00243846  0.01998003  0.02036115 ... -0.0001325   0.0008517
   0.00100604]
 [-0.00075245  0.00748387  0.00769022 ...  0.          0.00012576
   0.        ]
 ...
 [ 0.00015572 -0.00108407 -0.00113922 ... -0.00173638  0.01528715
   0.01595564]
 [ 0.00016235 -0.00131936 -0.00132281 ...  0.          0.
   0.        ]
 [ 0.         -0.00087394 -0.00101166 ...  0.00027418 -0.00208173
  -0.00218095]]
layers.1.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.00519517  0.0082078   0.00321327 ... -0.0029708  -0.0016706
   0.00065461]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.00012873  0.
   0.        ]]
layers.2.weight: [[ 0.0000000e+00 -2.1953155e-04  7.1638033e-02 -1.2076354e-03
   0.0000000e+00 -2.4480079e-04 -1.9534511e-04 -9.0910459e-04
  -2.4437383e-04 -2.3706023e-04  6.9639549e-02  0.0000000e+00
  -5.5151910e-04  3.7078980e-02  1.2955184e-01 -5.1581825e-04
   3.5612009e-02  5.8418191e-03  1.6708335e-01  1.7147806e-01
   6.9755968e-03 -2.9812846e-04  9.2189452e-03  0.0000000e+00
   6.2937033e-04 -3.3732821e-04  0.0000000e+00  2.1358285e-02
  -1.2789051e-04  0.0000000e+00 -4.6024914e-04 -5.6948408e-04]]

Final Loss: 0.0000
Distance Metric: 1.3618
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 1077

================================================================================

