Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[ 2.59 -2.83  0.87]]]
layers.1.weight: [[[-1.38  1.29]]]
layers.2.weight: [[[ 0.86 -0.84]]]

================================================================================

baselineCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         1.8918418  0.         0.
   0.         0.         0.         0.         0.         0.
  -1.3279715  0.         0.         0.         0.         0.
   0.         0.       ]]

Final Loss: 0.0004
Distance Metric: 8.8044
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 1
seed: 1

================================================================================

baselineCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.01516217  0.00251888  0.07365445 ... -0.12136319  0.12475405
  -0.00737636]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.03930691  0.01104317 -0.05705019 ...  0.00230044 -0.12010663
  -0.00101778]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[0.15453516 0.         0.         ... 0.         0.10137103 0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 ...
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.00220485 0.         0.         ... 0.         0.00263151 0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]]
layers.2.weight: [[ 0.72784895  0.          0.          0.         -0.40978932  0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.3351331   0.
   0.          0.          0.          0.          0.          0.
  -0.4075018   0.          0.          0.          0.          0.
   0.34912103  0.        ]]

Final Loss: 0.0111
Distance Metric: 8.7834
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 1
seed: 1

================================================================================

baselineCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.          0.          0.         -0.26952875  0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.        ]]

Final Loss: 0.2527
Distance Metric: 6.5401
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 1
seed: 1

================================================================================

baselineCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[  0.          0.          0.          0.          0.         15.141515
    0.          0.          5.5165586   0.          0.          0.
    8.625148    0.          0.         -9.758039    0.          0.
   -9.921168   -6.551011    0.          0.          0.          0.
  -12.814235    0.          0.          0.          0.          0.
    0.          0.       ]]

Final Loss: 3.2792
Distance Metric: 59.9674
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 1
seed: 1

================================================================================

baselineCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.         0.         0.         0.         0.         0.
   0.         0.         0.        -1.0529548  0.         0.
   0.         0.         1.3152668  0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.       ]]

Final Loss: 0.0003
Distance Metric: 8.7581
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 1
seed: 1

================================================================================

baselineCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.24538012 -0.4396329   0.20220955 ...  0.4053601  -0.2655395
   0.44732484]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [-0.00212676  0.0067631   0.001144   ... -0.00813728  0.01368507
  -0.00259538]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.00293268  0.          0.         ... -0.00304646  0.
   0.        ]
 [ 0.003055    0.          0.         ... -0.00013942  0.
   0.        ]
 ...
 [ 0.00989646  0.          0.         ...  0.00084733  0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.00347303  0.          0.         ... -0.00173172  0.
   0.        ]]
layers.2.weight: [[ 0.         -0.19020711  0.20982118  0.          0.          0.
   0.9830449   0.         -0.4897748   0.55169165 -0.5695585  -0.5336264
   0.          0.          0.32349667 -1.0425984   0.          0.
   0.2069799   0.          0.          0.2177384  -0.05169265  0.46369728
  -0.48244748  0.          0.          0.          0.          0.09253479
   0.          0.36651033]]

Final Loss: 3.5226
Distance Metric: 42.8837
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 1
seed: 1

================================================================================

baselineCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[  0.05101288   0.34904203   0.07070147   0.04308992   0.07070363
    0.07070118  -6.6072907    0.07070285   0.07070228   0.07070187
    0.07070588   0.07070226   0.07070211   0.30267236   0.07070184
    0.0707032    0.07070399   3.075093     0.0707033    0.07070208
    0.07070169   0.07070336 -10.554588     0.07070164  -6.1359563
    0.07069833   0.07070523   0.07070372   0.0707012    0.07070084
    0.07070182   0.20579533]]

Final Loss: 0.1858
Distance Metric: 51.0808
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 1
seed: 1

================================================================================

baselineCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[-0.9077754   0.33014646  0.          0.          0.          0.
   0.          0.         -0.9250641   0.          0.          0.
   0.2986711   0.          0.          0.         -0.5927335   0.
   0.          0.          0.         -0.43506113 -0.24064094  0.25438908
   0.23147283  0.37627506  0.         -0.34382585  0.2654807   0.
   0.          0.        ]]

Final Loss: 0.1946
Distance Metric: 14.0784
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 1
seed: 1

================================================================================

baselineCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.          0.          0.          0.          0.36120945
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.         -0.48988786  0.          0.          0.
   0.          0.          0.47760183  0.          0.          0.36929908
   0.          0.        ]]

Final Loss: 0.0004
Distance Metric: 11.4248
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 1
seed: 1

================================================================================


