Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[ 2.59 -2.83  0.87]]]
layers.1.weight: [[[-1.38  1.29]]]
layers.2.weight: [[[ 0.86 -0.84]]]

================================================================================

nonoverlappingCNN_relu -> fcnn_relu

Student Model Parameters:
layers.0.weight: [[-2.92591937e-02  6.72919583e-03 -5.72924763e-02 ... -1.19240604e-01
   1.76999848e-02  0.00000000e+00]
 [ 0.00000000e+00 -1.51935220e-01 -6.70842975e-02 ... -1.21390086e-03
   6.62985623e-01 -6.02123104e-02]
 [-2.79289424e-01 -3.44620615e-01 -3.01362604e-01 ... -6.38145627e-03
   1.54523700e-01 -2.27813810e-01]
 ...
 [ 4.20625567e-01  3.59427810e-01 -2.75862098e-01 ... -1.96602643e-02
  -4.62771624e-01 -2.08953246e-01]
 [ 0.00000000e+00  1.79412216e-01 -2.40944850e-04 ...  7.19717646e-04
  -5.01618371e-04  1.35318405e-04]
 [ 5.52742422e-01 -5.13423583e-04  4.52032655e-01 ...  0.00000000e+00
  -2.58305460e-01 -3.16733241e-01]]
layers.1.weight: [[ 0.          0.02329701  0.         ... -0.06094793  0.
  -0.00802327]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.0003651   0.00032469 ... -0.00162482  0.00031861
   0.00836128]
 ...
 [ 0.          0.07770713 -0.00033014 ...  0.          0.00041027
   0.00089985]
 [ 0.          0.00517305  0.04551415 ...  0.          0.
   0.        ]
 [ 0.00448218 -0.05833575 -0.00077001 ...  0.00033983  0.00034927
   0.00023222]]
layers.2.weight: [[ 8.43764916e-02  0.00000000e+00  3.44800055e-01  1.10499728e-04
   5.51580429e-01  3.24558243e-02  1.48063089e-04  4.63481098e-01
  -6.20364794e-04 -1.91017447e-04  0.00000000e+00 -1.09009624e-01
  -6.39089942e-02  1.65753409e-01  2.40030631e-01 -9.98182893e-02
  -6.62638247e-02  3.72672975e-01  3.53888720e-02 -3.65988701e-04
  -1.59862946e-04  3.21171567e-04  2.06774175e-01  0.00000000e+00
  -3.52951080e-01 -7.79129041e-04  5.23358107e-01  2.32112125e-01
   4.58004653e-01  6.99320361e-02  0.00000000e+00  1.60942189e-04
   1.03109457e-01  1.11653537e-01 -3.66394967e-01 -3.98339033e-02
   1.00521452e-03 -5.21401584e-04 -2.32018515e-01  0.00000000e+00
   2.26866126e-01  5.90264440e-01  0.00000000e+00  0.00000000e+00
   2.19570607e-01  1.80230069e-04  6.46134256e-04  2.64952332e-01
  -1.93251151e-04  7.99004078e-01  3.64103653e-02  4.49469507e-01
   2.44714588e-01  2.55551219e-01 -1.38560519e-01  2.43551061e-01
   1.00913987e-01  2.23032430e-01 -3.60860258e-01 -1.34972826e-01
  -9.13153170e-04  0.00000000e+00 -8.35897475e-02 -1.08096175e-01
   0.00000000e+00  3.30242037e-04  0.00000000e+00  4.69654500e-01
   2.43503440e-04 -1.77791655e-01  2.52634764e-01  1.48315668e-01
   2.91415542e-01  3.07999551e-04  2.11176634e-01  3.33445013e-01
  -4.15359973e-04 -2.76088752e-02 -1.03477526e+00 -1.94580048e-01
   3.63572966e-04  1.84302315e-01 -1.00832061e-04  1.45520637e-04
   1.73199526e-03 -4.07801010e-02 -1.17926084e-01 -5.87562978e-01
  -3.03046945e-02 -2.35433280e-01 -7.86350295e-03  1.67306192e-04
   9.50440168e-02  1.23212507e-04  9.76268575e-02 -1.33173525e-01
  -2.76298314e-01 -2.03721528e-03 -5.31217873e-01  0.00000000e+00
   3.81416440e-01  1.81751733e-03  0.00000000e+00 -4.24328208e-01
   0.00000000e+00 -1.40990242e-01 -8.33789557e-02 -1.14179410e-01
   2.27697745e-01  0.00000000e+00  0.00000000e+00 -1.02245051e-03
   3.45259786e-01 -2.20739737e-01  2.95584032e-04  1.77671120e-01
   0.00000000e+00  1.62103621e-03 -2.07380354e-02 -7.28234470e-01
   3.62878869e-04  4.64719266e-01  6.09580278e-01 -5.66708565e-01
   3.84792149e-01  3.08511198e-01  0.00000000e+00 -3.93514603e-01]]

Final Loss: 0.0066
Distance Metric: 22.2904
L1 norm: 1e-05
L2 norm: 0
Batch size: 32
Clipping: 0

================================================================================

nonoverlappingCNN_tanh -> fcnn_tanh

Student Model Parameters:
layers.0.weight: [[ 0.         -0.09430128  0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.02992682  0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.         -0.48604015  0.          0.          0.          0.
   0.          0.          0.42865697  0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.         -0.442262
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.0865187   0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.43322855 -0.40506074  0.          0.
   0.          0.          0.          0.         -0.19111416  0.
   0.          0.          0.          0.          0.         -0.6422606
   0.          0.          0.          0.          0.          0.
   0.          0.          0.         -0.17941369  0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.        ]]

Final Loss: 0.0006
Distance Metric: 11.9499
L1 norm: 1e-05
L2 norm: 0
Batch size: 32
Clipping: 0

================================================================================

nonoverlappingCNN_sigmoid -> fcnn_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.          0.          0.         ...  0.         -0.09717721
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.          0.          0.         -0.11013491  1.7629086
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.         -0.00712271  0.          0.
  -0.39882648  0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.         -0.01275102  0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.         -0.19518262  0.          0.          0.
   0.          0.         -0.12984489  0.         -0.02439877  0.
   0.          0.          0.          0.          0.6639641   0.
   0.          0.         -0.97272193  0.          0.          0.
   0.          0.          0.          0.          0.         -0.08574711
   0.          0.          0.          0.          0.         -0.01049123
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.        ]]

Final Loss: 0.0003
Distance Metric: 9.6182
L1 norm: 1e-05
L2 norm: 0
Batch size: 32
Clipping: 0

================================================================================

