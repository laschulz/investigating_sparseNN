Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[ 2.59 -2.83  0.87]]]
layers.1.weight: [[[-1.38  1.29]]]
layers.2.weight: [[[ 0.86 -0.84]]]

================================================================================

nonoverlappingCNN_relu -> fcnn_relu

Student Model Parameters:
layers.0.weight: [[ 1.05716467e+00 -5.38033307e-01  3.24015617e-01 ...  2.41069961e-02
  -4.48212802e-01 -1.12291835e-01]
 [-1.61527731e-02  1.91402689e-01 -1.76646322e-01 ... -8.58125836e-03
   1.36063652e-04 -7.65602454e-04]
 [ 7.14438796e-01  3.40472698e-01  3.67596447e-01 ...  6.85364842e-01
   5.57542026e-01 -7.77087152e-01]
 ...
 [ 9.78193805e-03  4.65457231e-01  1.66379235e-04 ...  0.00000000e+00
  -5.92098594e-01 -1.01742320e-01]
 [-3.80952656e-01  1.95278198e-01  4.42240417e-01 ... -1.42352119e-01
   5.03661633e-01  3.63717496e-01]
 [ 0.00000000e+00  0.00000000e+00  4.68188167e-01 ... -7.87448660e-02
  -5.05961180e-01  2.33463274e-04]]
layers.1.weight: [[ 0.0000000e+00 -1.7894077e-04  2.1344316e-04 ... -4.6311494e-02
  -1.3711258e-03  0.0000000e+00]
 [ 3.2008480e-02  0.0000000e+00  1.7264507e-04 ...  5.4062688e-04
   3.2994028e-02  2.4839400e-04]
 [ 0.0000000e+00  0.0000000e+00 -2.6442301e-02 ...  0.0000000e+00
   0.0000000e+00  0.0000000e+00]
 ...
 [ 1.2804935e-04  6.5142408e-02  0.0000000e+00 ... -2.7487651e-04
   1.4372081e-04  4.4665623e-02]
 [ 2.2490914e-01  1.3883442e-01  9.7847218e-03 ...  1.9130188e-04
  -3.0012935e-01  7.2257221e-02]
 [-7.7989494e-04 -1.8375485e-04 -1.7058806e-04 ...  0.0000000e+00
   1.2626525e-03  0.0000000e+00]]
layers.2.weight: [[-2.06571639e-01  2.55476087e-01  0.00000000e+00  2.12507397e-01
   0.00000000e+00 -2.55084723e-01  3.80539298e-01  0.00000000e+00
  -1.87450692e-01 -1.09693028e-01  0.00000000e+00  3.58818495e-03
   1.03218965e-01  0.00000000e+00 -1.68088347e-01 -1.75209045e-02
  -4.71479744e-01 -8.43719482e-01 -8.97453874e-02  0.00000000e+00
   4.69430029e-01 -2.18581888e-04  2.99762731e-04 -2.82687675e-02
   0.00000000e+00  0.00000000e+00 -2.33102575e-01 -2.68995936e-04
  -1.35063544e-01  4.57193941e-01 -1.21437453e-01 -1.09598134e-02
   1.01931699e-04  9.51578990e-02  2.51128882e-01  5.74548900e-01
  -2.77370453e-01  1.34809658e-01 -2.34206095e-01  4.62892130e-02
   3.12946051e-01  0.00000000e+00 -2.26326380e-02  8.96262303e-02
  -1.61244869e-04  0.00000000e+00 -6.05113626e-01  0.00000000e+00
  -3.70382249e-01  2.59376913e-01 -1.60971969e-01 -4.07171465e-04
  -2.88683802e-01 -3.04686755e-01 -7.17948616e-01  0.00000000e+00
   6.11844175e-02  4.63183882e-04 -1.16385665e-04 -1.60976067e-01
  -5.13880253e-01  0.00000000e+00  3.05432349e-01  3.83669645e-01
   0.00000000e+00 -2.16885775e-01  2.06332430e-01 -4.52650599e-02
  -7.95661807e-02 -1.30461892e-02  1.90618798e-01  9.91997197e-02
  -3.07075143e-01 -2.54954457e-01 -3.43549624e-02  0.00000000e+00
  -3.65193374e-03  2.49885097e-01  5.05580232e-02  0.00000000e+00
  -1.13151416e-01  1.38425544e-01  3.30176383e-01 -4.34912980e-01
   2.22759470e-01  1.42457255e-04  2.85603374e-01 -4.80522037e-01
  -2.54476219e-01  8.51082951e-02  2.85490781e-01  0.00000000e+00
   3.71655537e-04 -1.15186500e-04 -8.91830549e-02 -6.47507086e-02
  -1.05031635e-04  1.67047530e-01 -3.67552944e-04 -1.35186210e-01
  -1.38814226e-04  6.85689226e-02  0.00000000e+00  2.38904342e-01
  -3.01024076e-02  8.75852245e-04  0.00000000e+00  4.54363180e-04
   0.00000000e+00  4.85060997e-02  2.40833047e-04  4.22936887e-01
   4.09439579e-02 -1.56891793e-01  0.00000000e+00 -1.95457101e-01
   6.59639165e-02  1.52941881e-04  2.52728760e-01  1.37756739e-04
  -1.94626585e-01 -8.13294388e-03 -1.67765751e-01  1.02522317e-03
   0.00000000e+00 -2.50227034e-01 -6.03728771e-01  2.05655888e-01]]

Final Loss: 0.0109
Distance Metric: 24.8600
L1 norm: 1e-05
L2 norm: 0
Batch size: 32
Clipping: 0

================================================================================

nonoverlappingCNN_tanh -> fcnn_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.3885413  0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.38146862 0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.4772021
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.44956458 0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.        ]]

Final Loss: 0.0004
Distance Metric: 11.5048
L1 norm: 1e-05
L2 norm: 0
Batch size: 32
Clipping: 0

================================================================================

nonoverlappingCNN_sigmoid -> fcnn_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
  -0.02941445]
 [ 0.00460783  0.          0.         ...  0.03766887  0.
   0.        ]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          1.336822    0.
   0.          0.          0.          0.          0.         -1.9103684
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.03790715  0.          0.          0.          0.
   0.          0.47652382  0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.2549273   0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.        ]]

Final Loss: 0.0003
Distance Metric: 10.4273
L1 norm: 1e-05
L2 norm: 0
Batch size: 32
Clipping: 0

================================================================================

