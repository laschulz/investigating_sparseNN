Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.2718761  -0.40430093  0.5150949 ]]]
layers.1.weight: [[[-0.67822325 -0.09694757]]]
layers.2.weight: [[[ 0.67802006 -0.3834003 ]]]

================================================================================

baselineCNN_sigmoid -> fcn_128_128_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0.         0.         0.         0.         0.         0.
  0.         0.02860321 0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.01990541 0.         0.         0.         0.         0.
  0.00453852 0.         0.         0.         0.         0.01342098
  0.         0.         0.         0.03423987 0.         0.
  0.         0.01262776 0.03154238 0.         0.         0.0058778
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.02034395 0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.04247249
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.01249496
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.        ]]

Final Loss: 0.0000
Distance Metric: 2.2023
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 253

================================================================================

baselineCNN_sigmoid -> fcn_128_128_relu

Student Model Parameters:
layers.0.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.05931971 -0.02064232 -0.09156831 ...  0.00016618 -0.00876895
   0.05075843]
 [ 0.0055277   0.13310172 -0.00095201 ...  0.00495905 -0.01983479
   0.01750842]
 ...
 [ 0.01658734 -0.00782065 -0.04792113 ... -0.14756867 -0.08048411
  -0.0059389 ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.03404077 -0.00412095 -0.0067033  ... -0.02289029 -0.00808794
  -0.00278763]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        1.0374761 0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.       ]]

Final Loss: 0.0118
Distance Metric: 4.1367
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 1344

================================================================================

baselineCNN_sigmoid -> fcn_128_128_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.         -0.08396178
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.        ]]

Final Loss: 0.2316
Distance Metric: 3.8848
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 220

================================================================================

baselineCNN_relu -> fcn_128_128_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[-0.1208571  -0.003861   -0.25667462 -0.19135566 -0.00417397 -0.20565186
  -0.20588574 -0.00466401 -0.03143914 -0.00415282 -0.00702998 -0.07067958
  -0.00655885 -0.16817307 -0.0048078  -0.16888782 -0.00413839 -0.2269486
  -0.22370777 -0.00519968 -0.06832874 -0.17592189 -0.07970791 -0.14734024
  -0.15331744 -0.00505448 -0.06284299 -0.00427313 -0.00563726 -0.05933078
  -0.00390625 -0.00429216 -0.00484281 -0.17279536 -0.00470628 -0.07675578
  -0.0829358  -0.117784   -0.00359033 -0.10167994 -0.16107568 -0.28098717
  -0.00711701 -0.25       -0.00397773 -0.18276194 -0.19960819 -0.14258471
  -0.00696354 -0.09215502 -0.04761536 -0.00381116 -0.2728264  -0.00363835
  -0.00425811 -0.10904782 -0.18535693 -0.03531156 -0.00501859 -0.00479152
  -0.25864762 -0.0066106  -0.05087943 -0.25154704 -0.00372745 -0.0467116
  -0.17540157 -0.00452221 -0.00489823 -0.1451409  -0.19624633 -0.00416377
  -0.00405451 -0.00385178 -0.19734007 -0.0051843  -0.10874711 -0.06124961
  -0.2062134  -0.00411882 -0.02375469 -0.00454553 -0.05917114 -0.08752306
  -0.21993388 -0.0054871  -0.00540646 -0.23568332 -0.27008805 -0.08846466
  -0.07428952 -0.00405717 -0.18272993 -0.02163306 -0.11426938 -0.00427321
  -0.2372112  -0.21700172 -0.04940949 -0.23578875 -0.08414612 -0.07231402
  -0.00321617 -0.13676767 -0.00362517 -0.00569983 -0.03148986 -0.08410212
  -0.19813111 -0.00485572 -0.00576052 -0.00376386 -0.16473454 -0.00463016
  -0.20243037 -0.12104581 -0.26437098 -0.27324033 -0.00493766 -0.00625296
  -0.22580142 -0.1295946  -0.1635142  -0.0071429  -0.03636153 -0.00456649
  -0.05543699 -0.07646516]]

Final Loss: 0.0001
Distance Metric: 4.6663
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 166

================================================================================

baselineCNN_relu -> fcn_128_128_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.        -0.7369038  0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.9398275  0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.       ]]

Final Loss: 0.0001
Distance Metric: 3.6034
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 1990

================================================================================

baselineCNN_relu -> fcn_128_128_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0.]]

Final Loss: 0.0000
Distance Metric: 2.6951
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 231

================================================================================

baselineCNN_tanh -> fcn_128_128_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 1.0825732e-03  1.0835812e-03  1.0829619e-03  1.0830370e-03
   1.0828151e-03  1.0834382e-03  1.0830601e-03  1.0831343e-03
   1.0835328e-03  1.0835497e-03  1.0833654e-03  1.0834803e-03
   1.0830080e-03  1.0832114e-03 -2.2806575e+00  1.0834425e-03
   1.0830822e-03  1.0831770e-03  1.0829219e-03  1.0834086e-03
   1.0826121e-03  1.0828180e-03  1.0832575e-03  1.0832979e-03
   1.0826633e-03  1.0832490e-03  1.0827326e-03  1.0834818e-03
   1.0833701e-03  3.1008086e-01  1.0835284e-03  1.0828812e-03
   1.0828478e-03  1.0825414e-03  1.0830495e-03  1.0831369e-03
   1.0832327e-03  1.0829399e-03  1.0833179e-03  1.0832135e-03
   1.0830662e-03  1.0830108e-03  1.0827926e-03  1.0829805e-03
   1.0826793e-03  1.0834472e-03  1.0833568e-03  1.0830674e-03
   1.0831931e-03  1.0829250e-03  1.0831575e-03  1.0832468e-03
   1.0834237e-03  1.0827744e-03  1.0831069e-03  1.0827782e-03
   1.0831380e-03  1.0826894e-03  1.0827160e-03  1.0829753e-03
   1.0831335e-03  1.0831172e-03 -1.1693922e+01  1.0826852e-03
   1.0828819e-03  1.0830415e-03  1.0834051e-03  1.0830025e-03
   1.0828626e-03  1.0833299e-03  1.0835006e-03  1.0834844e-03
   1.0828984e-03  1.0831789e-03  1.0826710e-03  1.0826710e-03
   1.0827566e-03  1.0830440e-03  1.0830329e-03  1.0831048e-03
   1.0834427e-03  1.0831129e-03  1.0830300e-03  1.0829190e-03
   1.0832871e-03  1.0830176e-03  1.0827282e-03  1.0828726e-03
   1.0835340e-03  1.0831493e-03  1.0832833e-03  1.0827065e-03
   1.0831328e-03  1.0833406e-03  1.0827412e-03  1.0833585e-03
   1.6370441e+00  1.0829912e-03  1.0830013e-03  1.0832014e-03
   1.0829228e-03  1.0828482e-03  1.0829368e-03  1.0833299e-03
   1.0830914e-03  1.0828488e-03  1.0834611e-03  1.0832065e-03
   1.0833038e-03  1.0831654e-03  1.0833469e-03  1.0832768e-03
   1.0826354e-03  1.0834989e-03  1.0835148e-03  1.0834475e-03
   1.0825620e-03  1.0828213e-03  1.0828810e-03  1.0834029e-03
   1.0828784e-03  1.0830945e-03  1.0832325e-03  1.0826560e-03
   1.0826229e-03  1.0831667e-03 -2.4002252e+00  1.0829363e-03]]

Final Loss: 0.0712
Distance Metric: 36.0905
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 5429

================================================================================

baselineCNN_tanh -> fcn_128_128_relu

Student Model Parameters:
layers.0.weight: [[ 0.02843127 -0.00281372 -0.00320029 ... -0.01315779 -0.07002945
  -0.23021331]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.00249809 -0.1182721   0.05752651 ... -0.01147063  0.10699466
   0.06956643]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.03867618  0.         -0.03038822 ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.00210947  0.         -0.00262293 ...  0.          0.
   0.        ]]
layers.2.weight: [[ 0.          0.          0.9296572   0.          0.          0.
   0.          0.          0.          0.          0.          0.
  -0.86228293 -1.1677122   0.          0.          0.          0.
   0.          0.          0.          0.4201045   0.          0.
  -1.4664297   0.         -0.08914123  0.          0.          0.
  -1.0191019   0.          0.          0.          0.          0.50602233
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.         -1.0091864   0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.26249337  0.          0.
   0.          0.          0.          0.          0.         -0.8279603
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
  -0.4815272  -0.62067074  0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.7307875
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.37694842  0.          0.
   0.          0.          0.          0.          0.          0.
   0.         -0.46760753]]

Final Loss: 0.3627
Distance Metric: 11.0006
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 912

================================================================================

baselineCNN_tanh -> fcn_128_128_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.        -0.9803785  0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.        -1.1099344  0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.       ]]

Final Loss: 0.0001
Distance Metric: 4.1001
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 1236

================================================================================

