Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[ 0.29690564  0.9383415  -0.4263723 ]]]
layers.1.weight: [[[0.90976566 0.16705942]]]
layers.2.weight: [[[-0.996852   0.9182749]]]

================================================================================

baselineCNN_sigmoid -> fcn_128_128_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.         0.         0.         0.6683389  0.         0.
   0.         0.         0.        -1.2174145  0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.       ]]

Final Loss: 0.0001
Distance Metric: 3.4987
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 4
stopped after epoch: 2911

================================================================================

baselineCNN_sigmoid -> fcn_128_128_relu

Student Model Parameters:
layers.0.weight: [[ 0.02857266 -0.01284342 -0.0957205  ... -0.04398154 -0.00155544
  -0.01781433]
 [-0.01138901 -0.09386303  0.02123045 ...  0.00484295  0.0520763
   0.05986873]
 [ 0.1057135   0.04523214 -0.06813126 ... -0.09940983  0.00155378
  -0.05535403]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.10826692 -0.00156983 -0.04568426 ... -0.07443735  0.01193325
   0.06854811]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0.         0.         0.         0.         0.         0.
  0.01817662 0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.880878   0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.        ]]

Final Loss: 0.0178
Distance Metric: 4.2573
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 4
stopped after epoch: 1775

================================================================================

baselineCNN_sigmoid -> fcn_128_128_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.         -0.13009256  0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.        ]]

Final Loss: 0.1809
Distance Metric: 3.5168
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 4
stopped after epoch: 428

================================================================================

baselineCNN_relu -> fcn_128_128_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[-0.2263828  -0.00438455 -0.12504727 -0.1851942  -0.17319322 -0.00523583
  -0.09133163 -0.08267913 -0.1699475  -0.0042696  -0.00560408 -0.26364744
  -0.00496387 -0.00386652 -0.00473318 -0.03061977 -0.2731281  -0.00464968
  -0.09882349 -0.04917028 -0.23783332 -0.00433849 -0.04961024 -0.0059755
  -0.21054631 -0.22008516 -0.02259238 -0.15362588 -0.1988533  -0.02430808
  -0.00314579 -0.22530442 -0.06744726 -0.31208995 -0.00353723 -0.10085335
  -0.00729386 -0.05076316 -0.00392318 -0.15739359 -0.20993946 -0.24596034
  -0.16512755 -0.00556679 -0.19611365 -0.2238665  -0.21634425 -0.060878
  -0.00562622 -0.00455659 -0.00442282 -0.04702337 -0.06917232 -0.31022418
  -0.01544841 -0.15580642 -0.19767465 -0.20775281 -0.13136616 -0.0973961
  -0.03766406 -0.00589757 -0.10419603 -0.00469588 -0.13782977 -0.00422097
  -0.16407543 -0.01130952 -0.00505297 -0.00366457 -0.00446876 -0.03421222
  -0.00453991 -0.26225403 -0.00520173 -0.22291788 -0.00475749 -0.09614989
  -0.00517394 -0.00435245 -0.00430935 -0.05126889 -0.00398246 -0.00501772
  -0.04598422 -0.10702319 -0.04448046 -0.11764678 -0.00372676 -0.00390625
  -0.00484879 -0.00585851 -0.00429974 -0.00414341 -0.00394963 -0.00375745
  -0.30559126 -0.00493876 -0.2609596  -0.2240755  -0.03962778 -0.17346193
  -0.00428745 -0.00445132 -0.22350544 -0.1487033  -0.00529067 -0.0044307
  -0.00535674 -0.15358102 -0.00542704 -0.13971367 -0.23751995 -0.00378729
  -0.16814695 -0.0049409  -0.24967189 -0.07162098 -0.30955225 -0.10863563
  -0.14835492 -0.20648722 -0.0046778  -0.23309846 -0.00440537 -0.0433692
  -0.02807094 -0.00393386]]

Final Loss: 0.0001
Distance Metric: 5.1292
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 4
stopped after epoch: 177

================================================================================

baselineCNN_relu -> fcn_128_128_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.93190956 -0.94238055
   0.          0.          0.          0.          0.          0.
  -1.3007004   0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.        ]]

Final Loss: 0.0001
Distance Metric: 4.5142
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 4
stopped after epoch: 3210

================================================================================

baselineCNN_relu -> fcn_128_128_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0.]]

Final Loss: 0.0000
Distance Metric: 3.2524
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 4
stopped after epoch: 230

================================================================================

baselineCNN_tanh -> fcn_128_128_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[-1.17327814e-04 -1.17021460e-04 -1.17473079e-04 -1.17325995e-04
  -1.17775911e-04 -1.17680684e-04 -1.17049312e-04 -1.17558819e-04
  -1.17029362e-04 -1.17059186e-04 -1.17536474e-04 -1.17374017e-04
  -1.17611940e-04 -1.17019561e-04 -1.17137708e-04 -1.17643489e-04
  -1.17587893e-04 -1.17420132e-04 -1.17346535e-04 -1.17508775e-04
  -1.17624739e-04 -1.17881144e-04 -1.17156735e-04 -1.17388023e-04
  -1.17429416e-04 -1.17212992e-04 -1.17278956e-04 -1.17067204e-04
  -1.17510179e-04 -1.17741649e-04 -1.17453375e-04 -1.17286480e-04
  -1.17332595e-04 -1.17610994e-04 -1.17167765e-04 -1.17464697e-04
  -1.17300442e-04 -1.17362768e-04 -1.17129966e-04 -1.17406737e-04
  -1.17655793e-04 -1.17570657e-04 -1.17532996e-04 -1.17338430e-04
  -1.17620963e-04 -1.16922609e-04 -1.17094954e-04 -1.17596246e-04
  -1.17478448e-04 -1.17715004e-04 -1.17690193e-04 -1.17372867e-04
  -1.17801588e-04 -1.17260839e-04 -1.17232332e-04 -1.17788339e-04
  -1.17883421e-04 -1.17281095e-04 -1.17259340e-04 -1.17495831e-04
  -1.17417483e-04 -1.17260359e-04 -1.17050971e-04 -1.16929506e-04
  -1.22718363e+01 -1.17418174e-04 -1.17637981e-04 -1.17167525e-04
  -1.17448471e-04 -1.17080890e-04 -1.17259224e-04 -1.17758675e-04
  -1.17701813e-04 -1.17488475e-04 -1.17539552e-04 -1.17619020e-04
  -1.17131865e-04 -1.17844829e-04 -1.17699019e-04 -1.17621210e-04
  -1.17879019e-04 -1.17766140e-04 -1.17166586e-04 -1.17494106e-04
  -1.17293326e-04 -1.17391646e-04 -1.17000629e-04 -1.17078911e-04
  -1.17099626e-04 -1.17741743e-04 -1.17269927e-04 -1.17495263e-04
  -1.17835232e-04 -1.17433701e-04 -1.17493226e-04 -1.17010903e-04
  -1.17039017e-04 -1.17307158e-04 -1.17587952e-04 -1.17586758e-04
  -1.17247109e-04 -1.16916985e-04 -1.17248863e-04 -1.17148527e-04
   3.39183474e+00 -1.16931515e-04 -1.17673517e-04 -1.17005337e-04
  -1.17776930e-04 -1.17148586e-04 -1.17462019e-04 -1.17218355e-04
  -1.17045012e-04 -1.17345138e-04 -1.16964460e-04 -1.17500291e-04
  -1.17856602e-04 -1.17159434e-04 -1.17876349e-04 -1.17531497e-04
  -1.17908516e-04 -1.01416457e+00 -1.17384945e-04 -1.17509036e-04
  -1.17906820e-04 -1.17330761e-04 -1.17595984e-04 -1.17168558e-04]]

Final Loss: 0.2557
Distance Metric: 32.1371
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 4
stopped after epoch: 4437

================================================================================

baselineCNN_tanh -> fcn_128_128_relu

Student Model Parameters:
layers.0.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.11678039 -0.14903705 -0.2356652  ...  0.05954449 -0.04655502
  -0.29708725]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.         -0.02886895  0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.2.weight: [[ 0.28625742  0.6653442   0.          0.32480648  0.          0.
   0.         -0.6076808   0.          0.          0.          0.
  -0.45848784  0.          0.7084377   0.          0.          0.
   0.          0.          0.          0.28195077  0.          0.
   0.          0.          0.          0.          0.          0.
   0.32652536  0.          0.          0.          0.          0.
  -0.3706682   0.          0.46118188  0.          0.          0.
   0.          0.          0.          0.4939344   0.          0.
   0.          0.         -0.9954351   0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.2845786   0.          0.          0.42705014
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.23763064  0.          0.
   0.         -0.42376733  0.         -0.4434251   0.          0.9924286
   0.          0.          0.2519617   0.          0.          0.
   0.          0.          0.          0.          0.49891028  0.
   0.          0.          0.          0.         -0.41677335  0.
   0.         -1.4071858   0.         -0.5677567   0.2840893   0.
   0.          0.          0.          0.          0.          0.
   0.         -0.56248534  0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.        ]]

Final Loss: 0.2870
Distance Metric: 9.4822
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 4
stopped after epoch: 1177

================================================================================

baselineCNN_tanh -> fcn_128_128_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.          0.          0.         -0.43073022  0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          1.6176524   0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.        ]]

Final Loss: 0.0001
Distance Metric: 3.9537
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 4
stopped after epoch: 1446

================================================================================

