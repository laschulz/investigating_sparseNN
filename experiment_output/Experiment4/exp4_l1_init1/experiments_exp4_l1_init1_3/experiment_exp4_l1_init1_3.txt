Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[ 0.7077322  -0.6849532   0.40006435]]]
layers.1.weight: [[[-0.5698907  -0.57363313]]]
layers.2.weight: [[[-0.2114608  -0.11755428]]]

================================================================================

baselineCNN_sigmoid -> fcn_128_128_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.          0.          0.          0.         -0.00246916
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.         -0.02873661  0.          0.
  -0.03485129  0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.         -0.04277524  0.         -0.04307439
   0.          0.         -0.00420679  0.          0.          0.
   0.          0.          0.         -0.01572554 -0.03651616  0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.         -0.02403813  0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.        ]]

Final Loss: 0.0000
Distance Metric: 2.1210
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 202

================================================================================

baselineCNN_sigmoid -> fcn_128_128_relu

Student Model Parameters:
layers.0.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.00231496 -0.05074073 -0.05526752 ...  0.02861487 -0.01733571
  -0.00014126]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         1.1681638  0.         0.         0.
  0.         0.         0.         0.589028   0.         0.6922898
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.6660627  0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.72191054
  0.         0.         0.         0.         0.         0.
  0.         0.6117663  0.         0.         0.         0.
  0.         0.        ]]

Final Loss: 0.0034
Distance Metric: 5.9522
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 1372

================================================================================

baselineCNN_sigmoid -> fcn_128_128_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.        -0.1125976  0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.       ]]

Final Loss: 0.4880
Distance Metric: 6.1702
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 400

================================================================================

baselineCNN_relu -> fcn_128_128_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 1.5923622e-04  1.5878689e-04  1.5865153e-04  1.5864646e-04
   1.5933391e-04  1.5935610e-04  1.5885737e-04  1.5877074e-04
   1.5911770e-04  1.5933567e-04  1.5890524e-04  1.5897510e-04
   1.5893689e-04  1.5858022e-04  1.5861179e-04  1.5914248e-04
   1.5884553e-04  1.5879558e-04  1.5868332e-04  1.5930377e-04
   1.5945006e-04  1.5857385e-04  1.5858746e-04  1.5865616e-04
   1.5885899e-04  1.5901198e-04  1.5858734e-04  1.5946339e-04
   1.5920035e-04  1.5883503e-04  1.5867119e-04  1.5938477e-04
   1.5909916e-04  1.5907097e-04  1.5891212e-04  1.5933592e-04
   1.5910545e-04  1.5859939e-04  4.7379031e+00  1.5853083e-04
   1.5854272e-04  1.5866582e-04  1.5857055e-04  1.5929209e-04
   1.5858140e-04  1.5907717e-04  1.5899124e-04  1.5937279e-04
   1.5862101e-04  1.5938655e-04  1.5939517e-04  1.5889625e-04
   1.5923881e-04  1.5889695e-04  1.5944702e-04  1.5922813e-04
   1.5912918e-04  1.5882982e-04  1.5867430e-04 -1.5593493e+01
   1.5860873e-04  1.5902521e-04  1.5907323e-04  1.5900355e-04
   1.5931649e-04  1.5940254e-04  1.5889329e-04  1.5877970e-04
   1.5935673e-04  1.5888172e-04 -1.0362634e+01  1.5931651e-04
   1.5880358e-04  1.5912383e-04  1.5927370e-04  1.5915312e-04
   1.5890015e-04  1.5916326e-04  1.5913787e-04  1.5866764e-04
   1.5892086e-04  1.5940267e-04  1.5907432e-04  1.5897618e-04
   1.5921248e-04  1.5896979e-04  1.5931386e-04  1.5859368e-04
   1.5860113e-04  1.5854048e-04  1.5909188e-04  1.4352790e+01
   1.5887377e-04  1.5924744e-04  1.5937831e-04  1.5868942e-04
   1.5868792e-04  1.5914923e-04  1.5906530e-04  1.5864805e-04
   1.5851221e-04  1.5876353e-04  1.5888072e-04  1.5922116e-04
   1.5881140e-04  1.5890670e-04  1.5849900e-04  1.5931010e-04
   1.5928262e-04  1.5919325e-04  1.5862186e-04  1.5856973e-04
   1.5934269e-04  1.5901515e-04  1.5882701e-04  1.5851467e-04
   1.5884402e-04  1.5859908e-04  1.5933487e-04  1.5904900e-04
   1.5915502e-04  1.5943986e-04  1.5879756e-04  1.5899018e-04
   1.5899120e-04  1.5912835e-04  1.5924976e-04  1.5890341e-04]]

Final Loss: 1.7514
Distance Metric: 47.6895
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 5217

================================================================================

baselineCNN_relu -> fcn_128_128_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0.]]

Final Loss: 0.0000
Distance Metric: 5.3293
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 1914

================================================================================

baselineCNN_relu -> fcn_128_128_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0.]]

Final Loss: 0.0000
Distance Metric: 2.8581
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 214

================================================================================

baselineCNN_tanh -> fcn_128_128_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[  0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.        -10.863833    0.          0.
    0.         -4.8009515   0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          4.9189625   0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.       ]]

Final Loss: 0.2039
Distance Metric: 31.3206
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 5651

================================================================================

baselineCNN_tanh -> fcn_128_128_relu

Student Model Parameters:
layers.0.weight: [[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00
   0.0000000e+00  0.0000000e+00]
 [ 2.9400423e-02 -1.0527669e-02 -6.1230385e-04 ...  4.3808736e-04
  -1.2572643e-01 -1.3554543e-01]
 [-9.3277849e-02 -6.5041918e-01  7.6869506e-01 ...  4.7903713e-03
   9.6526213e-02 -1.0255590e-01]
 ...
 [ 5.8823698e-03  8.2697399e-02 -3.8572580e-02 ...  2.9648822e-02
  -1.6141579e-01  4.6761893e-02]
 [ 1.8568611e-01  2.0168236e-02  5.4074410e-02 ... -5.5997674e-03
  -1.1341850e-01  1.8582138e-03]
 [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00
   0.0000000e+00  0.0000000e+00]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.         -0.5346053   0.          0.          0.
  -0.81255513  0.          0.          0.          0.          0.5298631
   0.          0.5601281   0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.         -0.6921156   0.
   0.          0.          0.          0.         -0.8675043   0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.46248767 -0.8527451
   0.          0.          0.          0.          0.         -1.3820027
  -0.33119208  0.          0.          0.         -0.70709145  0.4277821
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.65469223
  -0.82119054 -0.44069177  0.          0.41759723  0.          0.
   0.          0.          0.          0.49536863  0.         -0.2740234
   0.          0.          0.4623196   0.7767685   0.          0.
   0.50033265  0.          0.          0.         -0.6707205   0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.         -0.6702216   0.          0.
   0.          0.          0.          0.          0.          0.
   0.         -0.83784443  0.          0.          0.         -0.6579572
   0.          0.          0.          0.          0.          0.
   0.          0.        ]]

Final Loss: 0.2903
Distance Metric: 11.3862
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 1087

================================================================================

baselineCNN_tanh -> fcn_128_128_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.         -1.1682541   0.          0.
   0.          0.          0.          0.          0.          0.
  -0.26145086  0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.         -0.12421229
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.        ]]

Final Loss: 0.0002
Distance Metric: 4.1532
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 3
stopped after epoch: 1668

================================================================================

