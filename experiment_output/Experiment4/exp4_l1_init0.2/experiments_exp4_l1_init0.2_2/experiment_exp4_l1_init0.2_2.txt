Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[ 2.59 -2.83  0.87]]]
layers.1.weight: [[[-1.38  1.29]]]
layers.2.weight: [[[ 0.86 -0.84]]]

================================================================================

baselineCNN_sigmoid -> fcn_128_128_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0.00011524 0.00011489 0.00011479 0.0001148  0.00011532 0.0001147
  0.00011528 0.00011474 0.00011502 0.00011472 0.00011553 0.00011505
  0.00011461 0.00011515 0.00011539 0.00011451 0.00011464 0.00011518
  0.00011531 0.00011485 0.00011523 0.00011494 0.00011493 0.00011539
  0.00011506 0.00011459 0.0001148  0.00011539 0.00011534 0.00011543
  0.0001154  0.00011545 0.0001151  0.00011527 0.00011518 0.00011457
  0.00011527 0.00011524 0.00011473 0.00011542 0.0001148  0.00011533
  0.00011496 0.00011466 0.00011542 0.00011456 0.00011526 0.00011483
  0.00011474 0.00011479 0.00011463 0.000115   0.00011533 0.00011547
  0.00011532 0.00011499 0.00011504 0.00011461 0.00011525 0.00011483
  0.00011546 0.0001153  0.00011496 0.00011522 0.00011489 0.00011465
  0.00011483 0.00011463 0.0001149  0.00011492 0.0001149  0.00011536
  0.00011458 0.00011519 0.00011475 0.00011461 0.00011469 0.00011487
  0.00011521 0.00011479 0.00011451 0.00011465 0.00011537 0.00011514
  0.00011499 0.00011489 0.00011491 0.00011518 0.00011524 0.00011462
  0.00011546 0.000115   0.00011534 0.00011483 0.00011546 0.00011474
  0.00011447 0.00011507 0.00011527 0.00011521 0.00011536 0.00011469
  0.00011461 0.00011488 0.00011496 0.00011512 0.00011457 0.00011541
  0.00011489 0.0001148  0.00011452 0.00011462 0.00011492 0.00011481
  0.00011547 0.00011511 0.00011482 0.00011535 0.00011541 0.00011538
  0.00011531 0.00011534 0.00011523 0.00011541 0.00011479 0.00011478
  0.00011466 0.00011513]]

Final Loss: 0.0026
Distance Metric: 7.0262
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 131

================================================================================

baselineCNN_sigmoid -> fcn_128_128_relu

Student Model Parameters:
layers.0.weight: [[-0.1016261  -0.0313128  -0.03186654 ... -0.00258262 -0.0122869
   0.00859687]
 [ 0.00094608  0.00142514 -0.01678963 ... -0.00777546  0.01480715
  -0.00769312]
 [-0.00015353 -0.13153918 -0.09554181 ... -0.06083472 -0.00013842
   0.00394388]
 ...
 [-0.06128636  0.00629149  0.06360069 ...  0.00148172  0.00855718
  -0.05134544]
 [ 0.01635898 -0.00372199  0.05248337 ...  0.00368426  0.06583936
  -0.08476549]
 [ 0.00817605 -0.00142869  0.05074586 ...  0.00255137 -0.00712388
   0.01072885]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0.         0.         0.         0.         0.92432106 0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.37178493 0.         0.4836253
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.46760684 0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.37927875 0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.42607367 0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.54405427 0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.        ]]

Final Loss: 0.0109
Distance Metric: 9.3571
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 601

================================================================================

baselineCNN_sigmoid -> fcn_128_128_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.19039516 0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.        ]]

Final Loss: 0.2527
Distance Metric: 6.6114
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 224

================================================================================

baselineCNN_relu -> fcn_128_128_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.00059653 -0.00059669 -0.00059677 ... -0.0005962  -0.00059696
  -0.0005962 ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.2.weight: [[-2.2585795e-04 -2.2627317e-04 -1.0011886e+01 -2.2604832e-04
  -2.2610466e-04 -2.2568002e-04 -2.2564140e-04 -2.2558641e-04
  -2.2563701e-04 -2.2635267e-04 -2.2595744e-04 -2.2616223e-04
  -2.2640821e-04 -2.2560096e-04 -2.2602001e-04 -2.2608379e-04
  -2.2619712e-04 -2.2634135e-04 -2.2625910e-04 -2.2654860e-04
  -2.2604114e-04 -2.2606467e-04 -2.2644761e-04 -2.2620529e-04
  -2.2586633e-04 -2.2635031e-04 -2.2650517e-04 -2.2583958e-04
  -2.2601419e-04 -2.2617495e-04 -2.2619702e-04 -2.2632923e-04
  -2.2650250e-04 -2.2575569e-04 -2.2587916e-04 -2.2561877e-04
  -2.2642493e-04 -2.2580706e-04 -2.2586467e-04 -2.2656159e-04
  -2.2656866e-04 -2.2633214e-04 -2.2560767e-04 -2.2654883e-04
  -2.2605229e-04 -2.2594510e-04 -2.2647773e-04 -2.2634340e-04
  -2.2629336e-04 -2.2632138e-04 -2.2602113e-04 -2.2632803e-04
  -2.2626396e-04 -2.2623627e-04 -2.2605855e-04 -2.2619368e-04
  -2.2655241e-04 -2.2614538e-04 -2.2643586e-04 -2.2579936e-04
  -2.2565659e-04 -2.2611338e-04 -2.2619513e-04 -2.2557977e-04
  -2.2613724e-04 -2.2598151e-04 -2.2629229e-04 -2.2576237e-04
  -2.2566151e-04  6.0567284e+00 -2.2579615e-04 -2.2569110e-04
  -2.2590801e-04 -2.2586803e-04 -2.2654151e-04 -2.2570492e-04
  -2.2588989e-04 -2.2569453e-04 -2.2640430e-04 -2.2572375e-04
  -2.2570220e-04 -2.2624830e-04 -2.2557646e-04 -2.2567983e-04
  -2.2593186e-04 -2.2628404e-04 -2.2602000e-04 -2.2628225e-04
   1.5505120e+01 -2.2595047e-04 -2.2614043e-04 -2.2558878e-04
  -2.2606108e-04 -2.2585201e-04 -2.2592198e-04 -2.2582643e-04
  -2.2649439e-04  1.2825778e+01 -2.2618056e-04 -2.2622086e-04
  -2.2651000e-04 -2.2628655e-04 -2.2623342e-04 -2.2635711e-04
  -2.2609839e-04 -2.2614731e-04 -2.2588369e-04 -2.2639142e-04
  -2.2579278e-04  6.8568673e+00 -2.2590194e-04 -2.2567308e-04
  -2.2608135e-04 -1.6237686e+01 -2.2643898e-04 -2.2628128e-04
  -2.2609561e-04 -2.2599474e-04 -2.2586762e-04 -2.2596544e-04
  -2.2590635e-04 -2.2580703e-04 -2.2592250e-04 -2.2615009e-04
  -2.2610670e-04 -2.2647933e-04 -2.2643725e-04 -2.2568283e-04]]

Final Loss: 3.2733
Distance Metric: 64.8768
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 5478

================================================================================

baselineCNN_relu -> fcn_128_128_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         2.0350254  0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.        -2.3044982  0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.       ]]

Final Loss: 0.0002
Distance Metric: 10.8667
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 1561

================================================================================

baselineCNN_relu -> fcn_128_128_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0.]]

Final Loss: 0.0000
Distance Metric: 1.0042
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 212

================================================================================

baselineCNN_tanh -> fcn_128_128_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.36760426
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.        ]]

Final Loss: 0.0002
Distance Metric: 1.1906
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 631

================================================================================

baselineCNN_tanh -> fcn_128_128_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.        -0.6590256  0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.       ]]

Final Loss: 0.0000
Distance Metric: 0.8828
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 825

================================================================================

baselineCNN_tanh -> fcn_128_128_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[-0.11978796 -0.06276426 -0.0848932  -0.11205308 -0.12229322 -0.06487356
  -0.10638612 -0.06497651 -0.06759822 -0.08328211 -0.1311505  -0.0767244
  -0.11749937 -0.06794623 -0.10856736 -0.12525815 -0.07684781 -0.0749597
  -0.04832436 -0.07198782 -0.07193303 -0.07312517 -0.05162728 -0.06978911
  -0.13593602 -0.06567628 -0.05522489 -0.11091844 -0.0830282  -0.0757038
  -0.05295513 -0.09215192 -0.09036329 -0.09015597 -0.09559344 -0.12501667
  -0.13256751 -0.07218574 -0.06613175 -0.09750386 -0.10521031 -0.09500691
  -0.1203454  -0.06132977 -0.11241527 -0.05442723 -0.12349512 -0.07988581
  -0.09850567 -0.10884462 -0.06758646 -0.06891686 -0.07831698 -0.07299884
  -0.11760813 -0.0656006  -0.08151554 -0.06592093 -0.08316489 -0.06744209
  -0.08754967 -0.07749772 -0.08432908 -0.07087173 -0.11461213 -0.08731963
  -0.05458268 -0.09570622 -0.05664471 -0.11114686 -0.09798161 -0.08259335
  -0.08570099 -0.0621003  -0.05484504 -0.12803446 -0.09319673 -0.12888356
  -0.06868831 -0.09976644 -0.08176938 -0.08476364 -0.07528725 -0.11600165
  -0.1321673  -0.09248177 -0.11273128 -0.14560224 -0.10699872 -0.11551987
  -0.07276499 -0.09697922 -0.11367078 -0.13493024 -0.09960075 -0.07541142
  -0.1328593  -0.0776267  -0.11281176 -0.05663774 -0.07133683 -0.09392371
  -0.07915118 -0.05506986 -0.1160538  -0.12707672 -0.0986315  -0.05918327
  -0.0759471  -0.06461754 -0.07806531 -0.12972079 -0.05875307 -0.09689333
  -0.0894126  -0.08532777 -0.07295482 -0.08617745 -0.06092915 -0.07400256
  -0.13359545 -0.1045913  -0.0648476  -0.07525034 -0.12139735 -0.11012112
  -0.07915768 -0.12407406]]

Final Loss: 0.0007
Distance Metric: 1.7751
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 281

================================================================================