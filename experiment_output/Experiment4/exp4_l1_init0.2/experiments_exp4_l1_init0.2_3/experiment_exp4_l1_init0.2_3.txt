Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[ 2.59 -2.83  0.87]]]
layers.1.weight: [[[-1.38  1.29]]]
layers.2.weight: [[[ 0.86 -0.84]]]

================================================================================

baselineCNN_sigmoid -> fcn_128_128_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0.0003991  0.00039878 0.00039884 0.00039921 0.00039901 0.0003988
  0.00039883 0.00039906 0.00039963 0.000399   0.00039931 0.0003995
  0.00039895 0.00039902 0.00039928 0.00039951 0.00039919 0.00039921
  0.00039886 0.00039951 0.00039891 0.00039966 0.00039958 0.00039954
  0.00039879 0.0003992  0.00039918 0.00039898 0.00039926 0.00039932
  0.00039923 0.00039914 0.00039918 0.00039947 0.00039972 0.00039973
  0.00039944 0.00039967 0.00039947 0.00039884 0.00039876 0.00039911
  0.00039955 0.00039885 0.00039894 0.00039958 0.0003994  0.00039882
  0.00039958 0.00039905 0.00039954 0.00039912 0.00039912 0.00039919
  0.00039942 0.00039882 0.00039959 0.00039926 0.00039898 0.00039959
  0.00039874 0.00039913 0.00039918 0.00039964 0.000399   0.00039874
  0.00039875 0.00039895 0.00039958 0.00039889 0.00039887 0.00039908
  0.00039876 0.00039937 0.00039949 0.00039923 0.00039912 0.00039885
  0.00039949 0.00039927 0.00039916 0.00039917 0.00039921 0.00039952
  0.00039927 0.00039893 0.00039879 0.00039972 0.00039915 0.0003991
  0.00039894 0.00039941 0.00039926 0.00039901 0.00039912 0.00039967
  0.00039894 0.00039923 0.00039962 0.00039876 0.00039915 0.00039904
  0.00039909 0.00039914 0.00039895 0.00039886 0.00039943 0.00039911
  0.00039926 0.00039923 0.00039901 0.00039971 0.00039902 0.0003996
  0.0003989  0.00039965 0.00039913 0.00039968 0.00039912 0.00039973
  0.00039912 0.00039949 0.00039939 0.0003993  0.00039914 0.0003989
  0.00039935 0.00039914]]

Final Loss: 0.0026
Distance Metric: 7.0294
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 343

================================================================================

baselineCNN_sigmoid -> fcn_128_128_relu

Student Model Parameters:
layers.0.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.00477879  0.03653933  0.03160879 ...  0.00050078 -0.01113076
  -0.01049046]
 [-0.00499831  0.00048822 -0.01169364 ... -0.0434612  -0.05338563
  -0.04490067]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.00249599  0.00799832  0.06883182 ...  0.05596555 -0.01255275
   0.00410982]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.46840477 0.
  0.         0.37950158 0.         0.         0.         0.
  0.         0.         0.14289667 0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.5327939  0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.9124308  0.
  0.         0.         0.         0.         0.49339285 0.
  0.3411966  0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.        ]]

Final Loss: 0.0108
Distance Metric: 9.3172
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 494

================================================================================

baselineCNN_sigmoid -> fcn_128_128_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.21729632]]

Final Loss: 0.2527
Distance Metric: 6.6615
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 209

================================================================================

baselineCNN_relu -> fcn_128_128_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.05379599  0.05419325 -0.02195352 ...  0.77232176 -0.869966
   0.27016148]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[  0.          0.          0.         18.989016    0.          0.
    1.8489903   0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.         -7.3295617   0.          0.          0.          0.
  -13.657679    0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.         -2.1729422   0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          3.2350986   0.         10.984835    0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.       ]]

Final Loss: 3.2739
Distance Metric: 63.2062
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 4792

================================================================================

baselineCNN_relu -> fcn_128_128_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.        0.        0.        0.        0.        0.        0.
   0.        0.        0.        0.        0.        0.        0.
   0.        0.        0.        0.        0.        0.        0.
   0.        0.        0.        0.        0.        0.        0.
   0.        0.        0.        0.        0.        0.       -2.312783
   0.        0.        0.        0.        0.        0.        0.
   0.        0.        0.        0.        0.        0.        0.
   0.        0.        0.        0.        0.        0.        2.093561
   0.        0.        0.        0.        0.        0.        0.
   0.        0.        0.        0.        0.        0.        0.
   0.        0.        0.        0.        0.        0.        0.
   0.        0.        0.        0.        0.        0.        0.
   0.        0.        0.        0.        0.        0.        0.
   0.        0.        0.        0.        0.        0.        0.
   0.        0.        0.        0.        0.        0.        0.
   0.        0.        0.        0.        0.        0.        0.
   0.        0.        0.        0.        0.        0.        0.
   0.        0.        0.        0.        0.        0.        0.
   0.        0.      ]]

Final Loss: 0.0002
Distance Metric: 10.9356
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 1302

================================================================================

baselineCNN_relu -> fcn_128_128_tanh

Student Model Parameters:
layers.0.weight: [[ 0.04546503 -0.00999248  0.26079285 ... -0.07697672 -0.25672406
  -0.25877887]
 [ 0.49518394 -0.25705346 -0.02020599 ...  0.0900608  -0.1421941
   0.2175221 ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-1.5271494   1.6461127  -0.539541   ... -0.8248104   0.84351313
  -0.30294558]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.50245696  0.          0.          0.
   0.          0.          0.          0.          0.          0.
  -1.8263241   0.          0.          0.          0.          0.
   0.          0.         -0.67004585  0.         -0.19807711  0.
   0.          0.          0.         -1.7245957   0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
  -0.29095954  0.          0.          0.          0.          0.
   0.         -0.379107    0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.40685278  0.          0.          0.          0.
   0.          0.        ]]

Final Loss: 3.5154
Distance Metric: 36.3590
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 532

================================================================================

baselineCNN_tanh -> fcn_128_128_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[-0.06275779 -0.09008683 -0.06545643 -0.06844747 -0.08916184 -0.0628375
  -0.08621642 -0.10124155 -0.11471239 -0.08537868 -0.05264504 -0.10809332
  -0.09289171 -0.09977396 -0.05772396 -0.10835563 -0.09433655 -0.0698956
  -0.08133987 -0.09454752 -0.13177595 -0.04464633 -0.06765385 -0.09975889
  -0.08776856 -0.04929724 -0.09037481 -0.0691551  -0.07001808 -0.0865152
  -0.11032458 -0.14179082 -0.13341594 -0.11621332 -0.05299965 -0.05313151
  -0.06401286 -0.09381305 -0.04876252 -0.0494561  -0.08841731 -0.10027839
  -0.10923134 -0.13744399 -0.05083301 -0.04380805 -0.05110416 -0.09954513
  -0.12321156 -0.08797925 -0.11481382 -0.10602444 -0.07850764 -0.12588285
  -0.11613034 -0.11422801 -0.07511214 -0.06439912 -0.06450374 -0.05927997
  -0.08116917 -0.1086425  -0.08028661 -0.06494755 -0.1460585  -0.04997353
  -0.10521549 -0.1009602  -0.09112626 -0.05417011 -0.10101113 -0.12962337
  -0.12348208 -0.05368796 -0.06309386 -0.07636413 -0.05448975 -0.10750213
  -0.07984252 -0.07029784 -0.0497142  -0.13646588 -0.06796975 -0.09980377
  -0.11824057 -0.12305771 -0.08822825 -0.09651267 -0.09090591 -0.0589094
  -0.11664626 -0.10889662 -0.12750499 -0.11545148 -0.06055472 -0.07494843
  -0.12762998 -0.05313544 -0.11126145 -0.12423203 -0.05764353 -0.14458425
  -0.04214936 -0.07313813 -0.11339363 -0.11866035 -0.1263212  -0.10268559
  -0.09971616 -0.092191   -0.11137888 -0.05729282 -0.08812468 -0.13893673
  -0.1150711  -0.1215191  -0.04455709 -0.12266271 -0.06630591 -0.07913639
  -0.04716041 -0.06339425 -0.069571   -0.07725886 -0.08777682 -0.10490561
  -0.05360087 -0.10708769]]

Final Loss: 0.3667
Distance Metric: 8.0019
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 179

================================================================================

baselineCNN_tanh -> fcn_128_128_relu

Student Model Parameters:
layers.0.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.23309235  0.27080584 -0.10954072 ...  0.00083398 -0.00949899
   0.00573997]
 ...
 [-0.02987003  0.02254364 -0.004916   ...  0.00568799  0.01573016
   0.00461388]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.          0.          0.          0.          0.
   0.45005015  0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.51970536  0.          0.          0.         -0.31666693
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.36667293  0.
   0.          0.         -0.80766875  0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.         -1.0822154   0.          0.          0.          0.
   0.          0.4388121   0.          0.          0.          0.
   0.          0.          0.          0.          0.         -0.8546576
   0.          0.          0.          0.          0.          0.
   0.32830873  0.          0.         -0.54202265  0.          0.
   0.          0.          0.          0.          0.          0.
   0.23874795  0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.         -1.5411074   0.
  -1.2041528   0.          0.          0.          0.3116169   0.
   0.          0.          0.          0.          0.          0.4943264
   0.          0.21192023  0.          0.4301697   0.          0.
   0.          0.          0.          0.          0.32867432  0.
   0.          0.        ]]

Final Loss: 0.1929
Distance Metric: 13.7366
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 717

================================================================================

baselineCNN_tanh -> fcn_128_128_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.8416851  0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.86166894 0.
  0.         0.        ]]

Final Loss: 0.0003
Distance Metric: 8.6714
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 3
stopped after epoch: 392

================================================================================

