Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[ 2.59 -2.83  0.87]]]
layers.1.weight: [[[-1.38  1.29]]]
layers.2.weight: [[[ 0.86 -0.84]]]

================================================================================

nonoverlappingCNN_relu -> fcnn_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[  0.          0.          0.          0.          0.          0.
   -9.298715    0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
   11.043285    0.          0.          0.         13.8419075   0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          7.3149724   0.
    0.          7.235157    0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.        -15.059572    0.          0.          0.
    0.          0.          0.          0.         -6.6816287   0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.          0.          0.          0.          0.
    0.          0.       ]]

Final Loss: 3.2624
Distance Metric: 63.1970
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 42
stopped after epoch: 2793

================================================================================

nonoverlappingCNN_relu -> fcnn_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.         0.         0.         0.         0.         0.
   0.         0.         0.        -1.1461045  0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         1.2474339  0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.       ]]

Final Loss: 0.0003
Distance Metric: 8.4267
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 42
stopped after epoch: 629

================================================================================

nonoverlappingCNN_relu -> fcnn_tanh

Student Model Parameters:
layers.0.weight: [[ 0.05810303 -0.0278911   0.01124903 ...  0.08864924 -0.10240776
   0.07536093]
 [ 0.12183351  0.0742934  -0.22334379 ... -2.1450684   2.5105078
  -0.80974984]
 [ 0.0821839  -0.11816421  0.01137427 ...  0.01208013 -0.00286908
   0.0025128 ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.         -0.31931227  0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.         -0.8515578   0.35559392  0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.8485622   0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
  -1.4588423   0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          1.504184    0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.        ]]

Final Loss: 3.5030
Distance Metric: 49.6536
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 42
stopped after epoch: 606

================================================================================

nonoverlappingCNN_tanh -> fcnn_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[-0.09861552 -0.07185727 -0.07821199 -0.10315466 -0.0841818  -0.05055682
  -0.12745875 -0.11132481 -0.0693135  -0.09741294 -0.07342251 -0.13088357
  -0.06755092 -0.08740511 -0.11167823 -0.06799816 -0.13095891 -0.11558656
  -0.08256865 -0.06862727 -0.089875   -0.11529393 -0.05466069 -0.12213365
  -0.06030842 -0.04953332 -0.08858379 -0.06015408 -0.08077454 -0.09565111
  -0.06299783 -0.07154793 -0.06997077 -0.07306863 -0.06228681 -0.07214994
  -0.11444302 -0.05406202 -0.10794818 -0.10984907 -0.11167861 -0.06691293
  -0.11089814 -0.09020193 -0.1146007  -0.07769541 -0.10476847 -0.05229548
  -0.09107668 -0.09403311 -0.09649206 -0.10265464 -0.04884227 -0.06109029
  -0.13145688 -0.08014151 -0.10497691 -0.05092404 -0.11890323 -0.13007733
  -0.0808301  -0.05072387 -0.08957478 -0.08891074 -0.03908901 -0.12635732
  -0.08478717 -0.13204569 -0.04913775 -0.07278474 -0.11742879 -0.04573296
  -0.07122626 -0.12089559 -0.06942778 -0.04457247 -0.07723292 -0.0497481
  -0.12154276 -0.07859068 -0.07577708 -0.07525777 -0.11802095 -0.04642015
  -0.12103364 -0.08318473 -0.12286551 -0.072272   -0.13041395 -0.10041369
  -0.09174649 -0.0698026  -0.05472015 -0.08884359 -0.07028939 -0.11170582
  -0.0878101  -0.07026259 -0.06440073 -0.08822541 -0.10926409 -0.11971619
  -0.10032075 -0.1044376  -0.08466975 -0.07496165 -0.07701775 -0.11742574
  -0.09326874 -0.11836132 -0.04790563 -0.09969559 -0.08803134 -0.13156825
  -0.04884683 -0.0910727  -0.07386854 -0.05039205 -0.05351984 -0.1210625
  -0.12591963 -0.07955003 -0.10019922 -0.0690543  -0.10489497 -0.12295932
  -0.08847783 -0.11327667]]

Final Loss: 0.3659
Distance Metric: 7.9920
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 42
stopped after epoch: 199

================================================================================

nonoverlappingCNN_tanh -> fcnn_relu

Student Model Parameters:
layers.0.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.03814606 -0.0192057   0.01184825 ...  0.01006617  0.00274236
   0.00751915]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.32466742 ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 ...
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]]
layers.2.weight: [[ 0.          0.3559455   0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.253573   -0.40814677  0.          0.18642224  0.          0.
   0.          0.         -0.419455    0.          0.20324206  0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.33855495
   0.13452356  0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.         -0.9999546   0.2323646   0.          0.          0.
   0.          0.          0.         -0.9677148   0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
  -0.2170541   0.          0.          0.          0.          0.
   0.3427069   0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.34075585  0.          0.          0.          0.          0.
  -0.42235392  0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.        ]]

Final Loss: 0.1925
Distance Metric: 13.9214
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 42
stopped after epoch: 724

================================================================================

nonoverlappingCNN_tanh -> fcnn_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.         -0.86166775  0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.8418064
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.        ]]

Final Loss: 0.0003
Distance Metric: 8.6706
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 42
stopped after epoch: 278

================================================================================

nonoverlappingCNN_sigmoid -> fcnn_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0.00062972 0.00062973 0.00062952 0.00062837 0.00062931 0.00062846
  0.00062861 0.00062873 0.0006296  0.00062826 0.00062896 0.00062936
  0.00062946 0.0006298  0.00062876 0.0006299  0.00062953 0.00062993
  0.00062874 0.00062947 0.00062983 0.00062832 0.00062851 0.0006288
  0.0006286  0.00062873 0.00062921 0.00062976 0.00062917 0.00062902
  0.00062913 0.00063008 0.00062863 0.00062952 0.00062899 0.00062884
  0.0006288  0.00062814 0.00062923 0.00062943 0.00062852 0.00062933
  0.00062879 0.00062978 0.00062873 0.00062863 0.00062954 0.00062881
  0.00062909 0.00062829 0.00062913 0.00062938 0.00062835 0.000629
  0.00062937 0.00062949 0.00062986 0.00062899 0.00062863 0.00062844
  0.00062983 0.00062918 0.00062864 0.00062971 0.00062925 0.00062945
  0.00063009 0.00062861 0.00062816 0.00062905 0.00062828 0.00062948
  0.00062938 0.00062839 0.00062994 0.00062975 0.00062958 0.00062922
  0.00062984 0.00063    0.00062996 0.00062974 0.00062919 0.0006296
  0.00062971 0.00062948 0.00062898 0.00062954 0.00062841 0.00062944
  0.0006286  0.00062842 0.00063003 0.00062816 0.00062839 0.00062887
  0.00062988 0.00062924 0.00062893 0.00062884 0.00062903 0.00062996
  0.00062869 0.00063005 0.00062999 0.00062942 0.00062895 0.00062995
  0.00063003 0.00062873 0.00062852 0.00062869 0.00062895 0.00062814
  0.00063005 0.00062889 0.00062899 0.00062869 0.00062923 0.00062992
  0.00062856 0.00062837 0.0006293  0.00062841 0.00062813 0.00062865
  0.00062817 0.00062827]]

Final Loss: 0.0026
Distance Metric: 7.0320
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 42
stopped after epoch: 226

================================================================================

nonoverlappingCNN_sigmoid -> fcnn_relu

Student Model Parameters:
layers.0.weight: [[ 0.00181095  0.10121799 -0.01524505 ...  0.0080814   0.04858901
  -0.00172408]
 [ 0.00510174  0.12522464  0.102731   ... -0.12272308 -0.06799076
  -0.01007882]
 [-0.03073454  0.04866477 -0.00156232 ... -0.03636682 -0.029592
  -0.00988039]
 ...
 [-0.00213849 -0.09016412 -0.01970987 ... -0.07533448 -0.03615428
   0.0247077 ]
 [-0.00324282  0.11481203  0.03156525 ...  0.00257993 -0.00161009
   0.        ]
 [ 0.01238526  0.1496049   0.03788788 ...  0.01238676  0.
  -0.02463609]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0.         0.         0.         0.         0.         0.
  0.         0.4472742  0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.74195904 0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.41227075 0.4454376
  0.         0.         0.24738915 0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.40175784 0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.        ]]

Final Loss: 0.0110
Distance Metric: 9.4308
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 42
stopped after epoch: 277

================================================================================

nonoverlappingCNN_sigmoid -> fcnn_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.23559633 0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.        ]]

Final Loss: 0.2528
Distance Metric: 6.5094
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 100000
init: 0.2
seed: 42
stopped after epoch: 223

================================================================================

