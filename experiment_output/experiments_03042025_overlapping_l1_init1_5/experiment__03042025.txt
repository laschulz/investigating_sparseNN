Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.21852174  0.7435498   0.7299582 ]]]
layers.1.weight: [[[1.6735988 0.8192109]]]
layers.2.weight: [[[-1.7170275  1.0277497]]]

================================================================================

nonoverlapping_CNN_all_tanh -> fcnn_decreasing_all_tanh

Student Model Parameters:
layers.0.weight: [[-0.07731161  0.06744355 -0.12823988 ...  0.12241887 -0.03861859
   0.16345087]
 [-0.17807253 -0.08914657  0.03430578 ... -0.12420017  0.03836467
  -0.08446667]
 [ 0.07383665 -0.2669791  -0.23631406 ... -0.01606055  0.01071518
  -0.00271346]
 ...
 [ 0.02527411  0.06824714 -0.14404802 ...  0.09389526 -0.09337553
   0.05284406]
 [-0.16314727 -0.19628079  0.02930959 ... -0.04174785 -0.16317996
  -0.02980014]
 [ 0.00286449  0.04852146 -0.00706965 ... -0.10445128  0.05889481
  -0.10740827]]
layers.1.weight: [[ 0.00359575 -0.06825598 -0.20695281 ... -0.10435092  0.12696315
  -0.08972146]
 [ 0.07001277 -0.1038621  -0.13823277 ... -0.01028139  0.16316539
   0.15858853]
 [-0.07533398 -0.00477433 -0.05729278 ... -0.10821792 -0.02357456
  -0.10691871]
 ...
 [-0.23916161 -0.07474871  0.11433333 ... -0.20841917 -0.05973298
   0.19092757]
 [-0.21782836 -0.07963172  0.0880823  ... -0.11087655 -0.13930584
   0.17714107]
 [-0.18250102 -0.17783923 -0.06651602 ...  0.02680186  0.17703104
   0.13037828]]
layers.2.weight: [[-4.96099055e-01  2.21202839e-02  1.42675161e-01 -1.24157500e-03
   7.21871376e-01  1.28071755e-01 -4.86309528e-02 -4.93833516e-03
   1.44417565e-02 -4.08625245e-01  4.43035038e-03 -6.24468438e-02
   1.46291684e-03  3.17145675e-01  6.09970279e-03  2.93701096e-03
   5.05227502e-03 -8.06547329e-03 -9.90925431e-02  2.96978243e-02
  -1.96145289e-02 -8.91869795e-03  7.21247029e-03 -2.14060210e-03
   9.85372579e-04 -1.26763177e-03  2.50785857e-01 -8.83079693e-03
  -4.04770020e-04  1.81546792e-01  1.62698538e-03  5.12783676e-02]]

Final Loss: 0.0122
Distance Metric: 21.5625
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.01
data size: 5120
init: 1
seed: 5

================================================================================

