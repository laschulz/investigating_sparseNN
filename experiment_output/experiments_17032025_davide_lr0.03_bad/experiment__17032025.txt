Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[ 2.59 -2.83  0.87]]]
layers.1.weight: [[[-1.38  1.29]]]
layers.2.weight: [[[ 0.86 -0.84]]]

================================================================================

nonoverlappingCNN_relu -> fcnn_relu

Student Model Parameters:
layers.0.weight: [[-0.09204303  0.28404155 -0.17807072 ...  0.02204058 -0.13066116
   0.14179605]
 [-0.26466277 -0.27754533  0.35833707 ...  0.05165897  0.24707183
  -0.5341603 ]
 [ 0.02374183  0.0735347   0.04645017 ...  0.25586125  0.9658492
   0.04117629]
 ...
 [ 0.16625538 -0.1024358   0.81241226 ...  0.713649    0.06919936
  -0.85874605]
 [-0.61375034 -0.8485279   0.3559087  ... -0.06922758  0.10865215
  -0.31055373]
 [ 0.05075344  0.2027186  -0.64674675 ... -0.5169817  -0.41406444
   0.68744856]]
layers.1.weight: [[ 0.         -0.01761244 -0.11131712 ...  0.0793617  -0.09070477
   0.02857819]
 [-0.0505178   0.0562004   0.01374557 ...  0.03773019 -0.01438712
   0.00306455]
 [-0.00630488  0.         -0.18714324 ... -0.03003659  0.00517002
  -0.07656965]
 ...
 [ 0.13429505  0.13228157  0.29393396 ... -0.01429666  0.12746982
   0.17705537]
 [ 0.0777951   0.12038918  0.01332566 ...  0.04529557 -0.04443839
  -0.03538754]
 [ 0.          0.03653391 -0.08625523 ...  0.          0.0122551
   0.05349983]]
layers.2.weight: [[-2.0974133  -0.20763609  0.1629655  -0.47562215 -0.30922922 -1.8643932
  -0.95337576 -2.3254576  -0.73536384  0.21246323 -0.88563496 -0.8739329
  -0.5103624  -0.38230258 -1.5640719  -0.48330665 -0.5251739  -3.6617568
  -2.1620836  -2.2063832   0.36545253  0.01127748 -0.84907705 -0.175005
   0.14368455 -1.1771121  -0.06335023 -0.46114853 -0.3871136  -0.9233085
  -0.1394722  -0.3514489 ]]

Final Loss: 5.0593
Distance Metric: 56.4549
L1 norm: 1e-05
L2 norm: 0
Batch size: 32
Clipping: 0

================================================================================

nonoverlappingCNN_tanh -> fcnn_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.46059346  0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.37505662  0.         -0.39726543
   0.          0.4634143 ]]

Final Loss: 0.0004
Distance Metric: 11.5205
L1 norm: 1e-05
L2 norm: 0
Batch size: 32
Clipping: 0

================================================================================

nonoverlappingCNN_sigmoid -> fcnn_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[-0.00305359 -0.00305288 -0.00305187 -0.47318083 -0.00305601 -0.03925394
  -0.00305039 -0.00305186 -0.00305517 -0.00305556 -0.00305071 -0.00305543
  -0.03385256 -0.00305559 -0.00305597 -0.02998282 -0.06958012 -0.00305557
  -0.00305513 -0.0030564  -0.0030547  -0.4242287  -0.00305412 -0.00305439
   2.0188708  -0.0030566  -0.0085537  -0.00305579 -0.00305596 -0.866502
  -0.00305332 -0.00305231]]

Final Loss: 0.0003
Distance Metric: 10.3027
L1 norm: 1e-05
L2 norm: 0
Batch size: 32
Clipping: 0

================================================================================

