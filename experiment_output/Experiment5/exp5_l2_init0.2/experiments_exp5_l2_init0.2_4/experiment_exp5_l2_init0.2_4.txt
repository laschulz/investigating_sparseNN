Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.78 -0.12  0.7 ]]

 [[-1.16  0.47  0.05]]

 [[-0.73  1.96 -1.01]]

 [[-0.32  0.21  0.63]]]
layers.1.weight: [[[ 0.    0.04]
  [ 0.68  0.34]
  [ 0.54 -0.22]
  [-0.14 -0.33]]

 [[-0.14  1.59]
  [ 1.48 -0.52]
  [-1.26  0.3 ]
  [-0.4  -1.09]]

 [[-0.71  0.44]
  [-0.02 -0.14]
  [ 0.37 -0.7 ]
  [-0.83 -0.38]]

 [[ 0.89 -0.48]
  [-0.27 -0.81]
  [ 1.76 -0.41]
  [ 0.15  0.49]]]
layers.2.weight: [[[-0.54  0.16]
  [-0.74 -0.46]
  [ 0.08  0.18]
  [-0.22  0.81]]]

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.02913923 -0.00178981 -0.00392594 ...  0.02325997 -0.01202552
   0.00369892]
 [ 0.01135689 -0.00068883 -0.00153379 ...  0.00907848 -0.00468452
   0.00144222]
 [-0.00029899  0.          0.         ... -0.00023946  0.00012206
   0.        ]
 ...
 [ 0.04401384 -0.0027469  -0.00592071 ...  0.03505908 -0.01816239
   0.00558087]
 [ 0.04268919 -0.0026627  -0.00574407 ...  0.03401099 -0.01761464
   0.00541252]
 [-0.02719727  0.00166873  0.00366445 ... -0.02171597  0.01122147
  -0.00345327]]
layers.1.weight: [[ 0.00368698  0.00142911  0.         ...  0.00557106  0.00540305
  -0.00347467]
 [ 0.00339646  0.00131404  0.         ...  0.00513011  0.0049753
  -0.00320575]
 [-0.00100954 -0.00042211  0.         ... -0.00149969 -0.00145682
   0.00085237]
 ...
 [-0.0026637  -0.00106428  0.         ... -0.00399687 -0.00387683
   0.00240535]
 [-0.00038351 -0.0001745   0.         ... -0.0005535  -0.00054012
   0.00027191]
 [ 0.00785725  0.00305537  0.         ...  0.01185771  0.01150342
  -0.00736853]]
layers.2.weight: [[ 0.13785127  0.12703581 -0.03546006 -0.18355432 -0.40208444  0.09623198
   0.0101599  -0.05420552 -0.19019155  0.01173294 -0.1727293   0.19548535
   0.09476269  0.5292325   0.28531224 -0.43172297  0.29503304  0.35753265
   0.31753102 -0.64738584 -0.29048818 -0.07906423 -0.5417239  -0.33463645
   0.07135658 -0.04882541  0.2173043  -0.14609477 -0.36609173 -0.09704408
  -0.01228401  0.29306424]]

Final Loss: 0.0001
Distance Metric: 8.3011
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 1016

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.09422292  0.00822694  0.02409507 ...  0.00371199  0.02163534
   0.02542619]
 [-0.05272859  0.07225047 -0.01729584 ...  0.12679912  0.05808754
  -0.014247  ]
 [-0.05889168  0.07577724  0.04318038 ... -0.0529986  -0.03082212
  -0.01606978]
 ...
 [ 0.0333054  -0.01985675 -0.09357228 ... -0.00520154 -0.04786035
   0.01508027]
 [ 0.03255203  0.01541584 -0.1013631  ...  0.02399094  0.00066619
  -0.06940052]
 [-0.04424067 -0.02356389 -0.04442747 ... -0.03071783  0.15613778
   0.07430969]]
layers.1.weight: [[-0.05214947 -0.02579683  0.00547423 ...  0.00201702  0.0184965
  -0.07108893]
 [-0.00457971 -0.01280219 -0.01270451 ...  0.03982709  0.05839211
  -0.03222683]
 [ 0.04697623 -0.06346986 -0.02131453 ... -0.03250424 -0.04688388
  -0.03503963]
 ...
 [ 0.00973117  0.03648512 -0.00663422 ...  0.00662988 -0.00838641
   0.03382836]
 [-0.00387313  0.02072726 -0.01580015 ...  0.00224356 -0.07808536
   0.01316969]
 [ 0.02449342  0.0684841   0.01773726 ...  0.04079638  0.05281617
   0.02260028]]
layers.2.weight: [[-0.41052932  0.27189007 -0.40951958  0.33408222 -0.4354656  -0.40658483
   0.29219732  0.2991581  -0.2974639   0.2433346  -0.35866222  0.23216486
  -0.41956735 -0.37021744  0.19348074 -0.4113039  -0.4105605   0.21233574
  -0.4173422   0.2007867   0.27972367 -0.33425295 -0.40402567  0.14785664
   0.25228342 -0.28490376  0.08630368  0.2615863  -0.4328499  -0.30126032
  -0.38684657 -0.46899045]]

Final Loss: 0.0066
Distance Metric: 13.8755
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 895

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.00142679 -0.00032199 -0.00238339 ... -0.0042741   0.00087949
   0.00292115]
 [ 0.00032056 -0.00027634  0.0002559  ...  0.00036538 -0.00018178
  -0.00066075]
 [ 0.00307568  0.00049642  0.0049799  ...  0.00886792 -0.00186044
  -0.00624513]
 ...
 [-0.01639483  0.00112539 -0.02416041 ... -0.04160958  0.00879922
   0.0315791 ]
 [ 0.00788128  0.00029213  0.01197783 ...  0.02102381 -0.0045989
  -0.01577877]
 [ 0.00119029  0.00019579  0.00191088 ...  0.00338292 -0.00072437
  -0.00240587]]
layers.1.weight: [[-0.00074638 -0.0007203  -0.00034597 ...  0.00258403 -0.00240908
  -0.00086425]
 [ 0.00011562 -0.00062975 -0.0010231  ... -0.00128911 -0.00141765
   0.        ]
 [-0.00067774  0.00144389 -0.00020839 ... -0.00247987  0.0010373
   0.00084167]
 ...
 [-0.00089701 -0.00136338 -0.00090329 ... -0.00199997  0.00130277
   0.        ]
 [-0.00045381  0.00094799 -0.00100161 ...  0.00140788 -0.00045111
  -0.00066396]
 [ 0.00090148  0.00145405 -0.00029471 ... -0.00205993 -0.00019459
  -0.00105484]]
layers.2.weight: [[-0.01782128 -0.00084024  0.00838997  0.0145292  -0.00664413  0.00914527
  -0.01741039 -0.00678308  0.00324092 -0.0108626   0.00408027  0.00824973
  -0.02748229 -0.0017739   0.00822692 -0.20640801  0.01309355  0.00226121
  -0.00745893  0.01396534  0.01825065 -0.00239907  0.00224595  0.0108298
  -0.00818369  0.00142356 -0.01131294 -0.00678771 -0.00044748  0.00614466
  -0.00238194  0.01184937]]

Final Loss: 0.1671
Distance Metric: 7.4929
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 377

================================================================================

multiChannelCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.01543934  0.07858891 -0.02844694 ...  0.09512392  0.16006142
  -0.15666094]
 [-0.22561377  0.1621512  -0.01257136 ...  0.00552887 -0.08665648
   0.07957298]
 [-0.00706099  0.07258258 -0.01851104 ...  0.10383027  0.14921229
  -0.15354629]
 ...
 [-0.08615726 -0.1875245   0.06446357 ... -0.12468302  0.06299891
  -0.03059558]
 [-0.16094658 -0.08540218  0.07203778 ... -0.00308647  0.00701923
  -0.02511099]
 [-0.16109738 -0.06570771  0.06714021 ...  0.01145237 -0.00432338
  -0.02022594]]
layers.1.weight: [[ 0.01314021  0.00381036  0.0131489  ...  0.03623761  0.03112832
   0.02898095]
 [ 0.12094829 -0.11242036  0.1082979  ...  0.08619165 -0.01176665
  -0.02681361]
 [-0.00215341  0.00067379 -0.00181333 ... -0.00211078 -0.00124409
  -0.0009349 ]
 ...
 [-0.00302954  0.00179894 -0.00245499 ... -0.00291217 -0.00145797
  -0.0009363 ]
 [ 0.0070581   0.05847393  0.00944501 ... -0.02885726 -0.0290332
  -0.02191205]
 [-0.00216535  0.00070401 -0.00182032 ... -0.00212131 -0.00124236
  -0.00092868]]
layers.2.weight: [[-2.2291129  -3.9412456  -0.14512037 -0.20854506  2.5715628  -0.17574498
   1.6952028  -0.1924149  -4.787325    1.8814126  -0.3331917   3.2795753
  -3.077002    3.0860832   3.021112   -0.30321035 -0.4355647  -0.11146212
  -0.17749105  4.0045934  -0.13984364 -0.17839311 -2.2012296   2.8396857
  -0.16237134 -5.030969    1.7360587  -0.17698906  4.0158057  -0.23527479
   2.6861985  -0.14706959]]

Final Loss: 2.1538
Distance Metric: 41.1417
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 4929

================================================================================

multiChannelCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-3.6842693e-04 -3.2785628e-04  0.0000000e+00 ...  3.2355750e-04
   2.6776214e-04 -1.6069268e-04]
 [-1.5108588e-01  6.1230812e-02  6.4252396e-03 ...  0.0000000e+00
  -3.0740554e-04  1.1787888e-04]
 [-1.7230573e-01  6.9872677e-02  7.3500671e-03 ...  1.2174990e-04
   0.0000000e+00 -1.7616079e-04]
 ...
 [-6.0802145e-04  8.2711800e-04  8.3271461e-04 ...  3.4577122e-03
   3.2109253e-03 -3.1713909e-03]
 [ 1.8524379e-04  0.0000000e+00  1.3229116e-04 ...  0.0000000e+00
  -2.4739027e-04  2.7606223e-04]
 [ 2.4808291e-04  4.9449963e-04 -2.5463538e-04 ...  2.8300888e-04
   2.7731357e-03 -2.3981561e-03]]
layers.1.weight: [[ 0.0086311  -0.00284559 -0.00328373 ... -0.00022296  0.00758535
  -0.00019723]
 [ 0.00161174  0.          0.         ...  0.          0.00143456
   0.        ]
 [-0.02937077 -0.0001617  -0.00017492 ...  0.00095877 -0.02586634
   0.00065088]
 ...
 [-0.00038087 -0.00212249 -0.00234637 ...  0.00024066 -0.00029615
   0.00017938]
 [ 0.          0.00028879  0.00034013 ...  0.          0.
   0.        ]
 [ 0.00023847 -0.00654029 -0.00735839 ...  0.00245573  0.00012346
   0.00077779]]
layers.2.weight: [[ 0.07142864  0.03781708 -0.30305532 -1.5236609  -0.5149023   0.31009224
  -0.8002974  -0.0650263   0.28818431 -1.3058083   0.11947142  0.06700402
   0.69310015  0.2850942   0.03491073 -0.6195727  -0.05403043 -0.0724839
   0.2717801  -0.08680799 -0.7799198  -0.18431297  0.29836476  0.5561391
   1.5706323  -0.47580522 -0.2517509  -0.01393786 -0.02966198 -0.02692321
  -0.02174051 -0.52398103]]

Final Loss: 0.0003
Distance Metric: 13.0576
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 842

================================================================================

multiChannelCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 2.7874954e-02 -1.7734401e-02  1.4014831e-02 ...  2.1276407e-02
  -7.0157689e-03 -1.9077809e-03]
 [ 3.1122532e-01 -1.5324098e-01 -1.1719443e-02 ...  3.8007048e-01
  -1.5445983e-01  7.5232238e-02]
 [ 2.4463648e-02 -1.1792589e-02  2.0556593e-02 ...  2.1434285e-02
   3.8924075e-03 -1.0876549e-02]
 ...
 [-4.0299004e-01  5.5074447e-01 -2.3939422e-01 ...  9.9968627e-02
   3.1323712e-02 -1.4290471e-01]
 [ 4.4396460e-02 -1.3187631e-02  3.4909174e-02 ...  5.4224994e-02
  -6.0831495e-03 -5.0100411e-04]
 [ 1.9268753e-02 -1.3922314e-02  2.4088677e-02 ...  2.3156539e-02
  -7.5131482e-03 -1.5742371e-02]]
layers.1.weight: [[-0.00136249 -0.04364379 -0.00060619 ...  0.00933418  0.0012542
   0.00069581]
 [ 0.01825378 -0.3797843   0.0211446  ...  0.02058804  0.00418898
   0.02156644]
 [ 0.01015595 -0.48824278  0.02070604 ...  0.3803698   0.02858809
   0.02881468]
 ...
 [-0.00137842 -0.04384383 -0.00061588 ...  0.0094274   0.00125271
   0.00069789]
 [ 0.00140491  0.04419641  0.00063432 ... -0.00959448 -0.00124867
  -0.00069637]
 [ 0.01847173 -0.10385933  0.02575783 ... -0.21185619  0.02019263
   0.00377698]]
layers.2.weight: [[ 0.0197454   0.14849602 -0.29870918  0.0200894   1.491103    0.28543925
   1.4166683   0.14143771 -0.01972471 -0.01947634  0.01988617  0.01983011
  -0.19076185 -0.01964407 -0.01891588 -0.18612763 -0.20691788  0.02008215
   0.32469723 -0.01933843 -0.17257938 -0.01582848  0.01999902 -0.01986499
   0.19170491 -0.21495935  0.01966931  0.2077673   0.02015333  0.01986005
  -0.02006369 -0.20610568]]

Final Loss: 2.4336
Distance Metric: 28.2625
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 1099

================================================================================

multiChannelCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.00229784 -0.00996346  0.02646261 ... -0.01594023 -0.00467888
  -0.0010447 ]
 [-0.05651566 -0.0101363   0.01510248 ... -0.29421434  0.28596583
  -0.08329362]
 [-0.05524369 -0.01617249 -0.04183534 ...  0.05419666  0.03039294
   0.01410338]
 ...
 [-0.02917669 -0.00449939 -0.027844   ...  0.01187645 -0.02943828
  -0.0100787 ]
 [-0.00567056 -0.01595118  0.01965111 ...  0.01206256  0.06441783
   0.0210264 ]
 [ 0.05787909  0.01777884  0.04221984 ... -0.0694991  -0.04879124
  -0.02493193]]
layers.1.weight: [[-0.00427309  0.06131854  0.00621357 ... -0.00049004  0.00262056
  -0.00857352]
 [-0.00452592  0.06644286  0.00678002 ... -0.00046243  0.00292541
  -0.00917176]
 [-0.0104002   0.18583946  0.01722646 ... -0.00169572  0.00925777
  -0.02263765]
 ...
 [ 0.00115085 -0.02576814 -0.00327076 ... -0.0005068  -0.00170579
   0.00287142]
 [ 0.00154516 -0.03061686 -0.00370998 ... -0.00041911 -0.00185629
   0.00359527]
 [ 0.0132346  -0.24988216 -0.02162072 ...  0.00307526 -0.01247548
   0.02939171]]
layers.2.weight: [[-0.29158717 -0.31472698 -0.78011215 -0.35057944  0.9649177   0.0169871
  -0.0918909  -0.5553712   0.97441256 -0.9646877   2.9408925  -0.03261236
   0.04398222 -2.6440175   0.25525427  0.06777342 -3.5570688  -0.41286725
  -0.09667941  0.02779059 -0.21502471 -0.24263299  0.9711311  -7.5523667
  -0.20719655 -0.27920958 -0.46318853 -0.16620654  1.3827885   0.12873663
   0.15253058  0.98802465]]

Final Loss: 0.2310
Distance Metric: 31.4408
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 3023

================================================================================

multiChannelCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-0.15477483  0.02089353  0.11878229 ... -0.03255057  0.07207347
   0.02051165]
 [ 0.05048688  0.04387949 -0.03330501 ... -0.21774764  0.01548679
  -0.09863552]
 [-0.0180402   0.1533382  -0.0520369  ...  0.02435773  0.02882986
   0.02874711]
 ...
 [-0.03322065  0.05528255  0.0748386  ...  0.00821408 -0.05851773
   0.03031655]
 [-0.28196788  0.02275248  0.02048046 ... -0.00220234  0.09884422
   0.04422487]
 [-0.18008909  0.03199209 -0.02410503 ... -0.00075735 -0.04811539
  -0.0387894 ]]
layers.1.weight: [[-0.14369397 -0.00247592  0.03485109 ... -0.02129366 -0.02552772
   0.05011212]
 [ 0.08804259  0.12086375  0.02581836 ...  0.1688483   0.05101748
   0.05918954]
 [-0.05319452  0.0579301  -0.18787995 ...  0.0596436  -0.00902377
  -0.13541639]
 ...
 [ 0.06681585  0.03589761  0.02563599 ...  0.2535876   0.05626681
   0.12181977]
 [ 0.00566699 -0.03671415  0.01040531 ... -0.00042041  0.09354206
  -0.08426105]
 [-0.04864405 -0.0997206   0.05603353 ...  0.06638838  0.13366866
   0.06503554]]
layers.2.weight: [[ 0.37456107 -0.6987232   0.32479155 -0.77623904 -0.64611274  0.25897104
  -0.32084042  0.35656065  0.2758683  -0.510214   -0.31734923  0.27434134
  -0.4739267   0.55122465  0.42244723 -0.68307     0.3707455   0.32348984
  -0.38477817 -0.55088806  0.29993936  0.28653148 -0.42524427 -0.350525
   0.4935976   0.34611285  0.2741456  -0.5720288   0.3442891  -0.759263
   0.29413393 -0.5850478 ]]

Final Loss: 0.2352
Distance Metric: 19.6713
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 934

================================================================================

multiChannelCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.00126038  0.00452233  0.00417589 ...  0.0019256  -0.00377216
   0.00541456]
 [ 0.001064    0.00022308  0.003002   ... -0.00183287 -0.00111252
  -0.00429928]
 [ 0.00671805 -0.00751763  0.00869204 ... -0.00233038  0.00826888
  -0.0110115 ]
 ...
 [-0.00217099  0.00432615 -0.00237209 ...  0.00115907 -0.0056718
   0.00834146]
 [ 0.00185583 -0.00463884  0.         ... -0.00138286  0.00533555
  -0.00498277]
 [-0.00255556  0.00045048 -0.00755585 ...  0.00061411 -0.00072355
   0.00298009]]
layers.1.weight: [[-0.00104266 -0.00039529 -0.0008935  ...  0.          0.00030735
   0.00117666]
 [ 0.00145748  0.00058188  0.00147395 ...  0.         -0.00036052
  -0.00175308]
 [ 0.00251452 -0.00567354 -0.0102055  ...  0.00599952 -0.00314348
   0.00508577]
 ...
 [ 0.00093168  0.00034981  0.00077357 ...  0.         -0.00028243
  -0.00104048]
 [-0.00152551 -0.00056922 -0.00155563 ...  0.          0.00038277
   0.00182565]
 [-0.00038895 -0.00014276 -0.00029052 ...  0.          0.00012688
   0.0004179 ]]
layers.2.weight: [[ 0.07983424 -0.11756434  0.7251092  -0.34890488  0.36272857  0.48903593
  -0.05651917  0.14042331  0.06372715 -0.12966253  0.04826288  0.11722947
   0.07242953 -0.360117   -0.0411123   0.08287807 -0.24097435  0.88033915
  -0.04962263 -0.02017663  0.07797163  0.27459127 -0.10869392  0.0045759
  -0.89217013 -0.04565124 -0.04491489  0.5961609  -0.0544385  -0.07071479
   0.12395606  0.02855548]]

Final Loss: 0.0006
Distance Metric: 8.5265
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 1136

================================================================================

