Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.0725508   0.05479349 -0.07691643]]

 [[-0.08239191 -0.05627735 -0.10398467]]

 [[ 0.11947256 -0.07516178 -0.0899037 ]]

 [[-0.11573362 -0.10147351 -0.09668112]]]
layers.1.weight: [[[ 0.06831169 -0.05618221]
  [-0.05048486  0.05310852]
  [ 0.12246924 -0.0444613 ]
  [ 0.0507839  -0.08282235]]

 [[ 0.01117534  0.07127499]
  [ 0.06058899  0.09682198]
  [-0.00781927  0.08185679]
  [-0.03770983 -0.01818325]]

 [[ 0.08953753 -0.08527942]
  [-0.0461405   0.01599835]
  [ 0.05047125  0.05755028]
  [-0.05400843 -0.03344396]]

 [[-0.05603869  0.08576181]
  [ 0.11256712  0.06767148]
  [-0.03735587  0.00075204]
  [-0.00620596  0.07698128]]]
layers.2.weight: [[[-0.0076765   0.10527762]
  [-0.0072187   0.07282244]
  [ 0.11144265 -0.13146459]
  [-0.07062697 -0.02777096]]]

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0.00139149 0.00139047 0.00139176 0.00139179 0.0013925  0.00139235
  0.00139207 0.00139204 0.00139155 0.00139164 0.00139251 0.00139072
  0.00139236 0.00139247 0.00139117 0.00139229 0.00139093 0.00139206
  0.00139144 0.00139078 0.00139256 0.00139172 0.00139197 0.00139044
  0.00139057 0.00139244 0.00139246 0.00139174 0.00139225 0.00139187
  0.00139175 0.00139138]]

Final Loss: 0.0000
Distance Metric: 0.9036
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 1203

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.03102164  0.05812741  0.09173527 ...  0.05541886  0.01484508
  -0.11092679]
 [-0.06826275 -0.00229636 -0.03470243 ...  0.01665811 -0.01440857
  -0.03681435]
 [ 0.02945299  0.01846831 -0.06099831 ...  0.03615167  0.16896875
  -0.01543445]
 ...
 [-0.10604151 -0.01462387  0.00797333 ... -0.01242289  0.04031705
   0.0139786 ]
 [-0.0337007   0.07082984  0.04272553 ... -0.00112896  0.01280567
  -0.04693468]
 [-0.0742552   0.07433617 -0.04067033 ... -0.11358873  0.03371141
  -0.03215509]]
layers.1.weight: [[-0.0603218  -0.00334347 -0.07544816 ...  0.04133869 -0.03852101
   0.01023485]
 [-0.04712314  0.01784359 -0.02532637 ...  0.02334178  0.05747198
   0.0457667 ]
 [-0.03253482 -0.01933979  0.01068373 ...  0.03498107 -0.01779487
  -0.09932007]
 ...
 [-0.00432391  0.10709726  0.01523881 ... -0.04523219 -0.0147932
  -0.00210756]
 [ 0.09865586  0.00939166  0.03115134 ... -0.00871823  0.04811855
  -0.02877328]
 [ 0.04212684  0.03087902 -0.01244499 ...  0.01134251  0.04911888
   0.03972046]]
layers.2.weight: [[-0.3586773  -0.4665473  -0.50988626  0.1897358  -0.5550081   0.31997105
  -0.44394907 -0.55571157  0.22778708  0.13727844  0.20325015  0.14573725
  -0.50841075  0.1601038   0.34294337 -0.48622304  0.11970296 -0.49401173
   0.2843036  -0.48732093  0.16347685  0.17688406  0.21451283  0.1767678
   0.247102   -0.53799504  0.3818723  -0.4338192   0.25822923 -0.3255917
  -0.38513386  0.16114852]]

Final Loss: 0.0110
Distance Metric: 9.2838
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 948

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.00183459  0.00461904  0.00300183 ... -0.00168445 -0.0030517
   0.00035941]
 [ 0.00268411 -0.00501535 -0.0025472  ...  0.00137559  0.00317698
   0.00027746]
 [ 0.00312897 -0.00766284 -0.00461845 ...  0.00332697  0.00474795
   0.00017464]
 ...
 [ 0.00015602 -0.00052856 -0.00039022 ...  0.00012995  0.00042996
  -0.00012504]
 [-0.00028082  0.00084358  0.         ... -0.00051984  0.
   0.00016539]
 [-0.00311021  0.00538957  0.00340757 ... -0.0026907  -0.00413405
   0.00053432]]
layers.1.weight: [[ 0.         -0.00011636  0.00089383 ... -0.00161261 -0.00030826
   0.00157658]
 [ 0.00229878 -0.00158455 -0.00159216 ...  0.00117446  0.00182151
   0.00150111]
 [ 0.00013894  0.         -0.00068099 ...  0.00034702  0.0007637
   0.00136961]
 ...
 [ 0.0022661  -0.00069867 -0.00250966 ...  0.00151405  0.0016578
   0.00052103]
 [ 0.00212392  0.00094559 -0.00060016 ... -0.00039386 -0.00168764
   0.00108188]
 [ 0.          0.00082658  0.00060626 ...  0.         -0.00051829
  -0.00229612]]
layers.2.weight: [[-0.00805555 -0.01269296 -0.00169156  0.00383307 -0.01579586 -0.00318398
   0.02682644 -0.00071651 -0.00091299 -0.01701663 -0.00170177 -0.00467166
   0.01208131 -0.03852214 -0.01110422 -0.00948037  0.0082697  -0.00769024
  -0.01774114 -0.02674351  0.02912972 -0.00475504 -0.01325744  0.00174035
  -0.02491311 -0.02907512 -0.01503531 -0.01013361 -0.0339678  -0.01925593
  -0.03078673  0.01904066]]

Final Loss: 0.2536
Distance Metric: 1.2471
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 346

================================================================================

multiChannelCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.00024793  0.0002073  -0.00064533 ...  0.          0.
   0.00011576]
 [ 0.00024966  0.00020804 -0.00064546 ...  0.          0.
   0.00011569]
 [ 0.00024859  0.00020808 -0.00064487 ...  0.          0.
   0.00011618]
 ...
 [ 0.00024931  0.00020709 -0.00064412 ...  0.          0.
   0.00011604]
 [ 0.00024867  0.00020755 -0.00064602 ...  0.          0.
   0.00011612]
 [ 0.00024921  0.00020699 -0.00064416 ...  0.          0.
   0.00011581]]
layers.1.weight: [[0.00801967 0.00801882 0.00801934 ... 0.00802034 0.00801922 0.0080194 ]
 [0.00802327 0.00802323 0.0080233  ... 0.00802174 0.00802301 0.00802165]
 [0.0080212  0.0080203  0.00802084 ... 0.0080198  0.00802074 0.00802013]
 ...
 [0.00802351 0.00802292 0.00802246 ... 0.00802333 0.00802423 0.00802345]
 [0.0080163  0.00801605 0.00801673 ... 0.0080165  0.00801696 0.00801558]
 [0.00802338 0.00802299 0.0080231  ... 0.00802186 0.00802309 0.00802182]]
layers.2.weight: [[-0.2465964  -0.24665958 -0.24660616 -0.24674603 -0.24665603 -0.24673966
  -0.24665396 -0.24663424 -0.24660337 -0.24671449 -0.24666357 -0.24651977
  -0.24671412 -0.2465317  -0.2465053  -0.24663897 -0.24672627 -0.24667875
  -0.24670903 -0.24667858 -0.24649331 -0.24653411 -0.2466144  -0.24670894
  -0.24667063 -0.24671718 -0.24659842 -0.24664813 -0.24662894 -0.2466854
  -0.24651036 -0.24666862]]

Final Loss: 0.0000
Distance Metric: 3.5797
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 1086

================================================================================

multiChannelCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.00025717 -0.00073073 -0.00118006 ... -0.00183204  0.00362761
   0.00200453]
 [ 0.          0.          0.         ...  0.00022303 -0.00011734
   0.00011911]
 [ 0.         -0.00282373 -0.00496301 ...  0.00047195 -0.00148289
  -0.00083237]
 ...
 [ 0.00069124  0.00052158  0.00221022 ... -0.00425137  0.0054705
   0.00194012]
 [ 0.00014182 -0.00037639 -0.00062393 ... -0.00100891  0.00191763
   0.00104442]
 [ 0.0001814  -0.0004846  -0.00080125 ... -0.00129634  0.00246068
   0.00134176]]
layers.1.weight: [[-0.00264616  0.          0.00072104 ...  0.00098046 -0.00140124
  -0.00180036]
 [-0.00762816 -0.0001801   0.00208261 ...  0.00282488 -0.00403749
  -0.00518593]
 [-0.00632312 -0.00014911  0.00172698 ...  0.00234224 -0.00334605
  -0.00429944]
 ...
 [-0.00246581  0.          0.00067653 ...  0.00091363 -0.00130529
  -0.00167565]
 [-0.00278859  0.          0.00076338 ...  0.00103507 -0.00147662
  -0.00189504]
 [ 0.00011361  0.          0.         ...  0.          0.
   0.        ]]
layers.2.weight: [[ 0.02213971  0.06377052  0.05285822 -0.00095482  0.013109   -0.00044433
   0.0326386   0.         -0.00109021  0.09128509  0.09641734  0.01321134
   0.         -0.00103765  0.04761991 -0.00082815  0.00083051  0.01683661
   0.05421285  0.          0.03282355  0.04667292  0.02272894 -0.00157854
  -0.00020668 -0.00174116  0.0191104   0.02772285  0.00129325  0.02061118
   0.02332976 -0.00056195]]

Final Loss: 0.0000
Distance Metric: 1.7000
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 1118

================================================================================

multiChannelCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0.]]

Final Loss: 0.0000
Distance Metric: 1.2742
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 1791

================================================================================

multiChannelCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.00137828  0.01142947  0.00779741 ...  0.00064969 -0.00248778
   0.00021192]
 [ 0.00137167  0.01138753  0.00777426 ...  0.0006468  -0.00247827
   0.00021441]
 [ 0.00137568  0.01142337  0.00779787 ...  0.00064563 -0.00248422
   0.0002105 ]
 ...
 [ 0.00137503  0.01141299  0.00779514 ...  0.00064737 -0.00248337
   0.00021532]
 [ 0.001372    0.01135909  0.00775247 ...  0.00064292 -0.00246859
   0.00021235]
 [ 0.00137329  0.01141969  0.00780054 ...  0.00064753 -0.00248555
   0.00021273]]
layers.1.weight: [[0.00834397 0.00833277 0.0083396  ... 0.00833844 0.00831593 0.00834008]
 [0.00834235 0.00833057 0.00833878 ... 0.00834041 0.00832215 0.00834075]
 [0.00834113 0.00832828 0.00834024 ... 0.00833597 0.00831762 0.00834067]
 ...
 [0.00832202 0.00830972 0.00831853 ... 0.00831503 0.00830007 0.00831837]
 [0.00832735 0.00832034 0.00832756 ... 0.00832766 0.00830796 0.00833106]
 [0.00833959 0.00832511 0.00833802 ... 0.0083317  0.00831482 0.00833457]]
layers.2.weight: [[-0.250362   -0.25041413 -0.25035378 -0.2502428  -0.25027555 -0.25001857
  -0.25032595 -0.25035632 -0.25028566 -0.25037467 -0.2503123  -0.25041017
  -0.25013354 -0.2500744  -0.25008258 -0.2503973  -0.2502419  -0.25023267
  -0.25042892 -0.24998902 -0.25022048 -0.25039566 -0.25029415 -0.25039244
  -0.25032857 -0.25030193 -0.25043142 -0.25006986 -0.2503307  -0.2497784
  -0.25009495 -0.25032133]]

Final Loss: 0.0014
Distance Metric: 4.4172
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 949

================================================================================

multiChannelCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-0.0018486   0.00160323  0.0040145  ...  0.00095354  0.00401451
   0.00816056]
 [ 0.         -0.00012708 -0.00028104 ...  0.00055997  0.00043625
   0.00011504]
 [ 0.          0.          0.00014225 ... -0.00051236 -0.00042532
  -0.0001485 ]
 ...
 [-0.00010977  0.          0.00010415 ...  0.          0.00012782
   0.00019262]
 [-0.00266099  0.00205546  0.00566435 ...  0.00284729  0.00658341
   0.01099735]
 [ 0.          0.          0.00024465 ... -0.0010851  -0.00089691
  -0.00029906]]
layers.1.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.00210035 -0.00015625 -0.00012419 ...  0.          0.00295889
  -0.00025278]]
layers.2.weight: [[-1.00704528e-04  1.39076437e-04 -2.56082276e-04  0.00000000e+00
   0.00000000e+00  0.00000000e+00  1.12960950e-01  0.00000000e+00
   7.95635059e-02  5.48472665e-02  7.81110525e-02  5.14645949e-02
   1.27359126e-02  4.14487720e-02  5.36752045e-02  9.75522250e-02
   4.59174514e-02  2.99346466e-02  7.21369311e-02  0.00000000e+00
   0.00000000e+00  9.65568935e-04 -1.44420599e-04  1.58858355e-04
   4.18085828e-02  1.10599615e-01  1.58100016e-02  1.79442141e-04
   4.73426394e-02  0.00000000e+00  0.00000000e+00  4.39588614e-02]]

Final Loss: 0.0002
Distance Metric: 1.8913
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 860

================================================================================

multiChannelCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.00324315 -0.00772591  0.00937938 ...  0.00429094 -0.00225879
   0.01130329]
 [-0.00043794 -0.0010453   0.00126973 ...  0.0005818  -0.00030808
   0.00153462]
 [ 0.00218629  0.00521204 -0.00633047 ... -0.00290131  0.00152626
  -0.00764134]
 ...
 [-0.00107835 -0.00256913  0.00312258 ...  0.00142892 -0.00075264
   0.00377074]
 [ 0.00249547  0.00594743 -0.00722149 ... -0.00330824  0.00174215
  -0.00871296]
 [-0.00050343 -0.00120192  0.00146058 ...  0.00066918 -0.00035198
   0.00176291]]
layers.1.weight: [[ 0.00020421  0.         -0.00013657 ...  0.         -0.00015642
   0.        ]
 [-0.00062251  0.          0.00042242 ... -0.00020853  0.00048025
   0.        ]
 [ 0.00588134  0.00079884 -0.00397319 ...  0.00196023 -0.00453229
   0.00091684]
 ...
 [-0.0054338  -0.00073532  0.00367267 ... -0.00181203  0.00419025
  -0.00084827]
 [ 0.00136551  0.00018627 -0.00092351 ...  0.00045673 -0.00104935
   0.00021254]
 [-0.00555001 -0.00075177  0.00375258 ... -0.00185011  0.0042781
  -0.00086673]]
layers.2.weight: [[ 0.00281499 -0.00868209  0.08174165 -0.04116905 -0.00297387  0.07710298
   0.02032076  0.01873799  0.00254235  0.01680288  0.00952469  0.05128585
   0.07911363 -0.04595289 -0.06742117  0.0003317   0.01878707 -0.07057376
   0.01141946 -0.05805229  0.06101784  0.09461155 -0.06303674 -0.01679381
   0.00034104 -0.09689537  0.02309554  0.05455741  0.0129631  -0.07553465
   0.01896979 -0.07714085]]

Final Loss: 0.0000
Distance Metric: 1.9728
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 1081

================================================================================

