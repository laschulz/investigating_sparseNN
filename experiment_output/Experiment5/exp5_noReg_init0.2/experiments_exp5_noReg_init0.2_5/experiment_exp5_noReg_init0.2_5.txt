Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.02935871  0.07950273 -0.01860587]]

 [[ 0.04993595  0.08147299 -0.04688057]]

 [[ 0.11349684  0.12007649  0.10019027]]

 [[-0.03953208  0.07742103 -0.07130682]]]
layers.1.weight: [[[ 0.09851278  0.09099542]
  [-0.09756707  0.00592992]
  [ 0.00982233  0.10170404]
  [ 0.11265574  0.09300414]]

 [[-0.11053558 -0.03705058]
  [-0.04522468 -0.0492827 ]
  [ 0.07147727  0.11494905]
  [-0.07420101 -0.10749694]]

 [[-0.07625904 -0.07239844]
  [ 0.07401183 -0.11219128]
  [ 0.05351537  0.11010487]
  [ 0.03414411  0.10677379]]

 [[ 0.07433326  0.06244647]
  [ 0.09364282 -0.10606134]
  [-0.03379757  0.00377373]
  [-0.1194687   0.10048642]]]
layers.2.weight: [[[ 0.01291269 -0.05095901]
  [-0.13416192  0.1472371 ]
  [ 0.00229784  0.09840246]
  [-0.0681918   0.02813202]]]

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.0271027   0.02759535  0.01579206 ... -0.0274947   0.02248418
   0.00411279]
 [ 0.00019056  0.0114994   0.0051299  ... -0.00358198 -0.00587797
  -0.00516628]
 [ 0.02972425 -0.02775015  0.00139593 ... -0.02411173  0.02700566
  -0.01221957]
 ...
 [ 0.0084739   0.02702726  0.02197984 ... -0.00912175 -0.00144314
   0.0015518 ]
 [ 0.02501765  0.0061247  -0.00740771 ...  0.00243084 -0.028297
   0.02508481]
 [-0.02095931 -0.0231205   0.01748931 ...  0.02576899 -0.01457192
  -0.0275352 ]]
layers.1.weight: [[-0.02310888 -0.02827454  0.02820564 ... -0.01632191  0.01953452
  -0.00390797]
 [-0.00437505  0.02767911  0.02362374 ...  0.00379493  0.00076147
   0.02536999]
 [-0.01387461 -0.02717265  0.02750446 ... -0.02395841  0.00057275
  -0.01835408]
 ...
 [-0.02848034  0.01713027 -0.0249711  ... -0.01465596  0.00078463
   0.0179816 ]
 [ 0.          0.02680921 -0.01413036 ... -0.02292258  0.01891624
  -0.02190104]
 [-0.01481704  0.01265673  0.0032862  ... -0.01505897  0.02151748
  -0.01146452]]
layers.2.weight: [[-0.01451706 -0.07925585 -0.00390089 -0.05503996  0.10097367 -0.03452981
  -0.04818589  0.02008956 -0.02204647 -0.04287748  0.03238704  0.02268303
   0.03312748  0.01016007  0.07693326  0.07686628 -0.01029247 -0.05536813
   0.09931425 -0.04498549 -0.02010375 -0.04208077  0.08376406 -0.06960359
  -0.04168634  0.02042369 -0.00441594  0.0007953   0.03884444  0.02544624
   0.0162914  -0.07481834]]

Final Loss: 0.0000
Distance Metric: 3.2292
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 1999

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 8.8299416e-02 -2.7567404e-04  2.0481901e-01 ...  1.5715978e-01
  -4.5701537e-02 -4.1835973e-01]
 [-8.0044799e-02 -1.3050075e-01 -1.1093191e-01 ... -4.4401544e-01
   1.2760416e-01  6.7026010e-03]
 [-7.0990548e-02 -2.6381117e-01 -2.1607096e-01 ... -8.8820688e-02
   3.0337954e-01  5.0931633e-02]
 ...
 [ 2.1477448e-02 -1.6005537e-01  9.0245521e-03 ... -9.1945805e-02
  -1.2309550e-01  3.9742175e-01]
 [-2.3570707e-02 -8.9533553e-02 -4.6335340e-02 ... -9.6716449e-02
  -9.5595606e-02 -7.1584679e-02]
 [ 1.2119130e-01  1.0340769e-01 -1.1683680e-01 ...  1.9675966e-01
  -2.8101182e-01  6.8452813e-02]]
layers.1.weight: [[ 0.07747062 -0.04807657  0.09141654 ... -0.11607066  0.01684204
   0.04969251]
 [-0.16644982 -0.19572891  0.24415681 ... -0.12222862  0.23627073
  -0.19959743]
 [-0.00359285 -0.2727205  -0.11657307 ... -0.13126178  0.03069526
  -0.08468617]
 ...
 [ 0.2306524  -0.24229003 -0.38272208 ... -0.13610923  0.4727283
   0.00808083]
 [-0.08065917 -0.17539342 -0.13758038 ...  0.11075844  0.2426717
  -0.16985612]
 [-0.21104643 -0.22698215  0.38404033 ... -0.40906602  0.10318779
  -0.03461744]]
layers.2.weight: [[ 0.1065794  -0.11726593 -0.10108154 -0.23364384  0.10755929 -0.43560922
   0.10786385  0.10377996 -0.10185307  0.10461828 -0.16418578 -0.14164051
  -0.39703023  0.11509059  0.14030015 -0.30631918 -0.11046498  0.11122338
   0.10076156 -0.18068    -0.1532119  -0.21019192 -0.4279142  -0.6673837
  -0.1379056  -0.11133489 -0.28854367  0.11357288  0.09216652 -0.14615537
   0.11011142 -0.42100498]]

Final Loss: 0.0085
Distance Metric: 28.4002
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 1999

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.02658636 -0.02035924 -0.03819543 ... -0.02463916  0.01501097
   0.02523909]
 [-0.00172285  0.00114295  0.0173739  ...  0.00419    -0.03179178
  -0.01982365]
 [-0.01563854  0.01550578  0.01026754 ...  0.00291603  0.03377958
   0.00611633]
 ...
 [ 0.03004083  0.02693369 -0.00032321 ...  0.01615316 -0.02403218
   0.02580488]
 [-0.0229658  -0.01388743 -0.01592878 ...  0.03409044 -0.00842477
  -0.01895174]
 [-0.00525725 -0.01802711  0.00757021 ... -0.02098383  0.01889943
  -0.0242286 ]]
layers.1.weight: [[ 0.03721983  0.04523259 -0.01520313 ... -0.01950221 -0.0415065
  -0.00940985]
 [ 0.01579692  0.02440948 -0.04341049 ... -0.03742063 -0.0090208
  -0.00606454]
 [-0.03236792  0.01958341  0.0440498  ... -0.01050238  0.04417506
   0.00616664]
 ...
 [ 0.03889582  0.00541886  0.02887155 ... -0.00201528 -0.02443879
  -0.02297905]
 [-0.02618858 -0.01876446 -0.02562211 ... -0.01270393  0.02455786
   0.01904391]
 [ 0.04300437  0.0231501   0.01706769 ...  0.04057419 -0.04159598
  -0.03440159]]
layers.2.weight: [[ 0.0019991   0.00073931 -0.018649    0.00828274  0.00835993  0.0130085
  -0.00915314  0.00714146  0.01066974  0.00042848  0.00033028  0.00272919
   0.0139959  -0.00104071 -0.01339238  0.00263202 -0.0053199   0.01056114
  -0.00997158  0.00381181  0.00317009  0.00587477  0.01042772  0.00602488
   0.01009472  0.01560702  0.00725047 -0.00744982 -0.01280279  0.00104852
   0.00546147  0.00649265]]

Final Loss: 0.2477
Distance Metric: 4.2404
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 144

================================================================================

multiChannelCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.00939276  0.02416586  0.02032606 ...  0.02722114 -0.00537622
   0.02455344]
 [ 0.00618634  0.02194589 -0.0037678  ... -0.02220006 -0.009645
  -0.00818999]
 [-0.02812473  0.01248765 -0.00583751 ...  0.02282869  0.01096876
   0.02929949]
 ...
 [-0.00762958  0.02031269 -0.02346853 ... -0.01484875 -0.00225006
   0.02792844]
 [ 0.0113374  -0.01362534  0.02924999 ... -0.00150182  0.01505844
  -0.01097252]
 [-0.00293191 -0.02690239 -0.01968375 ... -0.00661831 -0.01765582
   0.01816793]]
layers.1.weight: [[ 0.03808523  0.02003274  0.00784176 ... -0.01097685 -0.01649499
  -0.00053367]
 [ 0.01720497  0.00917348 -0.01646552 ... -0.01703987 -0.01060564
   0.03782309]
 [-0.01900113  0.00314896  0.01244508 ...  0.00551038 -0.02285359
  -0.01276661]
 ...
 [ 0.01160097 -0.01052306 -0.02224158 ...  0.00391512  0.02431493
  -0.02039738]
 [ 0.00438901  0.01994343  0.02442107 ...  0.03125     0.00175873
   0.00196236]
 [-0.00170536  0.02726555  0.01824056 ...  0.03125623 -0.0137556
   0.00376889]]
layers.2.weight: [[-0.40909588 -0.42885044 -0.23594768 -0.28847763 -0.38139814 -0.3890358
  -0.3733205  -0.234992   -0.40089703 -0.3571673  -0.25       -0.3658219
  -0.18550955 -0.27778214 -0.25       -0.32316428 -0.24617945 -0.38333562
  -0.38677514 -0.25       -0.34533238 -0.37482837 -0.24969386 -0.3123446
  -0.4193815  -0.39314708 -0.25       -0.39472526 -0.32199803 -0.19665669
  -0.29412428 -0.3748548 ]]

Final Loss: 0.0000
Distance Metric: 5.7575
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 1999

================================================================================

multiChannelCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.00284929 -0.01151796 -0.00218879 ... -0.00285949 -0.0007257
   0.00413625]
 [ 0.00261502  0.01350117 -0.0027594  ... -0.00736569 -0.01847932
  -0.00569781]
 [ 0.00707443 -0.00224667  0.00837386 ...  0.00050529 -0.00648629
  -0.00516888]
 ...
 [ 0.01115027 -0.0047299   0.01403501 ...  0.00176214 -0.01223743
  -0.00691555]
 [ 0.00062701 -0.0011065   0.00185432 ...  0.00072851 -0.00625128
  -0.00739063]
 [-0.00254147  0.00542959  0.02168329 ... -0.00314571 -0.00502414
  -0.00150046]]
layers.1.weight: [[-0.00535944 -0.01133999 -0.01481795 ...  0.03609904 -0.02007818
  -0.01428769]
 [ 0.04671655  0.01100551  0.05137035 ... -0.00090356 -0.06555893
  -0.05605654]
 [-0.02344163  0.02818138  0.02990887 ...  0.00328625  0.01644952
   0.04476145]
 ...
 [-0.03983738  0.0040876  -0.06482835 ...  0.05094062  0.04424011
  -0.02589856]
 [-0.07533263  0.03672357  0.01681869 ...  0.06395598  0.08121247
   0.07533065]
 [-0.05098539 -0.01655281  0.06762045 ... -0.01557763  0.06037781
   0.03423896]]
layers.2.weight: [[-0.09145023 -0.14153707 -0.54162043 -0.5215379  -0.02919598  0.69065803
   0.47679573 -0.17369533  0.15717082 -0.13161875 -0.01079248 -0.2800167
   0.36926588 -0.25858742 -0.10579272 -0.09865912 -0.40180343 -0.40439516
   0.06059293  0.3214112   0.00136758  0.31946048  0.0333106   0.36077648
  -0.06163957  0.2092035  -0.36848283 -0.00404202 -0.2770479   0.19710615
  -0.3158168  -0.4518239 ]]

Final Loss: 0.0000
Distance Metric: 6.7916
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 1999

================================================================================

multiChannelCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.00535777 -0.0001388  -0.04305451 ...  0.00022038  0.00540433
   0.04762805]
 [-0.03259162  0.00279674  0.04577114 ...  0.00608442  0.0420038
   0.01251292]
 [-0.02994172 -0.0513773  -0.00315532 ...  0.04548228  0.04813685
  -0.03236929]
 ...
 [ 0.02575242  0.04576107 -0.00591845 ... -0.01151446  0.00048964
  -0.01836842]
 [-0.04236401 -0.01235432  0.01648016 ... -0.04347074 -0.02271581
   0.03425381]
 [ 0.04487876 -0.00876565  0.03011115 ...  0.02076644  0.04422542
   0.01146113]]
layers.1.weight: [[-0.04017355 -0.01915252 -0.04200588 ... -0.03364976  0.03755605
   0.01760933]
 [-0.01109699 -0.00206821  0.03558917 ... -0.04671157  0.03220466
   0.03595668]
 [-0.01888733  0.03889356 -0.01573461 ... -0.04020492 -0.03686501
  -0.03174056]
 ...
 [-0.01829065 -0.0428965   0.01298183 ... -0.02686644 -0.04186861
   0.04274111]
 [ 0.01869674 -0.01370119 -0.0009322  ... -0.02493475 -0.01136697
  -0.0178957 ]
 [ 0.00249746  0.02201612  0.01273598 ...  0.04279052 -0.01297225
  -0.01304116]]
layers.2.weight: [[-0.03539683  0.          0.08911724  0.09024132  0.04589155  0.08982448
   0.0848871  -0.02962373 -0.03821618  0.01491141 -0.00401681  0.014939
  -0.04165692  0.09972631  0.08306988  0.00688036  0.02075072  0.06386402
   0.04104352  0.01171017  0.03029834  0.01196916 -0.00136391  0.08135616
  -0.00253415 -0.01196936  0.05852813  0.11513279  0.06858002 -0.08269458
   0.06093415  0.07268247]]

Final Loss: 0.0000
Distance Metric: 5.1464
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 1999

================================================================================

multiChannelCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.01819583 -0.01186179 -0.02148767 ... -0.03129061  0.02210658
   0.03076346]
 [-0.00781976  0.00091829  0.01383868 ... -0.01160681 -0.02270622
  -0.00160906]
 [-0.01562716  0.01163404  0.01572165 ... -0.01461896  0.03125124
   0.01959877]
 ...
 [ 0.02882261  0.02352575  0.00169034 ...  0.0028234  -0.01127914
   0.0273172 ]
 [-0.02456346 -0.00871985 -0.00982511 ...  0.02442934  0.00468132
  -0.01667199]
 [-0.00244526 -0.01336147  0.01110592 ... -0.01562503  0.01465982
  -0.02026953]]
layers.1.weight: [[ 0.03654474  0.03437922  0.00260052 ... -0.00103908 -0.01985404
   0.00155493]
 [ 0.02497062  0.02654478 -0.01564215 ... -0.01470804  0.00470589
   0.00768059]
 [-0.00269043  0.02179445  0.03992996 ...  0.00322499  0.03670535
   0.01640253]
 ...
 [ 0.03535728  0.01214838  0.02563745 ...  0.00546077 -0.00628008
  -0.00554266]
 [-0.00845521 -0.0042156  -0.00155914 ...  0.00061494  0.02370804
   0.02341354]
 [ 0.03754995  0.01940902  0.02225705 ...  0.03231799 -0.02069519
  -0.0104883 ]]
layers.2.weight: [[-0.34849808 -0.40153703 -0.45780936 -0.25960886 -0.25680017 -0.17592034
  -0.3874374  -0.3634058  -0.2236594  -0.40564653 -0.34406513 -0.34200937
  -0.28967023 -0.41001686 -0.47313812 -0.27654836 -0.43664756 -0.23861262
  -0.3968466  -0.39507473 -0.41189095 -0.40368837 -0.23910847 -0.22515458
  -0.3116154  -0.20731027 -0.26227456 -0.38988173 -0.41796303 -0.31567726
  -0.35118708 -0.34709707]]

Final Loss: 0.0003
Distance Metric: 6.1934
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 1999

================================================================================

multiChannelCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.0074943   0.00266264 -0.00163705 ...  0.00043699 -0.0091436
  -0.02192976]
 [ 0.00211669  0.00564679 -0.00429669 ... -0.01234598 -0.00504666
   0.01319842]
 [ 0.00930844 -0.01745519 -0.01036596 ... -0.01745538  0.01631806
  -0.02325472]
 ...
 [-0.00533248 -0.00914528  0.00756987 ... -0.00209321  0.01214342
   0.02149624]
 [ 0.0160033  -0.00619269 -0.00177175 ... -0.02616259 -0.01984465
  -0.00514946]
 [ 0.00980295 -0.0025517  -0.01294533 ...  0.02093056 -0.0154439
  -0.00320555]]
layers.1.weight: [[ 0.10918324 -0.09689254  0.01605607 ...  0.03825311  0.00722831
   0.01013159]
 [ 0.017454   -0.03551363 -0.00250863 ...  0.01440862  0.03699452
   0.0190949 ]
 [-0.02472837 -0.0327883  -0.02600534 ...  0.06539588 -0.035616
  -0.01121252]
 ...
 [ 0.08255099 -0.01984699 -0.07905936 ...  0.03339412  0.08988987
   0.00622388]
 [-0.02617822 -0.02728629  0.01969261 ...  0.07986255 -0.07720863
  -0.05954748]
 [-0.02824919 -0.04959979  0.04231779 ... -0.06734231 -0.00046121
   0.04952626]]
layers.2.weight: [[ 1.5854011e-01 -2.8066525e-02 -4.3644771e-02 -3.3289459e-01
   2.7304611e-01 -6.0181493e-01  1.9595526e-01  2.1652745e-02
  -1.2521479e-01  1.6207199e-01 -6.5718397e-02 -2.1302843e-01
  -4.2462784e-01  4.5873931e-01 -2.8979877e-04 -2.2653228e-01
  -2.9689515e-02  5.7779413e-01  6.7153707e-02 -1.3618977e-01
  -6.0407270e-02 -2.1287492e-01 -5.9610653e-01 -6.0172290e-01
  -1.7397065e-01 -8.7877952e-02 -1.9632700e-01  2.3404895e-01
   2.3336704e-01 -1.3034679e-01  9.0137022e-03 -2.9014438e-01]]

Final Loss: 0.0002
Distance Metric: 7.0168
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 1999

================================================================================

multiChannelCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.03403428 -0.02842035 -0.04482016 ... -0.02516019  0.01152553
   0.01508673]
 [-0.0110958   0.00032757  0.02341376 ...  0.00610169 -0.0492529
  -0.02528499]
 [-0.02051483  0.01603308  0.00880856 ...  0.00273801  0.05734098
   0.01695975]
 ...
 [ 0.04946141  0.03421367 -0.00601133 ...  0.01928235 -0.0244297
   0.03873555]
 [-0.04085709 -0.01392676 -0.01625999 ...  0.05248535 -0.00546927
  -0.0360682 ]
 [-0.00439586 -0.02122939  0.01943641 ... -0.02150762  0.0168648
  -0.03305271]]
layers.1.weight: [[ 0.04164244  0.04142556 -0.01444217 ... -0.01777209 -0.0471661
  -0.01270471]
 [ 0.01642668  0.02831162 -0.04769519 ... -0.04262215 -0.00873379
  -0.00447426]
 [-0.03644348  0.0176701   0.04382674 ... -0.01725657  0.03956921
   0.00652748]
 ...
 [ 0.04397062  0.00765574  0.02695978 ... -0.00403878 -0.02065071
  -0.02169547]
 [-0.0350085  -0.02163109 -0.02068269 ... -0.01432023  0.02646274
   0.02392962]
 [ 0.04613296  0.01948343  0.02025476 ...  0.03976754 -0.04539303
  -0.03096791]]
layers.2.weight: [[-0.01066319 -0.05228544 -0.12829423  0.05869676  0.1175155   0.14226024
  -0.03643445  0.01457398  0.14061241 -0.06711823  0.0628164   0.03702008
   0.10440195 -0.03483143 -0.18593058  0.09554689 -0.09215686  0.18230274
  -0.06588143 -0.03899354 -0.0302562  -0.03967013  0.11841873  0.13692713
   0.07086679  0.14922488  0.12620081 -0.07635567 -0.06869743  0.03412747
   0.01312717  0.01730526]]

Final Loss: 0.0000
Distance Metric: 5.1909
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 5
stopped after epoch: 1999

================================================================================

