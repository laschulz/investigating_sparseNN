Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.10649966  0.10134845 -0.01128256]]

 [[-0.0025161   0.03368366  0.05291212]]

 [[ 0.04677701  0.01937879 -0.10814954]]

 [[ 0.04240735  0.02341017  0.10762463]]]
layers.1.weight: [[[-0.07988058  0.01762322]
  [ 0.02358116  0.04571449]
  [ 0.08080366  0.09313419]
  [ 0.03408349 -0.07868686]]

 [[ 0.07561999 -0.00228277]
  [-0.01924186  0.10442666]
  [ 0.08085974 -0.01771602]
  [-0.0770553   0.09020274]]

 [[-0.08428332 -0.02215911]
  [ 0.02794121  0.04631669]
  [-0.06616814 -0.0932852 ]
  [ 0.02936697 -0.0187903 ]]

 [[ 0.11543393  0.01986997]
  [-0.06525016 -0.02224966]
  [-0.1089294   0.11452335]
  [ 0.00319116 -0.10505389]]]
layers.2.weight: [[[ 0.00446768 -0.14459378]
  [ 0.030365   -0.00809362]
  [ 0.07782461  0.09186557]
  [ 0.04048548 -0.08664494]]]

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.01029352 -0.02936237  0.02063817 ...  0.01036328 -0.02885606
  -0.01686091]
 [-0.02244735 -0.00073174 -0.01622884 ...  0.00931571 -0.01265735
  -0.00356099]
 [ 0.0109672   0.00978897 -0.00513928 ... -0.00312718 -0.02023
   0.02054323]
 ...
 [ 0.01857671  0.02586135 -0.00021625 ...  0.02381182  0.01161289
  -0.01239451]
 [ 0.00463179 -0.00885765  0.00934083 ...  0.02031936  0.00244289
  -0.01417978]
 [ 0.02522412 -0.0169718  -0.00146995 ... -0.01178127 -0.02501962
  -0.02399242]]
layers.1.weight: [[ 0.02589911  0.01859928  0.01112219 ... -0.02761248  0.02438523
  -0.00354358]
 [-0.01285359 -0.00295063  0.00308622 ...  0.0200566   0.01335826
  -0.00641502]
 [-0.00179722  0.01721435  0.007019   ...  0.02805222  0.00536017
   0.01524344]
 ...
 [-0.0273255  -0.00386154  0.01333314 ... -0.02816948  0.01968754
   0.01903586]
 [ 0.02112525  0.01996838  0.         ... -0.02430885  0.00505468
  -0.00620621]
 [ 0.01961676 -0.00777181  0.00798324 ... -0.00649583  0.01857725
   0.00372503]]
layers.2.weight: [[ 0.02406219  0.02477734 -0.04390863 -0.04707321  0.01320992  0.05832436
   0.07296357  0.03848363  0.04687478  0.00061208  0.06543952 -0.02071961
   0.00468941 -0.08457755 -0.01225377 -0.0335752  -0.04433525  0.06183087
  -0.05404983 -0.00180762  0.06445581 -0.04242643  0.00892307  0.0235003
   0.04897621 -0.04400209 -0.06507081 -0.01829128  0.02529904 -0.04322856
   0.05797464 -0.08293678]]

Final Loss: 0.0000
Distance Metric: 3.1462
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 1999

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.09049487 -0.03824842 -0.32820708 ...  0.14730687 -0.21029949
   0.07317246]
 [-0.14432518 -0.14908615 -0.19359182 ...  0.1271077   0.07580838
  -0.30815166]
 [-0.2766302  -0.19865923 -0.00753753 ...  0.03501308  0.17416959
  -0.0563136 ]
 ...
 [-0.37750682  0.07324454 -0.03758725 ...  0.00057015  0.08874671
  -0.2739896 ]
 [ 0.11546326 -0.22657062  0.29674396 ...  0.0811877   0.22574045
  -0.15812199]
 [-0.00629922  0.17157862 -0.14562614 ...  0.21300124 -0.12952846
   0.05518153]]
layers.1.weight: [[-0.0618486  -0.00837643  0.00260925 ... -0.12873957  0.09111857
  -0.16170293]
 [-0.04110256  0.2738207  -0.09634537 ... -0.31939608 -0.11549788
   0.24687502]
 [ 0.09735313 -0.28388405  0.01272957 ... -0.0098194   0.14817433
   0.11370668]
 ...
 [-0.24211381 -0.02391783  0.40439177 ...  0.01766933 -0.04158599
  -0.01251668]
 [ 0.2581042   0.4237088   0.125127   ...  0.06574931  0.25964755
  -0.1129453 ]
 [-0.08905511 -0.02853542 -0.08554062 ...  0.05501332  0.2069041
  -0.30975717]]
layers.2.weight: [[ 0.0856422   0.09666096 -0.31544483 -0.22445546  0.09437096  0.09777364
   0.11898828 -0.20431295 -0.1444117  -0.14039038 -0.21318108  0.09572425
   0.10219589 -0.11257255  0.09793162  0.10306417 -0.10071906  0.10574844
  -0.1445945  -0.3242329  -0.29077533  0.1026664   0.10653522 -0.10246529
   0.26281258 -0.2709     -0.08554922  0.11410384  0.10171156 -0.33429676
  -0.2615585   0.10055182]]

Final Loss: 0.0067
Distance Metric: 25.9057
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 1999

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.00570069  0.01462168  0.0141257  ... -0.0239507  -0.00082446
   0.0305132 ]
 [ 0.00971782 -0.03692534  0.0364985  ...  0.02558872 -0.00419844
   0.01356134]
 [ 0.02640064  0.01924441 -0.00870127 ... -0.03421405  0.00230558
   0.01906189]
 ...
 [-0.02071572  0.0286637  -0.0144791  ... -0.01966015 -0.00606008
  -0.03192434]
 [-0.02116146  0.01942677 -0.02453462 ...  0.03362016 -0.01703869
  -0.02022796]
 [ 0.00623695  0.02514424  0.02013765 ... -0.03538049  0.00674411
  -0.03659048]]
layers.1.weight: [[-0.0341624   0.02914022  0.03648144 ...  0.03190088  0.01347579
   0.01761585]
 [ 0.0419722  -0.02303895  0.03614804 ...  0.02241882  0.00532267
  -0.00554281]
 [ 0.04207882  0.00913868 -0.04531578 ... -0.02964651 -0.02523626
  -0.04575825]
 ...
 [-0.0401024  -0.04278391 -0.03261094 ... -0.04313253  0.02349125
   0.01038938]
 [-0.03175627  0.03768466  0.01273715 ...  0.00213964  0.00137142
   0.05868369]
 [ 0.01927835  0.01219071  0.         ... -0.00731443  0.01988905
   0.03458665]]
layers.2.weight: [[-0.0052289  -0.00922272  0.00707505 -0.00786842 -0.00232167 -0.00837088
   0.01315629 -0.00090365  0.00773436  0.01654352  0.00126457 -0.00201133
  -0.00922741  0.00307456 -0.00850873 -0.00308424 -0.01840213  0.00864552
  -0.01575642  0.00390967 -0.00185268 -0.00271026  0.00688164 -0.0096677
  -0.00518365  0.00558826  0.0044556  -0.00793484 -0.00801939  0.00835076
   0.01173304  0.00016384]]

Final Loss: 0.1938
Distance Metric: 4.2289
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 168

================================================================================

multiChannelCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.02002393 -0.02249914  0.00675502 ... -0.01392109 -0.00115202
  -0.02137809]
 [-0.01559306 -0.02827941 -0.0234214  ... -0.00645942 -0.00015658
   0.02412131]
 [ 0.0078227   0.00217541 -0.00612915 ... -0.01857031 -0.02020886
   0.02244023]
 ...
 [ 0.00838599 -0.01237542 -0.02308892 ...  0.00698983  0.02359023
   0.02236017]
 [-0.00912297  0.00487459  0.02944006 ... -0.02792745 -0.00122009
   0.01528447]
 [ 0.01078327 -0.00919944 -0.00444323 ...  0.01947207  0.02033998
   0.01613241]]
layers.1.weight: [[ 0.02518392  0.03125074  0.00579325 ...  0.01489609  0.02456799
   0.00161513]
 [ 0.02836325  0.02262505  0.01575936 ...  0.03233643  0.02934684
  -0.01457875]
 [-0.00331162 -0.01436342  0.03006521 ...  0.02150306 -0.00505233
  -0.01324256]
 ...
 [-0.00234     0.00627037 -0.00494139 ...  0.01928162 -0.02038365
  -0.01533088]
 [ 0.00849823  0.00538786  0.01200698 ...  0.02184272  0.02616134
   0.02562541]
 [-0.00460905  0.00055656  0.00610772 ...  0.00250941  0.01426305
   0.00897114]]
layers.2.weight: [[-0.23983799 -0.3648713  -0.1772017  -0.30989653 -0.19193806 -0.323478
  -0.18581066 -0.38561714 -0.31493473 -0.2622172  -0.21320905 -0.16294765
  -0.17893063 -0.40607893 -0.30011    -0.28703243 -0.38323376 -0.373516
  -0.3207055  -0.3061733  -0.21380362 -0.240584   -0.35500255 -0.16129175
  -0.17331012 -0.37094256 -0.24103957 -0.20378345 -0.20259404 -0.32764095
  -0.3785656  -0.26979876]]

Final Loss: 0.0000
Distance Metric: 5.4891
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 1999

================================================================================

multiChannelCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-0.00780145 -0.01250276  0.00500142 ...  0.0234962  -0.01481025
  -0.02972939]
 [-0.00781634  0.02409351 -0.00427526 ... -0.02554335  0.00692934
   0.00863137]
 [-0.01608036 -0.01567123  0.01790706 ...  0.01421085  0.02082942
  -0.01579972]
 ...
 [-0.01318163 -0.00608258  0.01231066 ...  0.01089206  0.00255067
   0.01695432]
 [-0.01489724  0.0089269  -0.01960973 ... -0.00743644 -0.03652101
  -0.01008277]
 [-0.01675197  0.00152101 -0.00636492 ... -0.01157263 -0.0014424
  -0.00590243]]
layers.1.weight: [[ 0.09988451  0.05541725 -0.04639718 ...  0.10188339  0.07778949
  -0.05755027]
 [-0.022253    0.07412982  0.08952434 ... -0.01297548 -0.00042408
   0.00149339]
 [ 0.01971802  0.06385621  0.0065193  ...  0.03390948 -0.06022866
  -0.01848428]
 ...
 [ 0.01463296 -0.06402647 -0.06468178 ...  0.07820956 -0.06703894
   0.0414987 ]
 [ 0.00232977  0.02323761  0.04377374 ...  0.11082692  0.02316143
  -0.01247768]
 [ 0.0016901  -0.01828287  0.05665893 ... -0.09021457  0.04768709
  -0.03783428]]
layers.2.weight: [[-0.31564027  0.29266924  0.44661167 -0.09647777 -0.25951365 -0.3046438
  -0.21360375  0.05656628  0.04290832 -0.40512404 -0.33716655  0.07108283
  -0.15469244  0.4971526   0.31090882  0.2524927  -0.07483798  0.29955867
  -0.2454032  -0.33467472 -0.42657718 -0.24982132  0.12711243 -0.5028458
  -0.48048675  0.00221679  0.45321974 -0.27223122  0.14226606  0.04329121
   0.18756984 -0.48442724]]

Final Loss: 0.0000
Distance Metric: 7.4672
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 1999

================================================================================

multiChannelCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.00228997 -0.00092235  0.01035333 ... -0.08254454 -0.02370486
   0.01349742]
 [-0.04937359 -0.01280386  0.00396307 ...  0.09581167  0.03574997
  -0.0508673 ]
 [ 0.00795616  0.02594602  0.00562685 ...  0.02360111 -0.00619731
  -0.01123896]
 ...
 [ 0.11227445  0.02034765 -0.0557994  ... -0.25128812 -0.02358101
   0.12727849]
 [-0.15010047 -0.04842012  0.12142412 ...  0.4470185   0.05993036
  -0.23035961]
 [ 0.00312224  0.01413823  0.0297074  ...  0.03725316  0.03349299
  -0.03624426]]
layers.1.weight: [[ 0.00587973 -0.06186352 -0.03696923 ...  0.06888147 -0.19754514
  -0.0380287 ]
 [ 0.02709139 -0.06074546 -0.03203412 ...  0.09359923 -0.19711939
  -0.05806584]
 [-0.01098097 -0.06163956 -0.06377342 ...  0.09728344 -0.21109417
  -0.01796806]
 ...
 [ 0.02399047 -0.02544799 -0.01715448 ...  0.09596487 -0.17523056
  -0.06554085]
 [-0.01613316 -0.01756103 -0.01002309 ...  0.05974778 -0.1353673
  -0.05696866]
 [ 0.02943618 -0.06881509 -0.06564788 ...  0.11679298 -0.22171377
  -0.0399404 ]]
layers.2.weight: [[-0.7651064  -0.73496944 -0.78458935 -0.33198315 -0.37285888 -0.47492674
  -0.2834588  -0.3483269  -0.646032   -0.33859926 -0.90042937 -0.5937295
  -0.72438496 -0.3344444  -0.25128245 -0.40167487 -0.72206944 -0.842501
  -0.34442863 -0.84122217 -0.689494   -0.17360923 -0.3378524  -0.9090205
  -0.5368095  -0.32861203 -0.86812854 -0.6510646  -0.9016167  -0.7128492
  -0.4608963  -1.0467143 ]]

Final Loss: 0.0004
Distance Metric: 14.7034
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 1999

================================================================================

multiChannelCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-0.00739745 -0.01757418  0.02629646 ... -0.0075881  -0.01596847
   0.00319243]
 [-0.00137256 -0.00383409 -0.00378552 ... -0.00349598  0.00421715
   0.00309801]
 [ 0.01403942  0.00259179 -0.0057978  ...  0.00823527  0.00335146
  -0.00126909]
 ...
 [ 0.00285008 -0.00108085  0.01252026 ...  0.01525732  0.00990784
   0.01461414]
 [-0.01169002 -0.00256186  0.00063084 ...  0.00974975 -0.00215809
   0.01679298]
 [ 0.00169056  0.00230663  0.01665722 ... -0.00422124  0.00026571
  -0.00539576]]
layers.1.weight: [[-0.02028014  0.08002035 -0.03955885 ... -0.01621351 -0.02695027
   0.0242283 ]
 [-0.00438505  0.05367114 -0.02793574 ... -0.05042959 -0.02254019
  -0.01360078]
 [-0.00053963 -0.06464982 -0.0262791  ... -0.03690033 -0.01710463
   0.04976663]
 ...
 [-0.10596666 -0.07619745  0.00060561 ...  0.04879137  0.00906894
  -0.10848386]
 [-0.03567971 -0.01381856 -0.11074505 ...  0.08060651  0.07674693
  -0.05244085]
 [-0.02508523  0.00937579  0.03317584 ... -0.01976047 -0.01142631
  -0.02457426]]
layers.2.weight: [[ 0.52830845  0.23776534 -0.2064619   0.13402194  0.00666421  0.14637877
   0.2020099  -0.00758516  0.0288346   0.01753202 -0.11758406 -0.42376816
   0.31976253  0.5186164  -0.04180979 -0.20424657 -0.04673336 -0.12674399
  -0.01857786 -0.15493143  0.05846744 -0.07612176 -0.18975139 -0.2846134
   0.19638988  0.04085903 -0.1512936  -0.15302116  0.02169178 -0.01034764
   0.16692151  0.42277634]]

Final Loss: 0.0002
Distance Metric: 6.7251
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 1999

================================================================================

multiChannelCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.0134666  -0.03307005  0.01955665 ... -0.00267868 -0.02788461
   0.04750647]
 [ 0.          0.02718214  0.0109835  ... -0.00158526 -0.0062814
   0.00793463]
 [-0.03932748  0.00504085  0.01509266 ... -0.01459036 -0.02977558
   0.03602229]
 ...
 [ 0.00900565 -0.03384334 -0.01753656 ... -0.04399969 -0.02768312
  -0.02280024]
 [ 0.02570254 -0.01065969 -0.0237274  ... -0.03546743  0.02816566
   0.01717321]
 [-0.00922201  0.01675778 -0.04906337 ... -0.02280723 -0.03975938
  -0.02374969]]
layers.1.weight: [[ 0.01137256  0.03308797  0.03200063 ... -0.01933426 -0.03596588
  -0.01657277]
 [-0.03794875  0.01895658  0.00651446 ... -0.00274325 -0.01923409
  -0.02128249]
 [-0.01860705  0.03934317 -0.00961061 ... -0.02447444 -0.00181547
  -0.02096469]
 ...
 [ 0.04882192  0.03172457  0.02245339 ... -0.03313877 -0.011249
  -0.03707941]
 [-0.00509848 -0.03041373  0.03891206 ...  0.02921305 -0.02702588
  -0.01346101]
 [ 0.01374197  0.01642009  0.04892713 ... -0.04031118  0.00905087
   0.0204918 ]]
layers.2.weight: [[-0.06839574 -0.12892559 -0.05248126  0.03195347  0.06155751 -0.0984704
  -0.04926672  0.02990549 -0.08734759 -0.01357255 -0.14262389  0.06495593
  -0.0243086  -0.14232564  0.10439612  0.01088191  0.07446084  0.08907937
  -0.00322627 -0.11026073 -0.08082747  0.14468254  0.07356651  0.13083814
  -0.02393072  0.13491371 -0.00928674  0.05770326 -0.06050549 -0.12809655
   0.13379474 -0.12694019]]

Final Loss: 0.0000
Distance Metric: 5.0685
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 1999

================================================================================

