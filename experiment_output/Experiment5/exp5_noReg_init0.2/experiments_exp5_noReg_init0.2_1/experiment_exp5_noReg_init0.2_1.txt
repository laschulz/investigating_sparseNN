Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.10649966  0.10134845 -0.01128256]]

 [[-0.0025161   0.03368366  0.05291212]]

 [[ 0.04677701  0.01937879 -0.10814954]]

 [[ 0.04240735  0.02341017  0.10762463]]]
layers.1.weight: [[[-0.07988058  0.01762322]
  [ 0.02358116  0.04571449]
  [ 0.08080366  0.09313419]
  [ 0.03408349 -0.07868686]]

 [[ 0.07561999 -0.00228277]
  [-0.01924186  0.10442666]
  [ 0.08085974 -0.01771602]
  [-0.0770553   0.09020274]]

 [[-0.08428332 -0.02215911]
  [ 0.02794121  0.04631669]
  [-0.06616814 -0.0932852 ]
  [ 0.02936697 -0.0187903 ]]

 [[ 0.11543393  0.01986997]
  [-0.06525016 -0.02224966]
  [-0.1089294   0.11452335]
  [ 0.00319116 -0.10505389]]]
layers.2.weight: [[[ 0.00446768 -0.14459378]
  [ 0.030365   -0.00809362]
  [ 0.07782461  0.09186557]
  [ 0.04048548 -0.08664494]]]

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.01029352 -0.02936237  0.02063817 ...  0.01036328 -0.02885606
  -0.01686091]
 [-0.02244735 -0.00073174 -0.01622884 ...  0.00931571 -0.01265735
  -0.00356099]
 [ 0.0109672   0.00978897 -0.00513928 ... -0.00312718 -0.02023
   0.02054323]
 ...
 [ 0.01857671  0.02586135 -0.00021625 ...  0.02381182  0.01161289
  -0.01239451]
 [ 0.00463179 -0.00885765  0.00934083 ...  0.02031936  0.00244289
  -0.01417978]
 [ 0.02522412 -0.0169718  -0.00146995 ... -0.01178127 -0.02501962
  -0.02399242]]
layers.1.weight: [[ 0.02589911  0.01859928  0.01112219 ... -0.02761248  0.02438523
  -0.00354358]
 [-0.01285359 -0.00295063  0.00308622 ...  0.0200566   0.01335826
  -0.00641502]
 [-0.00179722  0.01721435  0.007019   ...  0.02805222  0.00536017
   0.01524344]
 ...
 [-0.0273255  -0.00386154  0.01333314 ... -0.02816948  0.01968754
   0.01903586]
 [ 0.02112525  0.01996838  0.         ... -0.02430885  0.00505468
  -0.00620621]
 [ 0.01961676 -0.00777181  0.00798324 ... -0.00649583  0.01857725
   0.00372503]]
layers.2.weight: [[ 0.02406219  0.02477734 -0.04390863 -0.04707321  0.01320992  0.05832436
   0.07296357  0.03848363  0.04687478  0.00061208  0.06543952 -0.02071961
   0.00468941 -0.08457755 -0.01225377 -0.0335752  -0.04433525  0.06183087
  -0.05404983 -0.00180762  0.06445581 -0.04242643  0.00892307  0.0235003
   0.04897621 -0.04400209 -0.06507081 -0.01829128  0.02529904 -0.04322856
   0.05797464 -0.08293678]]

Final Loss: 0.0000
Distance Metric: 3.1462
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 1999

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.09049487 -0.03824842 -0.32820708 ...  0.14730687 -0.21029949
   0.07317246]
 [-0.14432518 -0.14908615 -0.19359182 ...  0.1271077   0.07580838
  -0.30815166]
 [-0.2766302  -0.19865923 -0.00753753 ...  0.03501308  0.17416959
  -0.0563136 ]
 ...
 [-0.37750682  0.07324454 -0.03758725 ...  0.00057015  0.08874671
  -0.2739896 ]
 [ 0.11546326 -0.22657062  0.29674396 ...  0.0811877   0.22574045
  -0.15812199]
 [-0.00629922  0.17157862 -0.14562614 ...  0.21300124 -0.12952846
   0.05518153]]
layers.1.weight: [[-0.0618486  -0.00837643  0.00260925 ... -0.12873957  0.09111857
  -0.16170293]
 [-0.04110256  0.2738207  -0.09634537 ... -0.31939608 -0.11549788
   0.24687502]
 [ 0.09735313 -0.28388405  0.01272957 ... -0.0098194   0.14817433
   0.11370668]
 ...
 [-0.24211381 -0.02391783  0.40439177 ...  0.01766933 -0.04158599
  -0.01251668]
 [ 0.2581042   0.4237088   0.125127   ...  0.06574931  0.25964755
  -0.1129453 ]
 [-0.08905511 -0.02853542 -0.08554062 ...  0.05501332  0.2069041
  -0.30975717]]
layers.2.weight: [[ 0.0856422   0.09666096 -0.31544483 -0.22445546  0.09437096  0.09777364
   0.11898828 -0.20431295 -0.1444117  -0.14039038 -0.21318108  0.09572425
   0.10219589 -0.11257255  0.09793162  0.10306417 -0.10071906  0.10574844
  -0.1445945  -0.3242329  -0.29077533  0.1026664   0.10653522 -0.10246529
   0.26281258 -0.2709     -0.08554922  0.11410384  0.10171156 -0.33429676
  -0.2615585   0.10055182]]

Final Loss: 0.0067
Distance Metric: 25.9057
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 1999

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.00570069  0.01462168  0.0141257  ... -0.0239507  -0.00082446
   0.0305132 ]
 [ 0.00971782 -0.03692534  0.0364985  ...  0.02558872 -0.00419844
   0.01356134]
 [ 0.02640064  0.01924441 -0.00870127 ... -0.03421405  0.00230558
   0.01906189]
 ...
 [-0.02071572  0.0286637  -0.0144791  ... -0.01966015 -0.00606008
  -0.03192434]
 [-0.02116146  0.01942677 -0.02453462 ...  0.03362016 -0.01703869
  -0.02022796]
 [ 0.00623695  0.02514424  0.02013765 ... -0.03538049  0.00674411
  -0.03659048]]
layers.1.weight: [[-0.0341624   0.02914022  0.03648144 ...  0.03190088  0.01347579
   0.01761585]
 [ 0.0419722  -0.02303895  0.03614804 ...  0.02241882  0.00532267
  -0.00554281]
 [ 0.04207882  0.00913868 -0.04531578 ... -0.02964651 -0.02523626
  -0.04575825]
 ...
 [-0.0401024  -0.04278391 -0.03261094 ... -0.04313253  0.02349125
   0.01038938]
 [-0.03175627  0.03768466  0.01273715 ...  0.00213964  0.00137142
   0.05868369]
 [ 0.01927835  0.01219071  0.         ... -0.00731443  0.01988905
   0.03458665]]
layers.2.weight: [[-0.0052289  -0.00922272  0.00707505 -0.00786842 -0.00232167 -0.00837088
   0.01315629 -0.00090365  0.00773436  0.01654352  0.00126457 -0.00201133
  -0.00922741  0.00307456 -0.00850873 -0.00308424 -0.01840213  0.00864552
  -0.01575642  0.00390967 -0.00185268 -0.00271026  0.00688164 -0.0096677
  -0.00518365  0.00558826  0.0044556  -0.00793484 -0.00801939  0.00835076
   0.01173304  0.00016384]]

Final Loss: 0.1938
Distance Metric: 4.2289
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 168

================================================================================

multiChannelCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.02002393 -0.02249914  0.00675502 ... -0.01392109 -0.00115202
  -0.02137809]
 [-0.01559306 -0.02827941 -0.0234214  ... -0.00645942 -0.00015658
   0.02412131]
 [ 0.0078227   0.00217541 -0.00612915 ... -0.01857031 -0.02020886
   0.02244023]
 ...
 [ 0.00838599 -0.01237542 -0.02308892 ...  0.00698983  0.02359023
   0.02236017]
 [-0.00912297  0.00487459  0.02944006 ... -0.02792745 -0.00122009
   0.01528447]
 [ 0.01078327 -0.00919944 -0.00444323 ...  0.01947207  0.02033998
   0.01613241]]
layers.1.weight: [[ 0.02518392  0.03125074  0.00579325 ...  0.01489609  0.02456799
   0.00161513]
 [ 0.02836325  0.02262505  0.01575936 ...  0.03233643  0.02934684
  -0.01457875]
 [-0.00331162 -0.01436342  0.03006521 ...  0.02150306 -0.00505233
  -0.01324256]
 ...
 [-0.00234     0.00627037 -0.00494139 ...  0.01928162 -0.02038365
  -0.01533088]
 [ 0.00849823  0.00538786  0.01200698 ...  0.02184272  0.02616134
   0.02562541]
 [-0.00460905  0.00055656  0.00610772 ...  0.00250941  0.01426305
   0.00897114]]
layers.2.weight: [[-0.23983799 -0.3648713  -0.1772017  -0.30989653 -0.19193806 -0.323478
  -0.18581066 -0.38561714 -0.31493473 -0.2622172  -0.21320905 -0.16294765
  -0.17893063 -0.40607893 -0.30011    -0.28703243 -0.38323376 -0.373516
  -0.3207055  -0.3061733  -0.21380362 -0.240584   -0.35500255 -0.16129175
  -0.17331012 -0.37094256 -0.24103957 -0.20378345 -0.20259404 -0.32764095
  -0.3785656  -0.26979876]]

Final Loss: 0.0000
Distance Metric: 5.4891
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 1999

================================================================================

multiChannelCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-0.00780145 -0.01250276  0.00500142 ...  0.0234962  -0.01481025
  -0.02972939]
 [-0.00781634  0.02409351 -0.00427526 ... -0.02554335  0.00692934
   0.00863137]
 [-0.01608036 -0.01567123  0.01790706 ...  0.01421085  0.02082942
  -0.01579972]
 ...
 [-0.01318163 -0.00608258  0.01231066 ...  0.01089206  0.00255067
   0.01695432]
 [-0.01489724  0.0089269  -0.01960973 ... -0.00743644 -0.03652101
  -0.01008277]
 [-0.01675197  0.00152101 -0.00636492 ... -0.01157263 -0.0014424
  -0.00590243]]
layers.1.weight: [[ 0.09988451  0.05541725 -0.04639718 ...  0.10188339  0.07778949
  -0.05755027]
 [-0.022253    0.07412982  0.08952434 ... -0.01297548 -0.00042408
   0.00149339]
 [ 0.01971802  0.06385621  0.0065193  ...  0.03390948 -0.06022866
  -0.01848428]
 ...
 [ 0.01463296 -0.06402647 -0.06468178 ...  0.07820956 -0.06703894
   0.0414987 ]
 [ 0.00232977  0.02323761  0.04377374 ...  0.11082692  0.02316143
  -0.01247768]
 [ 0.0016901  -0.01828287  0.05665893 ... -0.09021457  0.04768709
  -0.03783428]]
layers.2.weight: [[-0.31564027  0.29266924  0.44661167 -0.09647777 -0.25951365 -0.3046438
  -0.21360375  0.05656628  0.04290832 -0.40512404 -0.33716655  0.07108283
  -0.15469244  0.4971526   0.31090882  0.2524927  -0.07483798  0.29955867
  -0.2454032  -0.33467472 -0.42657718 -0.24982132  0.12711243 -0.5028458
  -0.48048675  0.00221679  0.45321974 -0.27223122  0.14226606  0.04329121
   0.18756984 -0.48442724]]

Final Loss: 0.0000
Distance Metric: 7.4672
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 1
stopped after epoch: 1999

================================================================================

