Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[ 0.10138871  0.12347537 -0.01527199]]

 [[-0.03863862  0.06530841  0.0947862 ]]

 [[-0.01336188  0.11715259  0.04005697]]

 [[-0.09395319  0.03758994 -0.10775208]]]
layers.1.weight: [[[ 0.04220537  0.09167527]
  [ 0.12088863  0.10100019]
  [ 0.04561167  0.01077049]
  [-0.0121038  -0.01400608]]

 [[-0.05291196  0.03048319]
  [-0.0507781  -0.11232179]
  [ 0.01416082  0.0734018 ]
  [-0.07189618  0.09651808]]

 [[ 0.1146416  -0.01998444]
  [-0.06943803  0.03957031]
  [-0.06464462 -0.05948039]
  [-0.0503616   0.11749054]]

 [[-0.11236387  0.1175149 ]
  [ 0.01873045  0.12162876]
  [-0.06856444  0.00893614]
  [ 0.02055028  0.10986362]]]
layers.2.weight: [[[ 0.12473222  0.1072491 ]
  [-0.06120743  0.15107448]
  [-0.05102805 -0.07179496]
  [ 0.00038075 -0.02346915]]]

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.0182769   0.01717503  0.00110311 ... -0.01292796  0.0059992
   0.02020402]
 [ 0.0169725   0.00109184  0.0249301  ...  0.01664028  0.00113526
   0.0219381 ]
 [-0.01544016  0.01001924 -0.01164781 ... -0.0131154   0.00088473
  -0.01719736]
 ...
 [-0.00283198  0.01297927  0.00784541 ... -0.01195219 -0.01148014
   0.00449   ]
 [ 0.01106011 -0.02764747 -0.01850718 ... -0.02176011  0.0044707
  -0.0247216 ]
 [-0.00502771  0.02084166 -0.01334078 ... -0.01381606  0.02861994
  -0.01865099]]
layers.1.weight: [[-0.01816286  0.00742031  0.00123386 ...  0.01348632 -0.00351982
   0.01758335]
 [ 0.00113805  0.01143092  0.01707034 ... -0.02058177  0.02690915
  -0.00808415]
 [-0.0237994   0.01482313 -0.02004671 ... -0.0274933  -0.01974084
   0.01248662]
 ...
 [ 0.01133783 -0.02884832 -0.02641544 ...  0.00815152 -0.00258978
  -0.00493468]
 [-0.00337334 -0.01134366 -0.01088929 ... -0.00480211 -0.01894908
   0.01397791]
 [ 0.02775244 -0.02471791 -0.02277222 ... -0.02791671  0.01260974
   0.02791378]]
layers.2.weight: [[-0.01027236 -0.01837657 -0.03773535  0.03621044 -0.02327395  0.04166613
   0.02141012  0.06745451 -0.00541734  0.06616724 -0.06966033 -0.07357212
   0.01107284  0.06635516  0.03159065 -0.03987057 -0.0559464  -0.01701695
   0.02286968  0.03781449  0.06366554  0.01716067 -0.04597453  0.02554541
   0.01445301  0.01927332 -0.03934688  0.02895172  0.0250589  -0.02651337
   0.05643265  0.00294391]]

Final Loss: 0.0000
Distance Metric: 3.2238
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 1999

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-0.03410346  0.28242552  0.23059233 ... -0.00228324  0.0169002
   0.18534511]
 [ 0.01806473 -0.0112061   0.17672735 ... -0.15330268  0.08122291
   0.00359063]
 [-0.30425146  0.05096569  0.04250833 ...  0.35496032  0.05540235
   0.01919674]
 ...
 [-0.12100242  0.05394476  0.0004178  ... -0.04632975  0.08449566
  -0.05996653]
 [ 0.14919305 -0.05204037 -0.17016266 ... -0.01785117  0.09268912
   0.0472784 ]
 [ 0.11412166  0.18574359 -0.13832949 ...  0.14377694 -0.07967358
   0.08365258]]
layers.1.weight: [[-0.38615635 -0.02921112  0.12836    ...  0.1884957   0.14627467
  -0.12184175]
 [ 0.2870488   0.22144885 -0.00977748 ... -0.04810176 -0.09812718
   0.05284693]
 [ 0.07973123 -0.03975759 -0.09391028 ...  0.25635895  0.05049955
  -0.0894502 ]
 ...
 [-0.16584216  0.1576169  -0.06279282 ...  0.3854314   0.19086011
  -0.08154214]
 [-0.10275866 -0.06535333  0.0296787  ... -0.22002223  0.26504532
  -0.02486177]
 [ 0.05811194  0.03259819 -0.04984464 ...  0.00786959  0.00789458
  -0.3355284 ]]
layers.2.weight: [[ 0.10084699  0.09877928  0.10986473  0.13299806 -0.4016407  -0.09818669
   0.0932162  -0.22240072  0.09258172  0.09335084  0.10231849 -0.09918864
  -0.41764152 -0.09718055 -0.35190964 -0.10193728 -0.5187986   0.11069243
   0.10204185 -0.27843556  0.10003682  0.10370804  0.12016473 -0.21411093
  -0.47833237 -0.13024534 -0.21527383  0.09625377  0.10953564 -0.22401913
   0.09257121  0.18948337]]

Final Loss: 0.0063
Distance Metric: 25.6489
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 1999

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.03486346  0.03839602 -0.0131407  ...  0.03425028  0.03030966
  -0.02779798]
 [-0.04264731 -0.00708218  0.00733422 ... -0.02871322 -0.02274602
  -0.01399685]
 [ 0.0227075  -0.02717545  0.01636349 ...  0.01559407  0.01284447
   0.00816075]
 ...
 [ 0.02241638 -0.03326248 -0.03242188 ... -0.00428771 -0.00359066
   0.0260903 ]
 [-0.03436666 -0.03710571  0.03503774 ...  0.010836   -0.00379742
   0.03753553]
 [-0.02021957  0.01809799  0.0197768  ... -0.02909221  0.01455766
   0.00470876]]
layers.1.weight: [[-0.0174883   0.01036587 -0.04253111 ... -0.00486426 -0.00326489
   0.03491452]
 [-0.01466059 -0.0387268   0.03466287 ...  0.01572492  0.03645505
   0.01720302]
 [ 0.01768206 -0.00704893 -0.02153817 ... -0.01116554 -0.01915623
  -0.00902064]
 ...
 [ 0.02733208 -0.01123988 -0.03338429 ... -0.02222822 -0.02793629
  -0.02097571]
 [ 0.03741251  0.02970466 -0.03148238 ... -0.03140452 -0.04151826
  -0.03909408]
 [-0.04108462  0.00202418 -0.04735764 ... -0.00570726  0.0011657
   0.00301047]]
layers.2.weight: [[-0.00317997 -0.00884619  0.01042359 -0.00170215  0.0153073  -0.0080968
   0.00918737 -0.00500269 -0.00527256 -0.01069411 -0.0081867   0.00975271
   0.00054299 -0.00358533  0.00364627  0.00241403  0.01103446  0.00099541
  -0.00991224  0.00410069  0.01614278  0.01163417  0.01501652  0.00880302
  -0.00109867  0.00786772  0.00420378 -0.00431709 -0.01400705  0.00727903
  -0.0107056   0.00139961]]

Final Loss: 0.1848
Distance Metric: 4.3842
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 151

================================================================================

multiChannelCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.01502678 -0.00202309 -0.02005668 ...  0.07527246  0.05961206
   0.02625717]
 [-0.01997697  0.01660568 -0.01188012 ...  0.12908812  0.09290487
  -0.00982968]
 [ 0.03130086  0.00733094 -0.00163086 ... -0.07371198 -0.04249021
  -0.0191718 ]
 ...
 [-0.01623192  0.01500827 -0.01520792 ... -0.03000704 -0.02333008
   0.01817713]
 [-0.02019136 -0.01731814  0.01806445 ... -0.201451   -0.08751798
  -0.03873881]
 [ 0.00388469  0.02587641 -0.00540228 ... -0.21590358 -0.14534836
   0.00513458]]
layers.1.weight: [[ 0.01404126 -0.02170397  0.01223886 ...  0.01032491  0.00927973
   0.03516674]
 [-0.01953992 -0.02911394 -0.00329192 ...  0.02065633  0.01911797
   0.02303406]
 [-0.04598199 -0.06306779  0.03115305 ... -0.02124133  0.05162796
   0.01835557]
 ...
 [-0.00919284 -0.06000562  0.00400759 ...  0.01149314  0.02868681
   0.02139419]
 [-0.01531139 -0.01654648 -0.00080696 ...  0.01460262  0.03185599
   0.0251253 ]
 [-0.01904028 -0.03511996  0.01756297 ...  0.00445885  0.00311465
   0.04450506]]
layers.2.weight: [[-0.06833625 -0.29922542 -0.3382198  -0.4033202  -0.17852536 -0.2429983
  -0.35902542 -0.18838358 -0.4667184  -0.40369076 -0.48147735 -0.2950776
  -0.45072383  0.04795891 -0.2753074  -0.41523874 -0.4715071  -0.23108786
  -0.10233857 -0.35496235 -0.41809434 -0.43168256 -0.20305857 -0.05154908
  -0.55813867 -0.4933731  -0.4367992  -0.26354355 -0.42990762 -0.3668562
  -0.37317577 -0.32542142]]

Final Loss: 0.0000
Distance Metric: 8.3882
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 1999

================================================================================

multiChannelCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-0.00087164 -0.00912569  0.00439278 ...  0.00408312  0.00425898
   0.01143837]
 [-0.02869813 -0.00938952 -0.02329069 ...  0.00181732 -0.0224408
  -0.00980834]
 [-0.00575474  0.02136536 -0.01223486 ... -0.00339383 -0.03416314
  -0.01348191]
 ...
 [-0.01020142  0.00071841 -0.00198002 ... -0.02270604  0.01060241
  -0.00168267]
 [-0.00992538  0.02232042 -0.02669645 ...  0.00616341 -0.01029897
  -0.0112308 ]
 [-0.01233876 -0.00221954 -0.02693996 ...  0.01334466 -0.00575199
   0.00879857]]
layers.1.weight: [[-0.05355336  0.05094605 -0.01000988 ...  0.03502705  0.0212655
   0.03420606]
 [ 0.00688266 -0.01339724 -0.03345186 ... -0.06133265 -0.05220126
   0.01365445]
 [ 0.07291079 -0.01372832  0.04055998 ... -0.11018681 -0.08965618
   0.02470815]
 ...
 [ 0.06518274 -0.00195353 -0.02848503 ... -0.04429508 -0.00415338
   0.00529351]
 [ 0.02261213 -0.03753629  0.02209809 ... -0.02462707  0.0283049
  -0.0011633 ]
 [ 0.05776843 -0.03238476  0.01012716 ... -0.00277388  0.02659889
  -0.03098318]]
layers.2.weight: [[ 0.09093568  0.78922915  0.6759674  -0.2876089   0.3686634  -0.04902645
   0.4464429  -0.20015799  0.60818064 -0.40390748  0.29232883  0.3515966
   0.11268688 -0.76485485 -0.18113178 -0.2570857  -0.24885002  0.1669322
  -0.3915276   0.49665165  0.26999986  0.1295035  -0.57286125  0.2330925
  -0.20612544  0.29767027 -0.28245774  0.21784793 -0.37097195  0.05194062
  -0.34692216  0.261126  ]]

Final Loss: 0.0000
Distance Metric: 7.8017
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 1318

================================================================================

multiChannelCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.03830305 -0.02496369  0.0469924  ...  0.0167147   0.02826407
  -0.01601222]
 [ 0.0122646   0.00835717 -0.03441707 ... -0.00393756  0.02207276
   0.01039766]
 [ 0.02835736 -0.02528594  0.00993496 ... -0.03347595  0.03980178
  -0.05014419]
 ...
 [-0.03996988  0.02404475 -0.04411688 ... -0.02839288  0.02406702
  -0.02600306]
 [-0.02684064 -0.0478451   0.02985342 ...  0.03246811 -0.03594963
  -0.01083605]
 [ 0.04323852  0.01784143 -0.01050164 ... -0.00882891  0.00547544
  -0.01763754]]
layers.1.weight: [[ 0.03673174 -0.02240972  0.03507014 ... -0.04384427 -0.0031129
   0.01516877]
 [-0.01018941  0.00931439  0.00878985 ... -0.01363484 -0.00276047
   0.01687238]
 [ 0.00671104  0.01238225  0.01196385 ... -0.01215064 -0.01012979
   0.0145013 ]
 ...
 [ 0.04403239 -0.01827412  0.01251862 ...  0.03602228  0.03867596
   0.02429029]
 [ 0.00766453  0.02202881 -0.00783832 ...  0.04158888  0.04161615
  -0.0239797 ]
 [-0.02502912 -0.02297312  0.04601813 ...  0.03247358  0.0151218
  -0.03692649]]
layers.2.weight: [[-0.08918059  0.06726792 -0.07613099 -0.13042095  0.04469941  0.13208692
   0.1400643   0.02071915  0.04197719  0.1263252   0.04709231 -0.09207061
  -0.09257182  0.05121853  0.13452335 -0.13304079 -0.05606749 -0.07187962
   0.11054583 -0.08426887 -0.0079353   0.09368604 -0.12586     0.12913147
  -0.10712258 -0.12243917 -0.02246624  0.04326     0.12750319  0.11612048
  -0.04365677 -0.08909063]]

Final Loss: 0.0000
Distance Metric: 5.0072
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 1999

================================================================================

multiChannelCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.12470005  0.03373052  0.06109735 ...  0.11849282  0.05176276
  -0.04426388]
 [ 0.03591816 -0.01320643 -0.0473429  ... -0.07394851 -0.04301812
   0.00522026]
 [ 0.08790296 -0.03063763 -0.05167992 ... -0.04596562 -0.00624901
   0.02586081]
 ...
 [ 0.50258446 -0.08940747 -0.41104662 ... -0.39232403 -0.1374249
   0.12080374]
 [-0.28891405  0.00186946  0.23632574 ...  0.24457492  0.08239596
  -0.03441622]
 [-0.08510656  0.01835247  0.07113827 ...  0.04682666  0.03411033
  -0.01121985]]
layers.1.weight: [[ 5.94936032e-03 -3.46496254e-02 -6.82270452e-02 ... -1.73205554e-01
   6.70707896e-02  2.24488117e-02]
 [ 2.32664105e-02 -7.32959807e-02 -2.44329590e-02 ... -2.18536198e-01
   1.23845249e-01  2.37536021e-02]
 [ 2.66609453e-02 -7.85476808e-03 -1.53593635e-02 ... -1.51299639e-02
   2.51185987e-03  7.55568920e-03]
 ...
 [ 3.27951908e-02 -1.91798005e-02 -2.91961823e-02 ... -4.93729189e-02
   7.60868285e-03 -3.15102166e-03]
 [ 7.12777451e-02 -3.56305912e-02 -7.46133402e-02 ... -2.94029564e-01
   1.10603176e-01 -3.12014902e-03]
 [-1.84430057e-04 -4.45814915e-02 -7.59797767e-02 ... -2.03890949e-01
   7.95251280e-02  1.35237090e-02]]
layers.2.weight: [[-0.7464188  -0.9831849  -0.19218202 -0.71274185 -0.27546373 -1.000029
  -0.2750368  -1.0625391  -1.0700439  -1.1652918  -1.0001522  -0.3321205
  -0.3683067  -0.9690686  -0.33182257 -0.3381532  -0.2392382  -0.576272
  -1.0060858  -0.6015975  -0.15125129 -0.32105863 -0.3262489  -0.34744143
  -0.35380423 -0.34120187 -0.34311214 -0.7320105  -1.0000302  -0.33357117
  -1.1750145  -0.84690934]]

Final Loss: 0.0012
Distance Metric: 16.6242
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 1999

================================================================================

multiChannelCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[-0.00499154  0.01543784  0.00666547 ... -0.0118675  -0.00418434
   0.00207216]
 [ 0.0142593   0.00148117 -0.00790849 ... -0.00929464 -0.00057735
   0.00624292]
 [-0.02784522  0.02383699 -0.00297722 ...  0.01269112  0.01651188
  -0.00167697]
 ...
 [-0.02655895  0.00183411  0.01352728 ...  0.01164357  0.01465121
  -0.00230028]
 [ 0.02896658  0.00081561 -0.02906634 ... -0.02532679 -0.00895455
   0.01067732]
 [ 0.          0.00843732 -0.00657675 ...  0.02248998 -0.01710015
  -0.00581721]]
layers.1.weight: [[-0.01652111  0.01886565  0.00543775 ...  0.0023354   0.01229471
  -0.07705794]
 [ 0.03995364  0.0011903   0.00945367 ... -0.04213427 -0.03082373
  -0.0476135 ]
 [-0.00724408 -0.01968378  0.0216489  ...  0.04065841  0.0483282
   0.02862968]
 ...
 [-0.08304632  0.033702    0.02110702 ...  0.10652979  0.08140744
   0.06403799]
 [ 0.00182731 -0.07530049  0.0371438  ...  0.05127652  0.03992392
   0.00188128]
 [-0.00459064  0.04133927 -0.00706905 ...  0.07697493  0.00629554
  -0.02459626]]
layers.2.weight: [[ 0.23378755  0.0801755   0.41411456  0.14223923 -0.5842741  -0.0863972
   0.01836393 -0.08124053  0.00919628  0.02415755  0.44694093 -0.18045887
  -0.37219903 -0.01522124 -0.618375   -0.05087832 -0.6863347   0.27214646
   0.01709645 -0.34302408  0.06802374  0.7366602   0.6801652  -0.28119346
  -0.52029383 -0.0242538  -0.1500847   0.03455635  0.5589348  -0.29353818
   0.2888327   0.34824327]]

Final Loss: 0.0011
Distance Metric: 7.5478
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 1999

================================================================================

multiChannelCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.04452806  0.04436605 -0.03664816 ...  0.035515    0.02836745
  -0.0279908 ]
 [-0.04140472 -0.00912846  0.00455474 ... -0.04492475 -0.04470078
  -0.01034142]
 [ 0.03159373 -0.03032325  0.0095961  ...  0.02624341  0.02665657
   0.0169149 ]
 ...
 [ 0.03256749 -0.0569326  -0.04950321 ...  0.00330601 -0.00950632
   0.02663304]
 [-0.09480869 -0.06327424  0.04347933 ...  0.00331478  0.00865491
   0.03900411]
 [-0.03384218  0.02443721  0.03975498 ... -0.05608223  0.03681308
   0.03764451]]
layers.1.weight: [[-0.02370217  0.01211201 -0.03980179 ... -0.00064591 -0.00278496
   0.02812126]
 [-0.0187509  -0.04506899  0.04715079 ...  0.01527188  0.03643398
   0.01192419]
 [ 0.02418526 -0.0063396  -0.03227894 ... -0.01149246 -0.02992
  -0.00151331]
 ...
 [ 0.03207864 -0.01323677 -0.03734255 ... -0.02611696 -0.02567329
  -0.01275263]
 [ 0.037306    0.02905073 -0.02432936 ... -0.03023196 -0.04578302
  -0.05273557]
 [-0.04238854  0.00035434 -0.04802332 ... -0.01529741 -0.00366899
   0.0072158 ]]
layers.2.weight: [[-0.07390367 -0.14575261  0.16869189 -0.06060777  0.16376013 -0.15845968
   0.15012352 -0.13265498 -0.19923699 -0.16634586 -0.11668753  0.11801876
   0.03511908 -0.00098747  0.10121369  0.01242806  0.17822239  0.00035624
  -0.07393638  0.02805916  0.12339498  0.15755954  0.13389844  0.08324935
   0.04734145  0.17868462  0.08553983 -0.01132791 -0.0889724   0.13486397
  -0.15895537 -0.0298251 ]]

Final Loss: 0.0000
Distance Metric: 5.4005
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 4
stopped after epoch: 1999

================================================================================

