Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.78 -0.12  0.7 ]]

 [[-1.16  0.47  0.05]]

 [[-0.73  1.96 -1.01]]

 [[-0.32  0.21  0.63]]]
layers.1.weight: [[[ 0.    0.04]
  [ 0.68  0.34]
  [ 0.54 -0.22]
  [-0.14 -0.33]]

 [[-0.14  1.59]
  [ 1.48 -0.52]
  [-1.26  0.3 ]
  [-0.4  -1.09]]

 [[-0.71  0.44]
  [-0.02 -0.14]
  [ 0.37 -0.7 ]
  [-0.83 -0.38]]

 [[ 0.89 -0.48]
  [-0.27 -0.81]
  [ 1.76 -0.41]
  [ 0.15  0.49]]]
layers.2.weight: [[[-0.54  0.16]
  [-0.74 -0.46]
  [ 0.08  0.18]
  [-0.22  0.81]]]

================================================================================

overlappingCNN_sigmoid -> fcnn_decreasing_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.01477749 -0.00091992 -0.00198683 ...  0.01173374 -0.00605728
   0.00193906]
 [ 0.03896849 -0.00245353 -0.00523456 ...  0.03085716 -0.01597078
   0.00510933]
 [ 0.06072408 -0.00395386 -0.00811852 ...  0.04792003 -0.02490423
   0.00793173]
 ...
 [-0.01315697  0.00080805  0.00177675 ... -0.01043604  0.00538813
  -0.00172766]
 [ 0.03884056 -0.00245957 -0.00520925 ...  0.03075694 -0.01591106
   0.00508295]
 [ 0.09134928 -0.00632686 -0.01215879 ...  0.0715497  -0.03750035
   0.0119041 ]]
layers.1.weight: [[ 0.0012803   0.00340625  0.00531448 ... -0.00119106  0.00339906
   0.00797468]
 [ 0.00086654  0.00236105  0.00368259 ... -0.00084034  0.00234883
   0.0055472 ]
 [-0.00255036 -0.00665349 -0.01033402 ...  0.0022207  -0.00663689
  -0.0154506 ]
 ...
 [ 0.00319946  0.00846444  0.01316354 ... -0.00287219  0.00842692
   0.01968279]
 [ 0.0049309   0.0130034   0.02021182 ... -0.0043986   0.01295541
   0.03023042]
 [-0.00386028 -0.01014014 -0.01575278 ...  0.00341302 -0.01010121
  -0.02356319]]
layers.2.weight: [[ 0.09615059  0.06701339 -0.18536742 -0.275852    0.30382758 -0.28336522
   0.01011018  0.42038587  0.13594948 -0.44860137  0.52817106 -0.20720014
   0.00997748 -0.19682574 -0.08015315  0.11233391 -0.05388997 -0.10253324
  -0.206761    0.39376202 -0.45414189  0.21517874 -0.2665724   0.34400544
  -0.27927256 -0.17345937  0.07542733 -0.3544607  -0.45216075  0.23697618
   0.36427537 -0.28327242]]

Final Loss: 0.0001
Distance Metric: 8.6018
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 1038

================================================================================

overlappingCNN_sigmoid -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.00010225 -0.00013721  0.          0.          0.         -0.00012211
   0.          0.          0.         -0.00011328  0.          0.
  -0.00017434  0.          0.          0.          0.          0.
   0.00013188  0.          0.          0.          0.          0.
   0.00013437 -0.00013951 -0.00014339  0.          0.          0.
   0.          0.        ]]

Final Loss: 0.1686
Distance Metric: 8.3517
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 1045

================================================================================

overlappingCNN_sigmoid -> fcnn_decreasing_tanh

Student Model Parameters:
layers.0.weight: [[-1.3813873e-04  1.9818181e-04 -2.1693292e-04 ...  0.0000000e+00
   0.0000000e+00 -1.1567466e-04]
 [ 3.8934457e-01  1.7706829e-01  5.9296537e-02 ...  3.9153671e-01
  -2.0693325e-01  3.8843754e-01]
 [ 5.9829390e-04 -8.8819768e-04  9.8692509e-04 ...  2.0097803e-04
   4.3100346e-04  5.1421672e-04]
 ...
 [-7.5909769e-04  1.0265982e-03 -1.0381908e-03 ... -1.7422432e-04
  -5.2112760e-04 -6.5836171e-04]
 [-1.2829723e-03  1.8643971e-03 -1.9915169e-03 ... -4.0130282e-04
  -9.0063701e-04 -1.1293876e-03]
 [ 5.7709520e-04 -8.4088760e-04  8.9204381e-04 ...  1.7908117e-04
   4.1146384e-04  5.0611026e-04]]
layers.1.weight: [[ 0.         -0.01409996 -0.00018779 ...  0.00028776 -0.00028577
  -0.00023969]
 [ 0.          0.01433871 -0.00027631 ... -0.00011726  0.
   0.        ]
 [-0.00015732  0.0031893   0.00014883 ...  0.         -0.00017925
   0.        ]
 ...
 [ 0.          0.00711301  0.00013848 ... -0.00028829 -0.0002545
  -0.00026647]
 [-0.00014395 -0.00309876  0.00011636 ...  0.00025859 -0.00026274
  -0.00019057]
 [-0.00014023  0.00027015  0.         ...  0.00018828  0.00024133
   0.00022453]]
layers.2.weight: [[ 0.01750134 -0.0178362  -0.00408908 -0.01494411  0.00667155 -0.00952942
  -0.00589645 -0.0006319  -0.00126983 -0.0097472   0.00397067 -0.00172054
   0.00037774 -0.00165984  0.00450755  0.00466436 -0.00969649 -0.02401593
   0.13277958  0.00135377  0.01394621  0.01123881 -0.00178775 -0.00150659
   0.00320246  0.00793233 -0.001293   -0.01911127  0.00522434 -0.00909054
   0.00393839 -0.00041658]]

Final Loss: 0.1668
Distance Metric: 10.2531
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 707

================================================================================

