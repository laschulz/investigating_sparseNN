Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.78 -0.12  0.7 ]]

 [[-1.16  0.47  0.05]]

 [[-0.73  1.96 -1.01]]

 [[-0.32  0.21  0.63]]]
layers.1.weight: [[[ 0.    0.04]
  [ 0.68  0.34]
  [ 0.54 -0.22]
  [-0.14 -0.33]]

 [[-0.14  1.59]
  [ 1.48 -0.52]
  [-1.26  0.3 ]
  [-0.4  -1.09]]

 [[-0.71  0.44]
  [-0.02 -0.14]
  [ 0.37 -0.7 ]
  [-0.83 -0.38]]

 [[ 0.89 -0.48]
  [-0.27 -0.81]
  [ 1.76 -0.41]
  [ 0.15  0.49]]]
layers.2.weight: [[[-0.54  0.16]
  [-0.74 -0.46]
  [ 0.08  0.18]
  [-0.22  0.81]]]

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.01477749 -0.00091992 -0.00198683 ...  0.01173374 -0.00605728
   0.00193906]
 [ 0.03896849 -0.00245353 -0.00523456 ...  0.03085716 -0.01597078
   0.00510933]
 [ 0.06072408 -0.00395386 -0.00811852 ...  0.04792003 -0.02490423
   0.00793173]
 ...
 [-0.01315697  0.00080805  0.00177675 ... -0.01043604  0.00538813
  -0.00172766]
 [ 0.03884056 -0.00245957 -0.00520925 ...  0.03075694 -0.01591106
   0.00508295]
 [ 0.09134928 -0.00632686 -0.01215879 ...  0.0715497  -0.03750035
   0.0119041 ]]
layers.1.weight: [[ 0.0012803   0.00340625  0.00531448 ... -0.00119106  0.00339906
   0.00797468]
 [ 0.00086654  0.00236105  0.00368259 ... -0.00084034  0.00234883
   0.0055472 ]
 [-0.00255036 -0.00665349 -0.01033402 ...  0.0022207  -0.00663689
  -0.0154506 ]
 ...
 [ 0.00319946  0.00846444  0.01316354 ... -0.00287219  0.00842692
   0.01968279]
 [ 0.0049309   0.0130034   0.02021182 ... -0.0043986   0.01295541
   0.03023042]
 [-0.00386028 -0.01014014 -0.01575278 ...  0.00341302 -0.01010121
  -0.02356319]]
layers.2.weight: [[ 0.09615059  0.06701339 -0.18536742 -0.275852    0.30382758 -0.28336522
   0.01011018  0.42038587  0.13594948 -0.44860137  0.52817106 -0.20720014
   0.00997748 -0.19682574 -0.08015315  0.11233391 -0.05388997 -0.10253324
  -0.206761    0.39376202 -0.45414189  0.21517874 -0.2665724   0.34400544
  -0.27927256 -0.17345937  0.07542733 -0.3544607  -0.45216075  0.23697618
   0.36427537 -0.28327242]]

Final Loss: 0.0001
Distance Metric: 8.6018
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 1038

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.00010225 -0.00013721  0.          0.          0.         -0.00012211
   0.          0.          0.         -0.00011328  0.          0.
  -0.00017434  0.          0.          0.          0.          0.
   0.00013188  0.          0.          0.          0.          0.
   0.00013437 -0.00013951 -0.00014339  0.          0.          0.
   0.          0.        ]]

Final Loss: 0.1686
Distance Metric: 8.3517
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 1045

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-1.3813873e-04  1.9818181e-04 -2.1693292e-04 ...  0.0000000e+00
   0.0000000e+00 -1.1567466e-04]
 [ 3.8934457e-01  1.7706829e-01  5.9296537e-02 ...  3.9153671e-01
  -2.0693325e-01  3.8843754e-01]
 [ 5.9829390e-04 -8.8819768e-04  9.8692509e-04 ...  2.0097803e-04
   4.3100346e-04  5.1421672e-04]
 ...
 [-7.5909769e-04  1.0265982e-03 -1.0381908e-03 ... -1.7422432e-04
  -5.2112760e-04 -6.5836171e-04]
 [-1.2829723e-03  1.8643971e-03 -1.9915169e-03 ... -4.0130282e-04
  -9.0063701e-04 -1.1293876e-03]
 [ 5.7709520e-04 -8.4088760e-04  8.9204381e-04 ...  1.7908117e-04
   4.1146384e-04  5.0611026e-04]]
layers.1.weight: [[ 0.         -0.01409996 -0.00018779 ...  0.00028776 -0.00028577
  -0.00023969]
 [ 0.          0.01433871 -0.00027631 ... -0.00011726  0.
   0.        ]
 [-0.00015732  0.0031893   0.00014883 ...  0.         -0.00017925
   0.        ]
 ...
 [ 0.          0.00711301  0.00013848 ... -0.00028829 -0.0002545
  -0.00026647]
 [-0.00014395 -0.00309876  0.00011636 ...  0.00025859 -0.00026274
  -0.00019057]
 [-0.00014023  0.00027015  0.         ...  0.00018828  0.00024133
   0.00022453]]
layers.2.weight: [[ 0.01750134 -0.0178362  -0.00408908 -0.01494411  0.00667155 -0.00952942
  -0.00589645 -0.0006319  -0.00126983 -0.0097472   0.00397067 -0.00172054
   0.00037774 -0.00165984  0.00450755  0.00466436 -0.00969649 -0.02401593
   0.13277958  0.00135377  0.01394621  0.01123881 -0.00178775 -0.00150659
   0.00320246  0.00793233 -0.001293   -0.01911127  0.00522434 -0.00909054
   0.00393839 -0.00041658]]

Final Loss: 0.1668
Distance Metric: 10.2531
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 707

================================================================================

multiChannelCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.00895779 -0.00549688 -0.02602871 ... -0.01687884 -0.00778212
   0.01092167]
 [-0.0024844   0.00132886  0.00657839 ...  0.00399885  0.00184331
  -0.00076168]
 [-0.00357808  0.00199888  0.00972956 ...  0.00605689  0.00278966
  -0.00196225]
 ...
 [ 0.00084562 -0.00074429 -0.0030817  ... -0.00237333 -0.00109771
   0.00292121]
 [-0.00395089  0.00222506  0.01079912 ...  0.00675105  0.00310821
  -0.00236795]
 [ 0.00233997 -0.00167157 -0.00741025 ... -0.0052202  -0.00241442
   0.00454094]]
layers.1.weight: [[-0.01640441  0.00470527  0.00675767 ... -0.00160316  0.00745334
  -0.00442769]
 [ 0.01867639 -0.00523568 -0.00756083 ...  0.00191167 -0.0083489
   0.00511176]
 [-0.01826026  0.00510355  0.00737535 ... -0.00187936  0.00814543
  -0.0050058 ]
 ...
 [ 0.00042268 -0.00066776 -0.000774   ... -0.000341   -0.00080999
  -0.00019477]
 [ 0.01721734 -0.00496586 -0.00712285 ...  0.00166381 -0.0078535
   0.00463217]
 [ 0.01730688 -0.00498581 -0.00715324 ...  0.00167662 -0.00788788
   0.00465962]]
layers.2.weight: [[ 0.98202777 -1.208145    1.156891    0.7713729  -1.2891289  -1.0979543
   1.1837306  -1.2739346  -1.2535794  -0.35139966  1.170753   -0.33517537
  -1.2320226  -1.2605217   1.106072    1.1742169  -1.0214677   1.1759348
   1.0304102   1.049106   -1.2614968   0.8047523  -1.2658774   0.7928129
  -1.2271279  -0.02276139  0.9636084   1.0272895   0.74818856 -0.04740186
  -1.0622991  -1.0705041 ]]

Final Loss: 0.0048
Distance Metric: 19.2960
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 1753

================================================================================

multiChannelCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.00308586  0.00845137  0.02526706 ... -0.00180493  0.02638877
  -0.01643585]
 [ 0.00846554 -0.00246213  0.01278434 ...  0.00125651 -0.01497809
   0.00032086]
 [-0.00328202  0.01486289  0.01670634 ... -0.00064181  0.02848549
  -0.01744039]
 ...
 [-0.00346893  0.0023961   0.03998641 ... -0.00352749  0.0283038
  -0.01794401]
 [-0.00405705  0.01043989  0.0328884  ... -0.00244051  0.03282619
  -0.02048967]
 [ 0.00664855  0.00403762  0.00538539 ...  0.00195896 -0.00834981
  -0.00201604]]
layers.1.weight: [[-0.00714606  0.00141075 -0.00626695 ... -0.00933589 -0.00895497
   0.00126989]
 [-0.00093588 -0.00077823 -0.00091982 ... -0.00097626 -0.00096945
  -0.0007809 ]
 [ 0.00141328 -0.00074585  0.00118881 ...  0.00196939  0.00187062
  -0.00071294]
 ...
 [-0.0119153   0.00266164 -0.01041928 ... -0.01564451 -0.01499937
   0.00242071]
 [-0.00171553 -0.0005082  -0.00159151 ... -0.00202449 -0.00197091
  -0.00052805]
 [ 0.00062341 -0.00078825  0.00047665 ...  0.00098686  0.00092226
  -0.00076667]]
layers.2.weight: [[ 5.9354955e-01  6.9405688e-03 -1.5683554e-01  7.0365781e-01
  -4.8399359e-01 -1.0068399e-01 -6.3175154e-01  1.9836949e-01
   7.6691175e-01 -2.7482040e+00 -2.7482471e-01  4.2389974e-02
  -5.4680735e-01 -9.6966189e-01 -7.3430109e+00  7.0632726e-01
   7.4537385e-01  6.2265074e-01 -1.0037146e+00  7.5365901e-01
   6.6987944e-01 -2.6398909e+00  6.4091820e-01  5.3309077e-01
   6.6877007e-01  3.4914339e-01 -1.4958243e+00  7.1341467e-01
  -6.2766254e-02  9.9742377e-01  8.1026733e-02 -1.0401836e-01]]

Final Loss: 0.2011
Distance Metric: 28.8852
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 1924

================================================================================

multiChannelCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0. 0. 0.]]

Final Loss: 0.0000
Distance Metric: 6.6482
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 1649

================================================================================

multiChannelCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.00291339 -0.00221699 -0.00112852 ...  0.02566436 -0.00150178
  -0.01147927]
 [ 0.0041704  -0.00080558 -0.00291906 ...  0.01819538 -0.00382478
  -0.00950672]
 [-0.00303445  0.00167845  0.00195145 ... -0.02162494  0.00395287
   0.01091777]
 ...
 [-0.00661177  0.00218239  0.00463158 ... -0.03601673  0.00653423
   0.01840381]
 [-0.00050852  0.00069915  0.00117671 ... -0.00427945  0.00328213
   0.00351094]
 [-0.00631956 -0.00154596  0.00223196 ... -0.01376758 -0.00133896
   0.00455269]]
layers.1.weight: [[-0.00134186 -0.00077873  0.00083782 ...  0.0016216   0.
   0.00088956]
 [ 0.00010504  0.          0.         ... -0.00012604  0.
   0.        ]
 [-0.0011704  -0.00067648  0.0007281  ...  0.00140842  0.
   0.00077497]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.01951446  0.00687833 -0.00996644 ... -0.01663212  0.00334185
  -0.01256247]
 [-0.00105899 -0.00061147  0.00065874 ...  0.00127359  0.
   0.00070157]]
layers.2.weight: [[ 3.8234886e-02 -2.9626265e-03  3.3216354e-02 -2.2617860e-02
   3.6977582e-02  4.3021810e-01 -9.5618166e-02  4.8447555e-01
   2.8072847e-02 -3.8828693e-02  3.8655039e-02  1.2713771e-02
  -5.2940261e-01  7.6481856e-02 -7.4155934e-02  1.6108574e-02
  -1.0788470e-02 -3.5677589e-02 -5.2143212e-02 -4.2016875e-02
  -6.3371412e-02 -5.2822698e-02  7.5002410e-02 -3.1278413e-02
   3.2893874e-02 -5.8258414e-02  5.7482481e-01 -4.2896461e-02
   1.2026704e-01  5.0282571e-04  3.7453279e-01  3.0028794e-02]]

Final Loss: 0.0019
Distance Metric: 8.5336
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 1357

================================================================================

multiChannelCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[ 0.          0.          0.         ... -0.00017929  0.
   0.        ]
 [ 0.         -0.00016386  0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [-0.00019325  0.          0.00016948 ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.         -0.000111
   0.00015607]
 [ 0.          0.          0.         ... -0.00013847  0.
   0.        ]]
layers.2.weight: [[ 0.00024241  0.00074362 -0.00083705  0.          0.0004834  -0.00041412
  -0.00052693  0.00012779 -0.00012625 -0.00043056  0.00063303 -0.00066412
   0.00088406 -0.00095013  0.         -0.00034964 -0.0001098   0.00056854
   0.00057459 -0.00047272 -0.00059542  0.          0.00069436  0.
  -0.00043189 -0.00027876  0.          0.00011697 -0.00059237 -0.00044361
  -0.00051115  0.00064955]]

Final Loss: 0.5356
Distance Metric: 7.8217
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 848

================================================================================

multiChannelCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.00212398 -0.00046987 -0.00275726 ...  0.00502263  0.00320789
   0.01140587]
 [-0.00133337 -0.00044238  0.00164602 ... -0.00142628 -0.00096394
  -0.00559648]
 [ 0.00147113  0.00019078 -0.00174901 ...  0.00613928  0.00487847
   0.01505434]
 ...
 [-0.00120905 -0.00022588  0.00143288 ... -0.00099738 -0.00063626
  -0.00401637]
 [ 0.00171705 -0.00012305 -0.00220369 ...  0.00262615  0.00156465
   0.00690125]
 [ 0.00180807  0.00032743 -0.00212857 ...  0.00456697  0.00352495
   0.01248638]]
layers.1.weight: [[ 0.00262554 -0.00239926  0.00194053 ... -0.00204976  0.00244534
   0.00275863]
 [-0.00840508  0.00296075 -0.00820929 ...  0.00224084 -0.00496738
  -0.0067947 ]
 [-0.00160733  0.00045476 -0.00093178 ...  0.00042776 -0.00102959
  -0.00087495]
 ...
 [-0.00517474  0.00398493 -0.0108789  ...  0.002467   -0.00307219
  -0.00881161]
 [ 0.00229581 -0.00064924  0.00132982 ... -0.00061063  0.00147058
   0.00124882]
 [ 0.002499   -0.00070659  0.00144703 ... -0.00066459  0.00160071
   0.00135899]]
layers.2.weight: [[-0.8606284   0.3331046  -0.06614067  0.11002959  0.06988891 -0.07410362
   0.04282938 -0.06973176 -1.0553297   0.04110954 -0.03933681 -0.08553562
   0.00680431 -0.09071979 -0.01906637 -0.01785472  0.01847554  0.03384959
  -0.01993643  0.8589238  -0.81298345  0.5226971   1.1152428   0.02936647
   0.07875473  0.04594535 -0.07865652 -0.05539808  0.00707998 -0.8647061
   0.09430926  0.10258759]]

Final Loss: 0.0005
Distance Metric: 7.6728
L1 norm: 0
L2 norm: 1e-05
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 1775

================================================================================

