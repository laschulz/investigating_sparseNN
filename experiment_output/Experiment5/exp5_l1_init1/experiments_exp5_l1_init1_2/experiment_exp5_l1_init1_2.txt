Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.78 -0.12  0.7 ]]

 [[-1.16  0.47  0.05]]

 [[-0.73  1.96 -1.01]]

 [[-0.32  0.21  0.63]]]
layers.1.weight: [[[ 0.    0.04]
  [ 0.68  0.34]
  [ 0.54 -0.22]
  [-0.14 -0.33]]

 [[-0.14  1.59]
  [ 1.48 -0.52]
  [-1.26  0.3 ]
  [-0.4  -1.09]]

 [[-0.71  0.44]
  [-0.02 -0.14]
  [ 0.37 -0.7 ]
  [-0.83 -0.38]]

 [[ 0.89 -0.48]
  [-0.27 -0.81]
  [ 1.76 -0.41]
  [ 0.15  0.49]]]
layers.2.weight: [[[-0.54  0.16]
  [-0.74 -0.46]
  [ 0.08  0.18]
  [-0.22  0.81]]]

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 1.00240875e-04  1.00374840e-04  1.00227815e-04  1.00084704e-04
   1.00548423e-04  1.00608573e-04  1.00649806e-04  1.00271849e-04
   1.00034609e-04  0.00000000e+00  1.00185891e-04  0.00000000e+00
   0.00000000e+00  1.00417150e-04  1.00328114e-04  0.00000000e+00
   0.00000000e+00 -2.63113213e+00  0.00000000e+00  1.00660029e-04
   7.21770585e-01  1.00179357e-04  0.00000000e+00  1.00593636e-04
   0.00000000e+00  1.00147961e-04  1.00227458e-04  1.00484220e-04
   1.00319579e-04  1.00567995e-04  1.00431593e-04  0.00000000e+00]]

Final Loss: 0.0001
Distance Metric: 8.8409
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 1798

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.06632771  0.00427202 -0.02259066 ...  0.00241195 -0.02737007
   0.06706559]
 [-0.00131941 -0.03273863  0.02980629 ... -0.0068267  -0.02220364
   0.03327049]
 ...
 [-0.00581222 -0.05881301  0.00600163 ...  0.00437048  0.11822691
   0.08917567]
 [ 0.02552367  0.02355347  0.06183733 ... -0.07630724  0.00213368
  -0.02856698]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[ 0.          0.06249337  0.08699397 ...  0.09574261  0.09139761
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.         -0.00141483 ... -0.03153137 -0.00011485
   0.        ]]
layers.2.weight: [[1.2580426  0.         0.         0.         0.         0.
  0.5947456  0.         0.         0.         0.         0.
  0.75238144 0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.5613695  0.         0.         0.
  0.         0.5031512 ]]

Final Loss: 0.0072
Distance Metric: 10.5660
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 1597

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.19073868 0.         0.         0.         0.
  0.         0.        ]]

Final Loss: 0.1671
Distance Metric: 7.4452
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 311

================================================================================

multiChannelCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.21012369  0.89966416 -0.5313773  ... -0.25367698  0.03808574
   0.00775574]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.00528762 -0.2116285   0.03570275 ...  0.01311542 -0.10462829
   0.19624217]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[ 3.3469641e-04 -3.1716129e-04  3.3398313e-04 ...  3.3413465e-04
  -9.2106014e-01  3.3385571e-04]
 [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00
   0.0000000e+00  0.0000000e+00]
 [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00
   0.0000000e+00  0.0000000e+00]
 ...
 [ 6.0178683e-04 -3.1306174e+00  6.0139771e-04 ...  6.0118159e-04
   1.0576893e+00  6.0209224e-04]
 [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00
   0.0000000e+00  0.0000000e+00]
 [ 1.5940154e-03 -1.6802938e+00  1.5931397e-03 ...  1.5934933e-03
  -1.1593760e+00  1.5933550e-03]]
layers.2.weight: [[-4.6568012e+00 -2.7057243e-04 -2.7041667e-04 -2.7103547e-04
  -2.7065139e-04 -2.7090975e-04 -6.3011684e+00 -2.7039720e-04
   5.1941390e+00 -2.7035820e-04 -2.7061196e-04 -2.7039484e-04
   9.0937767e+00 -2.7027840e-04 -2.7052462e-04 -2.7015086e-04
  -9.9981636e-01 -2.7071493e-04 -7.3554677e-01 -7.8436522e+00
  -2.7014423e-04 -2.7072680e-04 -2.7018299e-04 -2.7052479e-04
  -2.7072703e-04 -2.7079677e-04 -2.7030415e-04  4.4512253e+00
  -2.7108804e-04  1.0713102e+01 -2.7071993e-04  1.2985864e+01]]

Final Loss: 2.1328
Distance Metric: 55.9513
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 2195

================================================================================

multiChannelCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.9858518   2.051924    0.          0.          0.         -2.1037664
  -1.3685756   0.61810523  0.          0.7512247   0.          0.
   0.          0.         -0.90619254  0.         -1.3172103   0.
   0.         -2.4250178 ]]

Final Loss: 0.0005
Distance Metric: 11.3041
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 892

================================================================================

multiChannelCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00
   0.00000000e+00  0.00000000e+00]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00
   0.00000000e+00  0.00000000e+00]
 [ 1.35603715e-02 -2.90814991e-04  6.56946301e-02 ... -1.91108429e+00
  -3.39694113e-01 -9.88228738e-01]
 ...
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00
   0.00000000e+00  0.00000000e+00]
 [-1.38573968e+00 -2.27630186e+00 -2.64035940e+00 ... -1.31995790e-03
   1.03579778e-02 -1.62451458e-03]
 [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00
   0.00000000e+00  0.00000000e+00]]
layers.1.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.00036106 -0.00036035 -0.10385112 ... -0.00036028  0.06363925
  -0.00036041]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.2.weight: [[ 2.7957757e-04  2.7951202e-04  5.7960539e+00  2.8022600e-04
   2.7992355e-04  2.8039899e-04  2.8011162e-04 -3.5120065e+00
   2.8012868e-04  2.7978647e-04 -3.3604605e+00  2.8005632e-04
   2.8011185e-04  2.7958542e-04  2.7970824e-04  2.7988025e-04
   2.8026951e-04  2.7983965e-04  2.7956429e-04  2.7978787e-04
  -1.4523276e+01  2.8041046e-04 -5.4536781e+00  4.9090319e+00
   2.8041020e-04  2.8008438e-04  2.7967241e-04  2.8021028e-04
   2.8008365e-04  2.7947477e-04  2.8028962e-04  2.8038322e-04]]

Final Loss: 0.3148
Distance Metric: 46.0012
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 3067

================================================================================

multiChannelCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.00136744  0.00578069  0.02772903 ...  0.05572886 -0.07631066
  -0.08875371]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[ 0.         -0.00029621  0.         ...  0.          0.
   0.        ]
 [ 0.         -0.01934423  0.         ...  0.          0.
   0.        ]
 [ 0.         -0.00131413  0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.00128288  0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.2.weight: [[ 0.6520129  -1.010317   -0.9468177   0.          0.48395872 -0.37886718
  -0.8533898  -0.95772105 -0.9558025   0.51340115  0.6282895   0.33715808
  -0.7496581   0.6691226   0.6473028   0.49558455  0.          0.7017575
  -0.6576045   0.6282407   0.46674985 -1.0268478   0.         -0.780184
   0.48258498 -0.7741814  -0.7625909   0.40963307 -1.0644412   0.
   0.54728234  0.        ]]

Final Loss: 0.2265
Distance Metric: 12.3846
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 828

================================================================================

multiChannelCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00
   0.0000000e+00  0.0000000e+00]
 [-3.8560134e-01 -5.3403729e-01 -7.2108305e-01 ...  3.8073544e-04
  -2.8289255e-04  0.0000000e+00]
 [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00
   0.0000000e+00  0.0000000e+00]
 ...
 [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00
   0.0000000e+00  0.0000000e+00]
 [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00
   0.0000000e+00  0.0000000e+00]
 [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00
   0.0000000e+00  0.0000000e+00]]
layers.1.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.         -0.00054963  0.         ...  0.          0.
   0.        ]]
layers.2.weight: [[ 0.          0.          0.          0.          0.          0.
   0.7463524   0.          0.          0.          0.          0.
   0.          0.          0.          0.5449333   0.          0.
   0.          0.         -0.57357883  0.          0.5970724   0.
  -0.89133835  0.3351251   0.          0.          0.37465844  0.
   0.          1.0437167 ]]

Final Loss: 0.0006
Distance Metric: 6.8687
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 2
stopped after epoch: 906

================================================================================

