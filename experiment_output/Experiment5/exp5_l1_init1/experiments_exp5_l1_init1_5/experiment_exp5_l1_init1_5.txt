Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.78 -0.12  0.7 ]]

 [[-1.16  0.47  0.05]]

 [[-0.73  1.96 -1.01]]

 [[-0.32  0.21  0.63]]]
layers.1.weight: [[[ 0.    0.04]
  [ 0.68  0.34]
  [ 0.54 -0.22]
  [-0.14 -0.33]]

 [[-0.14  1.59]
  [ 1.48 -0.52]
  [-1.26  0.3 ]
  [-0.4  -1.09]]

 [[-0.71  0.44]
  [-0.02 -0.14]
  [ 0.37 -0.7 ]
  [-0.83 -0.38]]

 [[ 0.89 -0.48]
  [-0.27 -0.81]
  [ 1.76 -0.41]
  [ 0.15  0.49]]]
layers.2.weight: [[[-0.54  0.16]
  [-0.74 -0.46]
  [ 0.08  0.18]
  [-0.22  0.81]]]

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         0.         0.         0.         0.         0.
   0.         1.3550562  0.        -1.8460684  0.         0.
   0.         0.       ]]

Final Loss: 0.0001
Distance Metric: 7.6821
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 1762

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.42050084 0.
  0.6106531  0.         0.         0.         0.         0.
  0.         0.6910345  0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         1.207406  ]]

Final Loss: 0.0072
Distance Metric: 10.3563
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 1306

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.      0.      0.      0.      0.
  0.      0.      0.      0.      0.15804 0.      0.      0.      0.
  0.      0.      0.      0.      0.     ]]

Final Loss: 0.1672
Distance Metric: 7.5811
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 563

================================================================================

multiChannelCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [-0.00014409 -0.00014367 -0.00014317 ... -0.00014322 -0.0001436
  -0.00014377]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.2.weight: [[ 3.0973050e-04  3.0989718e-04  3.0980207e-04  9.9162407e+00
   3.1021578e-04  3.0996717e-04  3.1045443e-04  3.1030271e-04
   3.1044078e-04  3.1053985e-04  3.0981089e-04  9.9113188e+00
   3.0994799e-04  3.1038810e-04  8.0830030e+00  3.1040661e-04
   3.1060420e-04  3.1047559e-04  8.7900341e-02  3.0988659e-04
   3.1015510e-04  3.1032891e-04  3.1030388e-04  3.1048522e-04
   3.1058409e-04  3.1015469e-04  3.1067475e-04  1.1183447e+01
   5.0539722e+00 -9.0042772e+00  3.0972465e-04  3.1032669e-04]]

Final Loss: 2.1273
Distance Metric: 56.4584
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 1745

================================================================================

multiChannelCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.0003965   0.00125661  0.00063254 ... -0.00109424  0.00051869
   0.00049727]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.         -0.00106678
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.2.weight: [[ 0.          0.         -1.2362996   0.          0.          0.00752764
   0.          0.55297494  0.89387196  0.          0.         -1.9701643
   1.9299511   0.          0.          0.          0.          0.
   0.         -1.198722    0.         -2.0507348   0.          0.
   0.          0.          0.          0.          0.          0.
   0.         -0.21354853]]

Final Loss: 0.0006
Distance Metric: 10.3191
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 1094

================================================================================

multiChannelCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[-0.8442189   0.35407937 -0.4695645  ... -0.30545145  1.0806314
  -0.70007604]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.1.weight: [[-0.11793461  0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.00317223  0.          0.         ...  0.          0.
   0.        ]
 [-0.00922104  0.          0.         ...  0.          0.
   0.        ]]
layers.2.weight: [[ 0.30898634  0.          0.          1.4540523   0.          0.
  -0.16834506  0.         -0.2339875   0.15880515 -0.10136147  0.
   0.         -0.1994947  -0.34851158  0.20688139 -0.26235533 -0.1535788
   0.22437084  0.1408546  -0.38214064 -1.3420901  -0.3446111   0.15001017
  -0.15577503  0.13773507  0.          0.          0.          0.
  -0.0911841  -0.2746611 ]]

Final Loss: 2.4056
Distance Metric: 50.1502
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 914

================================================================================

multiChannelCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 ...
 [0.0043237  0.00432388 0.00432434 ... 0.00432449 0.00432414 0.00432429]
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]]
layers.2.weight: [[  0.          0.          0.          0.          4.721108    0.
  -14.314715    0.          0.          0.          0.          0.
    0.          0.          0.         -3.4713058   0.5972998   0.
    0.          0.          0.          0.          0.         -4.739321
    0.         -5.277854    0.          0.          0.          5.1606293
    0.          0.       ]]

Final Loss: 0.2279
Distance Metric: 49.2372
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 2956

================================================================================

multiChannelCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [-0.06572814  0.2655925  -0.14284459 ...  0.06736501 -0.02262286
   0.03737923]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [-0.08992591 -0.03657691 -0.02909004 ...  0.00067061 -0.0040716
  -0.03869937]]
layers.1.weight: [[ 0.          0.          0.         ... -0.04832628  0.
  -0.0018164 ]
 [ 0.          0.          0.         ...  0.06097737  0.
   0.00411281]
 [ 0.          0.          0.         ...  0.00472265  0.
  -0.00032025]
 ...
 [ 0.          0.          0.         ...  0.13021608  0.
   0.00061126]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.00082029  0.
   0.03418063]]
layers.2.weight: [[-1.1141062  -0.45188585  0.49731907 -1.1927114  -0.81454813  0.
   0.          0.28820294 -1.2226247   0.          0.         -0.45332724
  -0.7781614   0.         -1.1538806   0.59202665  0.          0.
   0.32633278  0.59113413  0.          0.60845286 -0.80633026  0.
  -0.6480652   0.6222742  -0.9820721   0.37855077 -0.9140782  -1.2669548
   0.          0.27078697]]

Final Loss: 0.3528
Distance Metric: 14.0401
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 1162

================================================================================

multiChannelCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.         -0.9308402   1.2423983   0.          0.
   0.6473939   0.          0.          0.          0.          0.80431724
   0.         -1.2271936   0.          0.          0.          0.
   0.          0.          0.          0.          0.1480483   0.
   0.          0.          0.          0.61891055  0.         -0.67025584
   0.          0.        ]]

Final Loss: 0.0006
Distance Metric: 6.1836
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 1
seed: 5
stopped after epoch: 971

================================================================================

