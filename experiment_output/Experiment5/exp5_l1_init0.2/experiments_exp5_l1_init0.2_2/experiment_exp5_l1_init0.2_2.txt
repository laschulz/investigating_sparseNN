Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.78 -0.12  0.7 ]]

 [[-1.16  0.47  0.05]]

 [[-0.73  1.96 -1.01]]

 [[-0.32  0.21  0.63]]]
layers.1.weight: [[[ 0.    0.04]
  [ 0.68  0.34]
  [ 0.54 -0.22]
  [-0.14 -0.33]]

 [[-0.14  1.59]
  [ 1.48 -0.52]
  [-1.26  0.3 ]
  [-0.4  -1.09]]

 [[-0.71  0.44]
  [-0.02 -0.14]
  [ 0.37 -0.7 ]
  [-0.83 -0.38]]

 [[ 0.89 -0.48]
  [-0.27 -0.81]
  [ 1.76 -0.41]
  [ 0.15  0.49]]]
layers.2.weight: [[[-0.54  0.16]
  [-0.74 -0.46]
  [ 0.08  0.18]
  [-0.22  0.81]]]

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[-0.07194545 -0.00441983 -0.00136857 -0.00136936 -0.00136938 -0.04426308
  -0.03697842 -0.02267852 -0.02480544 -0.07972631 -0.00136883 -0.00136872
  -0.07990423 -0.00136921 -0.07726184 -0.00136913 -0.04831528 -0.00136909
  -0.00136846 -0.0013687  -0.03605645 -0.00136928 -0.05457755 -0.04128828
  -0.00136911 -0.01305346 -0.00136878 -0.01660228 -0.02700792 -0.02300115
  -0.00136948 -0.00136883]]

Final Loss: 0.0016
Distance Metric: 8.3654
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 217

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.01231442  0.02638453 -0.00057791 ...  0.00577291 -0.00274365
  -0.00027486]
 [-0.09472448 -0.04928167  0.01528112 ... -0.00132468 -0.02802271
   0.04075174]]
layers.1.weight: [[0.         0.         0.         ... 0.         0.06254078 0.08296037]
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 ...
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]]
layers.2.weight: [[1.2740276  0.         0.         0.         0.         0.
  0.         0.         0.6323276  0.         0.56298083 0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.        ]]

Final Loss: 0.0073
Distance Metric: 10.5314
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 499

================================================================================

multiChannelCNN_sigmoid -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.          0.          0.          0.          0.
   0.         -0.21189615  0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.          0.        ]]

Final Loss: 0.1672
Distance Metric: 7.5617
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 266

================================================================================

multiChannelCNN_relu -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0.         0.         0.         ... 0.         0.         0.        ]
 [0.00063155 0.00063096 0.00063092 ... 0.00063167 0.00063079 0.00063177]
 [0.00045067 0.00045105 0.00045123 ... 0.0004514  0.00045154 0.00045165]
 ...
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.00096246 0.00096262 0.000962   ... 0.0009627  0.00096226 0.00096221]
 [0.         0.         0.         ... 0.         0.         0.        ]]
layers.2.weight: [[ 3.3721322e-04  9.8359547e+00  1.0726977e+01  3.3738106e-04
   3.3673071e-04  3.3743572e-04  3.3690594e-04 -1.0799785e+01
   3.3708787e-04  3.3682716e-04  3.3736826e-04  3.3752041e-04
   3.6507866e+00  3.3730187e-04  3.3703880e-04  3.3747067e-04
   3.3731241e-04  3.3736267e-04  3.3741767e-04  3.3723738e-04
   3.3696956e-04  3.3698883e-04  3.3764102e-04  3.3685041e-04
   3.3725041e-04  3.3680355e-04  3.3721959e-04  3.3696304e-04
  -6.3369274e+00  3.3685414e-04  1.2895951e+01  3.3682041e-04]]

Final Loss: 2.1065
Distance Metric: 59.0114
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 3531

================================================================================

multiChannelCNN_relu -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.         0.         1.7831756 -1.2314274  0.         0.
   0.         0.         0.         0.        -2.1379302  0.
   0.         0.         0.         0.         0.         0.
   0.9018351  0.         0.        -1.9899625  0.         0.
   0.         0.         0.592458   0.         0.         0.
  -1.237425   0.       ]]

Final Loss: 0.0005
Distance Metric: 10.3803
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 730

================================================================================

multiChannelCNN_relu -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.          0.07335656  0.          0.          0.
   0.          0.          0.          0.          0.          0.03880775
   0.          0.31494692  0.          0.          0.          0.
   1.9659107   0.          0.5873332   0.          0.          2.2621057
   0.          0.32854277  0.          0.          0.          0.
  -0.3068096   0.        ]]

Final Loss: 2.3893
Distance Metric: 46.5754
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 707

================================================================================

multiChannelCNN_tanh -> fcn_256_32_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[-0.3823311  -0.41867825 -0.32920197 -0.415553   -0.37369227 -0.43796664
  -0.4192285  -0.27956527 -0.41472402 -0.37130892 -0.18732688 -0.31868383
  -0.2574416  -0.4452961  -0.35380125 -0.41846585 -0.31329006 -0.42714134
  -0.44780028 -0.27863172 -0.36208925 -0.42555565 -0.3402163  -0.25904962
  -0.33897337 -0.32748514 -0.34915096 -0.3927803  -0.33809566 -0.2994343
  -0.38166973 -0.3800931 ]]

Final Loss: 0.0005
Distance Metric: 3.9653
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 191

================================================================================

multiChannelCNN_tanh -> fcn_256_32_relu

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0.3617651 0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.        0.        0.        0.
  0.        0.        0.        0.       ]]

Final Loss: 0.0002
Distance Metric: 1.3965
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 791

================================================================================

multiChannelCNN_tanh -> fcn_256_32_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.37930304 0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.         0.         0.         0.         0.
  0.         0.        ]]

Final Loss: 0.0000
Distance Metric: 1.1241
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 100000
init: 0.2
seed: 2
stopped after epoch: 531

================================================================================

