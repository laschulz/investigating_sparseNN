Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.78 -0.12  0.7 ]]

 [[-1.16  0.47  0.05]]

 [[-0.73  1.96 -1.01]]

 [[-0.32  0.21  0.63]]]
layers.1.weight: [[[ 0.    0.04]
  [ 0.68  0.34]
  [ 0.54 -0.22]
  [-0.14 -0.33]]

 [[-0.14  1.59]
  [ 1.48 -0.52]
  [-1.26  0.3 ]
  [-0.4  -1.09]]

 [[-0.71  0.44]
  [-0.02 -0.14]
  [ 0.37 -0.7 ]
  [-0.83 -0.38]]

 [[ 0.89 -0.48]
  [-0.27 -0.81]
  [ 1.76 -0.41]
  [ 0.15  0.49]]]
layers.2.weight: [[[-0.54  0.16]
  [-0.74 -0.46]
  [ 0.08  0.18]
  [-0.22  0.81]]]

================================================================================

overlappingCNN_relu -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.00127308  0.02534017 -0.00109038 ... -0.00040539  0.00101837
   0.00183291]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.00326082  0.01175042  0.2595607  ... -0.00084445 -0.05854807
  -0.00442219]]
layers.1.weight: [[0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 ...
 [0.         0.05200738 0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.02972705 0.         ... 0.         0.         0.        ]]
layers.2.weight: [[ 0.          0.          0.         -0.5009375  -1.9983252  -1.2554811
   0.          0.71355915  2.8727868  -0.6979165   0.          0.
   1.5171566  -2.3793807   0.          0.          0.         -1.4815904
   0.19784054 -2.381377    0.976616    0.          0.         -1.359114
   1.1424433  -1.0479041  -1.1815431  -0.70729816  1.2399342   0.6189586
   0.          1.5536689 ]]

Final Loss: 0.0014
Distance Metric: 14.3048
L1 norm: 1e-05
L2 norm: 0
Batch size: 32
Clipping: 0
Learning rate: 0.005
data size: 5120

================================================================================

overlappingCNN_tanh -> fcnn_decreasing_tanh

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.          0.          0.          0.          0.5701426
  -0.2892736   0.          0.          0.         -0.82893765  0.
   0.          0.          0.          0.          0.          0.
  -0.6594074   0.          0.          0.         -0.78404564  0.
  -0.2872747  -0.5655096   0.         -0.22360125  0.          0.
   0.          0.        ]]

Final Loss: 0.0007
Distance Metric: 9.2144
L1 norm: 1e-05
L2 norm: 0
Batch size: 32
Clipping: 0
Learning rate: 0.005
data size: 5120

================================================================================

overlappingCNN_sigmoid -> fcnn_decreasing_sigmoid

Student Model Parameters:
layers.0.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.1.weight: [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
layers.2.weight: [[ 0.          0.19309746  0.04267186  0.          0.          0.
   0.          0.          0.          0.          0.          0.
   0.         -1.9450309   0.          0.          0.          0.
   0.          0.14054751  0.          0.          0.          0.
   0.          0.          0.          0.          0.29959634  0.
   0.          0.        ]]

Final Loss: 0.0001
Distance Metric: 7.6929
L1 norm: 1e-05
L2 norm: 0
Batch size: 32
Clipping: 0
Learning rate: 0.005
data size: 5120

================================================================================

