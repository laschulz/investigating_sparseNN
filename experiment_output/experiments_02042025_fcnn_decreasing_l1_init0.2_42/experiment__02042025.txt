Experiment Summary:
================================================================================

Teacher Model Parameters:
layer1_weights.0: [[ 2.59 -2.83  0.87]]
layer1_weights.1: [[-1.22  0.45  0.88]]
layer2_weights.0: [[-1.38  1.29]]
layer2_weights.1: [[ 0.35 -0.73]]
layer3_weights.0: [[ 0.86 -0.84]]

================================================================================

multiWeightCNN_relu -> overlappingCNN_relu

Student Model Parameters:
layers.0.weight: [[[-0.8456888   0.31193554  0.6100095 ]]

 [[ 1.1163763  -1.2198248   0.37499914]]

 [[-0.34290108  0.12647584  0.24732274]]

 [[-0.27015856  0.0996485   0.19486754]]]
layers.1.weight: [[[-0.02992439 -0.16901386]
  [-0.11105902  0.        ]
  [ 0.03079285  0.19484252]
  [-0.04544183 -0.07309389]]

 [[-0.09942743  0.02616555]
  [-0.0440333   0.        ]
  [-0.08146711  0.01496016]
  [ 0.07734631 -0.16740155]]

 [[-0.02059511 -0.6876204 ]
  [ 0.6844662   0.        ]
  [ 0.08579742 -0.31934384]
  [-0.04442733 -0.22099927]]

 [[-0.07252009  0.81266004]
  [-1.5524336   0.        ]
  [-0.02900321  0.22511807]
  [ 0.26382595 -0.0049112 ]]]
layers.2.weight: [[[ 7.9919316e-02  3.1732887e-01]
  [ 1.2771849e-03 -1.0325666e-01]
  [-2.6532426e-01 -9.9651790e-01]
  [ 1.7735883e+00  0.0000000e+00]]]

Final Loss: 0.0002
Distance Metric: 5.9027
L1 norm: 1e-05
L2 norm: 0
Batch size: 32
Clipping: 0
Learning rate: 0.005
data size: 10240
multiWeightCNN_tanh -> overlappingCNN_tanh

Student Model Parameters:
layers.0.weight: [[[ 1.2040254  -0.44427642 -0.8684353 ]]

 [[ 0.83929783 -0.9127347   0.27568477]]

 [[ 1.1954145  -0.44100827 -0.86199653]]

 [[ 2.528716   -2.7631667   0.84958845]]]
layers.1.weight: [[[-3.4244992e-02  1.9214451e-01]
  [ 1.7081938e-03 -5.2031124e-04]
  [ 3.4383431e-02  5.8396584e-01]
  [ 3.2931644e-01  2.8626350e-04]]

 [[ 4.4664410e-01  4.5104420e-01]
  [ 1.2069224e+00 -5.8405995e-03]
  [-4.5716497e-01  7.0276767e-01]
  [ 1.7222441e+00  3.0284030e-03]]

 [[-1.5133467e-01  1.5374808e-01]
  [ 8.4322378e-02 -2.3189653e-03]
  [ 1.5089324e-01 -6.5999381e-02]
  [-3.8048631e-01  1.7995610e-03]]

 [[ 1.3829215e-02 -7.6157182e-01]
  [ 2.2984289e-02  1.2744407e-04]
  [-1.4191703e-02 -5.9227157e-01]
  [-1.3695917e+00  0.0000000e+00]]]
layers.2.weight: [[[-1.3789065e-02 -8.0382037e-01]
  [-8.3765604e-02 -8.7187178e-03]
  [ 2.2435850e-02  6.0528975e-02]
  [ 7.5913483e-01 -7.7962602e-04]]]

Final Loss: 0.0002
Distance Metric: 6.2297
L1 norm: 1e-05
L2 norm: 0
Batch size: 32
Clipping: 0
Learning rate: 0.005
data size: 10240
