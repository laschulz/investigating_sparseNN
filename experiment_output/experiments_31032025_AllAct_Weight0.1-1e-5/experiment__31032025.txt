Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[ 2.59 -2.83  0.87]]]
layers.1.weight: [[[-1.38  1.29]]]
layers.2.weight: [[[ 0.86 -0.84]]]

================================================================================

nonoverlappingCNN_relu -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[-0.01441316  0.01111597 -0.01272119 ... -0.01139698  0.01822549
   0.00149289]
 [ 0.12497795 -0.05830416 -0.01155432 ...  0.04827113 -0.04181911
   0.00242009]
 [-0.00340722  0.00178111  0.         ...  0.0890566  -0.10215138
   0.03320998]
 ...
 [ 0.02073084  0.00026575 -0.00018881 ... -0.02577779 -0.00369151
   0.00492209]
 [ 0.00974039  0.00159352  0.00775636 ... -0.037589    0.0482991
  -0.01758281]
 [ 0.00308162  0.00355748  0.00138996 ...  0.14680044 -0.16927537
   0.05849272]]
layers.1.weight: [[-0.01070259  0.00125482 -0.00082237 ...  0.00098583 -0.0199666
   0.00865508]
 [-0.01717902 -0.01655708  0.04641986 ... -0.01426435 -0.00929188
   0.12121648]
 [-0.08561902  0.01146916 -0.00325545 ... -0.01719266 -0.01120735
   0.02821439]
 ...
 [ 0.00547303  0.05064723 -0.00765893 ...  0.00029812  0.00989613
  -0.02654394]
 [ 0.0045062   0.00888321 -0.00854382 ... -0.01191215  0.03112756
   0.01522424]
 [-0.01972036  0.01813279  0.00859116 ... -0.00078836 -0.02952106
   0.03964843]]
layers.2.weight: [[ 0.39119706 -1.1753258  -0.10513132 -0.1218199   0.14283553  0.17808323
  -0.03725071  0.06949741 -0.685285    0.43625924  0.30447993 -0.26399305
  -0.06557144  0.1663914   0.6110889  -0.07787687 -0.11419439 -0.22906587
   0.4341316  -0.31516066 -0.31787068  0.09796155 -0.10595629 -0.83335006
   0.53093505 -0.18962267 -0.5158517   0.25006506  0.2520947  -0.08998055
  -0.280638   -0.16957167]]

Final Loss: 0.0040
Distance Metric: 14.8394
L1 norm: 1e-05
L2 norm: 0
Batch size: 32
Clipping: 0
Learning rate: 0.01
data size: 5120

================================================================================

nonoverlappingCNN_relu -> fcnn_decreasing_tanh

Student Model Parameters:
layers.0.weight: [[-0.21702102 -0.30132973  0.37518126 ... -0.09226458  0.01260836
  -0.05755869]
 [-0.03841535  0.03840183  0.02035229 ... -0.01741535  0.05862498
  -0.00971013]
 [-0.03670282 -0.06414482 -0.00721963 ... -0.06964297  0.
   0.04213344]
 ...
 [ 0.09435727 -0.07869154 -0.00460922 ...  0.02347443 -0.05328413
   0.02547939]
 [ 0.367772    0.2376423  -0.40269682 ...  0.2968341   0.19313164
   0.22904828]
 [-0.0806861   0.10713566 -0.04929219 ...  0.00109779  0.10400955
  -0.0697749 ]]
layers.1.weight: [[ 0.0313096   0.02178488 -0.00539669 ... -0.01811584  0.01786366
   0.01381845]
 [-0.00048798 -0.01573384  0.02754441 ... -0.00571072  0.02836872
  -0.01351611]
 [-0.10858732 -0.04754215 -0.02065361 ...  0.01947243 -0.28626043
   0.02446113]
 ...
 [ 0.10007399 -0.01400496  0.028044   ... -0.05419578 -0.09262883
   0.03513635]
 [-0.08397073 -0.03523055 -0.04542339 ... -0.01211795  0.02536515
  -0.01837065]
 [-0.19675565  0.03430867 -0.14407085 ...  0.00842485  0.0609596
   0.05931172]]
layers.2.weight: [[-1.8695101e-01 -2.8060161e-02  3.1067583e-01 -3.7918143e+00
   2.1719103e-01 -2.2249758e-01  2.1355483e-01 -2.6977372e-01
  -2.6935637e-01  9.9984920e-03  2.6827794e-01 -1.5857549e+00
   1.5949297e-01 -1.6037283e+00  1.8863644e-01  1.9194578e-01
   2.1816398e-01  6.1530650e-01  2.3323773e-01  1.2122467e-03
  -1.8404298e-01 -2.7274692e-01  9.1675438e-02  6.1707234e-01
  -2.0359318e-01  6.0824496e-01 -1.5221114e-02  1.0407421e-02
  -2.5810042e-01  2.8625849e-01  1.2503181e-01 -3.7748334e+00]]

Final Loss: 3.5823
Distance Metric: 54.7189
L1 norm: 1e-05
L2 norm: 0
Batch size: 32
Clipping: 0
Learning rate: 0.01
data size: 5120

================================================================================

nonoverlappingCNN_relu -> fcnn_decreasing_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.0013514   0.03352606 -0.01085415 ... -0.01474198 -0.01607287
   0.0093013 ]
 [ 0.04116957 -0.03158294  0.03112238 ...  0.05196794 -0.07217181
   0.01140017]
 [ 0.01526266 -0.00407721  0.00756778 ...  0.01384826 -0.05682348
   0.00619034]
 ...
 [-0.02796354  0.01206891 -0.03528187 ... -0.00435925 -0.02428425
  -0.01176138]
 [-0.01398616  0.02369688 -0.00985656 ...  0.00529369 -0.00677961
   0.01218328]
 [ 0.1175798  -0.10846443  0.06515713 ...  0.06756716 -0.07865202
   0.03390647]]
layers.1.weight: [[ 0.00873334 -0.03200962 -0.02774403 ... -0.00761096 -0.01027223
  -0.02601624]
 [ 0.04017917 -0.0672437   0.0012171  ...  0.0420218   0.00852169
  -0.09109723]
 [ 0.01893201 -0.05488644 -0.00294902 ...  0.05064364  0.01554624
  -0.08988693]
 ...
 [-0.00087561 -0.09596651 -0.04668941 ...  0.00707966  0.00313066
  -0.12015325]
 [-0.00587359 -0.01782057 -0.00821133 ...  0.005428   -0.00874292
  -0.0236384 ]
 [-0.00803523 -0.05029311 -0.02703847 ...  0.01152566 -0.01315349
  -0.04294633]]
layers.2.weight: [[ 1.9993732  -3.3447714  -3.862598   -2.2488697  -1.832254    1.7388288
  -1.3340486  -3.1485744   2.7049189   3.5627177   0.2232225   2.9051929
   0.40687355 -2.491315    1.6730278   2.1449609  -2.9963808   0.70600396
   3.2705946   1.3458023   2.7185085   2.7452097   3.723998    0.8038612
   3.5420094  -1.68219     3.0126066  -1.12549    -0.33863175  4.4467864
   1.046768    2.682422  ]]

Final Loss: 3.4233
Distance Metric: 50.7291
L1 norm: 1e-05
L2 norm: 0
Batch size: 32
Clipping: 0
Learning rate: 0.01
data size: 5120

================================================================================

nonoverlappingCNN_tanh -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[-0.09221176  0.05073411  0.0098241  ...  0.01181877 -0.01021794
   0.01327608]
 [ 0.25331858 -0.06526393  0.06227481 ... -0.00912352 -0.12175414
  -0.03672142]
 [ 0.06651419 -0.04559182 -0.05955098 ...  0.01107597 -0.08383112
   0.06284527]
 ...
 [ 0.01779914  0.07676411 -0.02406134 ... -0.13382232  0.12595794
  -0.02799773]
 [ 0.06019377 -0.08288614 -0.00854378 ...  0.05001155 -0.21223581
  -0.02354827]
 [ 0.24902053  0.08039189 -0.1129034  ...  0.16549276 -0.05004145
   0.08048092]]
layers.1.weight: [[-0.01944013  0.00050313  0.01758246 ...  0.03286505 -0.00200611
  -0.00767055]
 [-0.06758042  0.0198548   0.04170029 ... -0.10635924 -0.02448834
   0.06709537]
 [-0.016253    0.00411746 -0.10381648 ... -0.03328365  0.0295616
  -0.04224087]
 ...
 [-0.0452772   0.06351762 -0.01936858 ...  0.01670545  0.0304341
  -0.00144151]
 [-0.00815967  0.06059529 -0.02867658 ...  0.01456344  0.05560424
  -0.07030567]
 [-0.02952021  0.0630674   0.03731469 ... -0.01840174  0.06481758
   0.02509117]]
layers.2.weight: [[ 0.08932948 -0.9857116   0.53354794  0.34850824  1.0600246   0.7357644
  -0.70241404  1.1626074  -0.47592047  0.5006181  -0.57715726  0.39324802
   0.5275345   0.21091941 -0.37225118 -0.68915796 -0.2853813   0.609705
   0.53878766  0.85024154  0.81476104  0.27973852 -1.0283847  -1.035493
  -0.31493497  0.743084   -0.1637392   0.5195461   0.8515901  -0.92543787
   0.55655783 -0.72571295]]

Final Loss: 0.1837
Distance Metric: 18.7277
L1 norm: 1e-05
L2 norm: 0
Batch size: 32
Clipping: 0
Learning rate: 0.01
data size: 5120

================================================================================

nonoverlappingCNN_tanh -> fcnn_decreasing_tanh

Student Model Parameters:
layers.0.weight: [[ 0.00969182  0.00968767  0.01045513 ... -0.02671794  0.0350205
  -0.01845429]
 [-0.02663183 -0.00828868  0.00319855 ...  0.06737618 -0.06311618
   0.03347328]
 [-0.01850568  0.03558585 -0.00708621 ... -0.06318125  0.08335739
  -0.0272419 ]
 ...
 [-0.02386234 -0.02010891  0.01459448 ...  0.01004565 -0.02451215
   0.02609098]
 [-0.01062182  0.00592043 -0.01151157 ... -0.04524194  0.07788456
  -0.03076833]
 [-0.05884321  0.05462077 -0.02262593 ...  0.36589032 -0.38778985
   0.12268776]]
layers.1.weight: [[ 0.0093177  -0.01081149  0.00501698 ... -0.00687092 -0.01186634
  -0.01271731]
 [-0.01924715  0.0058549   0.00175126 ...  0.00563561  0.01950306
  -0.00321545]
 [-0.01990161 -0.00721302  0.02418782 ...  0.01287233 -0.00531823
   0.00205006]
 ...
 [ 0.02172046  0.00656218  0.01217705 ... -0.01268483  0.01066134
   0.00202517]
 [ 0.01305044  0.00671514 -0.02422191 ... -0.00886516 -0.01321196
  -0.01913917]
 [ 0.01605346  0.01093394 -0.00052812 ...  0.0074562  -0.01866572
   0.03601302]]
layers.2.weight: [[-2.3199373e-03  2.2878846e-02  2.3983158e-02 -3.4947671e-02
  -4.4059306e-02 -2.7775073e-02  1.6764945e-01 -7.6852595e-03
  -1.9719483e-02  4.2038532e-03  3.5784014e-02 -6.5511034e-04
  -6.7397900e-02 -6.3055851e-03 -5.6184721e-03  4.5143509e-01
  -1.1737023e-01 -1.5809204e-02  4.0648824e-01  1.7348222e-02
  -2.7190994e-03  9.9868169e-03 -3.3567242e-02  6.4205386e-02
   2.7384553e-02 -5.6476621e-03 -8.8577378e-01 -2.1074932e-02
  -1.0152108e-02 -1.8494241e-02 -5.3359810e-02  1.0575613e-03]]

Final Loss: 0.0026
Distance Metric: 10.9300
L1 norm: 1e-05
L2 norm: 0
Batch size: 32
Clipping: 0
Learning rate: 0.01
data size: 5120

================================================================================

nonoverlappingCNN_tanh -> fcnn_decreasing_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.05817724  0.06378131 -0.02139041 ... -0.06823092  0.06272682
  -0.0311829 ]
 [ 0.00936294 -0.0309919   0.00682199 ...  0.01020707 -0.01168168
   0.00809111]
 [ 0.25540778 -0.2754715   0.08092529 ...  0.22327672 -0.2177572
   0.06523287]
 ...
 [-0.07975234  0.09708091 -0.04161677 ... -0.09000921  0.1098819
  -0.04236794]
 [ 0.23837423 -0.2621154   0.08866137 ...  0.17798261 -0.17916763
   0.06408294]
 [ 0.05658845 -0.06774715  0.0234823  ...  0.07067025 -0.0740168
   0.02310848]]
layers.1.weight: [[-0.01832258  0.01126822  0.08122088 ... -0.04668969  0.05113278
   0.01869197]
 [-0.06065531 -0.00980824  0.12443385 ... -0.07872833  0.09517471
   0.02037917]
 [ 0.02368238  0.00308756  0.02692447 ...  0.01867913  0.01907294
   0.00357582]
 ...
 [-0.02810148  0.00844538  0.07300396 ... -0.0463766   0.05327614
   0.00552912]
 [-0.04769419  0.00448607  0.15975016 ... -0.08617476  0.15987107
   0.0216392 ]
 [-0.0273719  -0.0114665   0.08548956 ... -0.03755626  0.05708712
   0.01494722]]
layers.2.weight: [[-0.47423783 -0.8109057   0.3247079  -0.4133264  -1.2819141  -0.7423658
  -1.5038697  -0.40775362 -1.1873039  -1.2191592   0.34026083 -1.3585227
  -0.24331367 -1.4804945  -0.2982208   0.58980805 -0.9227592  -1.124451
  -0.87160057  0.45741507 -0.76806307 -0.6475434   0.37971026 -1.0359433
  -0.48829436  0.18618897 -0.22502261 -0.7234493  -0.65387815 -0.47014084
  -1.1275829  -0.5088398 ]]

Final Loss: 0.2314
Distance Metric: 21.9171
L1 norm: 1e-05
L2 norm: 0
Batch size: 32
Clipping: 0
Learning rate: 0.01
data size: 5120

================================================================================

nonoverlappingCNN_sigmoid -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[ 0.05891388  0.05020721 -0.02978578 ... -0.0522628  -0.14255925
   0.00683167]
 [-0.13989241 -0.06774724 -0.06326848 ...  0.00641318 -0.04124455
   0.02111248]
 [ 0.15598604  0.03848518  0.03769789 ...  0.05712276 -0.0079019
  -0.19194333]
 ...
 [-0.02987569 -0.04655034  0.07542639 ...  0.14622808  0.0978998
  -0.0039751 ]
 [-0.00998922  0.03041028 -0.04931005 ... -0.00107257 -0.17924911
   0.12197019]
 [-0.06245795  0.20346682 -0.06522357 ... -0.05399006 -0.01122216
   0.09638926]]
layers.1.weight: [[-0.03034958  0.03936322  0.00506925 ...  0.01904747  0.00982686
  -0.03260671]
 [ 0.01706311 -0.12366128 -0.05030312 ... -0.01076165  0.06446598
  -0.06878502]
 [ 0.00466147 -0.09057016 -0.05828376 ... -0.03830475 -0.03515374
  -0.01253147]
 ...
 [-0.09832094  0.05850289  0.08966137 ...  0.0684644  -0.0485703
  -0.10751263]
 [ 0.01379397  0.09610461 -0.04995406 ...  0.05121674  0.00231277
   0.03102395]
 [ 0.09023038 -0.00533307 -0.08560501 ... -0.04268769  0.01089194
  -0.02110099]]
layers.2.weight: [[ 0.3198714   0.62753344 -0.76395065  0.3212333  -0.8833638   0.5325755
  -0.79878336 -1.0710503  -0.69940823 -0.8688335  -0.85194325  0.37432748
   0.42572767 -0.9288642  -0.65614307  0.72360593  0.42156783  0.53048086
  -0.74107444 -0.8926832  -0.8199782  -0.7820049  -0.7851702  -0.6793571
   0.39214957 -0.7153126   0.50609815 -0.5542057  -0.88646597 -0.71756774
  -0.77895784  0.32214612]]

Final Loss: 0.0069
Distance Metric: 19.8733
L1 norm: 1e-05
L2 norm: 0
Batch size: 32
Clipping: 0
Learning rate: 0.01
data size: 5120

================================================================================

