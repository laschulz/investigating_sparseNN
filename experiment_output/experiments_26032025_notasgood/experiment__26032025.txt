Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[-0.78 -0.12  0.7 ]]

 [[-1.16  0.47  0.05]]

 [[-0.73  1.96 -1.01]]

 [[-0.32  0.21  0.63]]]
layers.1.weight: [[[ 0.    0.04]
  [ 0.68  0.34]
  [ 0.54 -0.22]
  [-0.14 -0.33]]

 [[-0.14  1.59]
  [ 1.48 -0.52]
  [-1.26  0.3 ]
  [-0.4  -1.09]]

 [[-0.71  0.44]
  [-0.02 -0.14]
  [ 0.37 -0.7 ]
  [-0.83 -0.38]]

 [[ 0.89 -0.48]
  [-0.27 -0.81]
  [ 1.76 -0.41]
  [ 0.15  0.49]]]
layers.2.weight: [[[-0.54  0.16]
  [-0.74 -0.46]
  [ 0.08  0.18]
  [-0.22  0.81]]]

================================================================================

overlappingCNN_relu -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00
   0.0000000e+00  0.0000000e+00]
 [-1.0724749e-04  0.0000000e+00 -1.6494273e-04 ... -4.6712127e-01
  -7.3187128e-02  4.1783398e-01]
 [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00
   0.0000000e+00  0.0000000e+00]
 ...
 [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00
   0.0000000e+00  0.0000000e+00]
 [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00
   0.0000000e+00  0.0000000e+00]
 [-2.3046344e-04  2.5714195e-04 -3.3492511e-04 ... -1.4572158e-04
  -2.1553181e-04  0.0000000e+00]]
layers.1.weight: [[ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 ...
 [ 0.          0.          0.         ...  0.          0.
   0.        ]
 [ 0.          0.56017363  0.         ...  0.          0.
  -0.48269436]
 [ 0.          0.          0.         ...  0.          0.
   0.        ]]
layers.2.weight: [[ 0.          0.          0.          0.          0.         -0.5071024
   0.9269598   0.          0.         -2.7291243   0.          0.
   0.         -0.10666561  0.          0.          0.          0.
  -1.4841987   0.          0.6453524   2.5374236   0.          1.1282082
  -1.5078497   0.          0.          0.          0.          0.
  -2.158967    0.        ]]

Final Loss: 0.0005
Distance Metric: 11.7689
L1 norm: 1e-05
L2 norm: 0
Batch size: 32
Clipping: 0
Learning rate: 0.005
data size: 8192

================================================================================

