Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[ 2.59 -2.83  0.87]]]
layers.1.weight: [[[-1.38  1.29]]]
layers.2.weight: [[[ 0.86 -0.84]]]

================================================================================

nonoverlapping_CNN_tanh -> overlapping_CNN_tanh

Student Model Parameters:
layers.0.weight: [[[ 0.16510591  0.49429047 -0.37591052]]

 [[-0.16516864 -0.49432233  0.3759551 ]]

 [[-0.16510458 -0.49407828  0.37577343]]

 [[ 2.589888   -2.8298824   0.86996454]]]
layers.1.weight: [[[ 0.47335416  0.08735949]
  [-0.09743565  0.37486234]
  [ 0.31197578  0.40404245]
  [-0.2150558  -0.40281975]]

 [[-0.11847354  0.12403553]
  [-0.13808249  0.        ]
  [ 0.01959596  0.12079301]
  [-1.379781    1.2898004 ]]

 [[ 0.         -0.12683617]
  [-0.37665316 -0.22552423]
  [ 0.5448023  -0.15449184]
  [ 0.2743751  -0.02980162]]

 [[ 0.6149178  -0.06610887]
  [ 0.7593238  -0.4585604 ]
  [ 0.          0.37269446]
  [ 0.5387097  -0.46370518]]]
layers.2.weight: [[[ 0.          0.        ]
  [ 0.86024165 -0.84022844]
  [ 0.          0.        ]
  [ 0.          0.        ]]]

Final Loss: 0.0000
Distance Metric: 2.9405
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0

================================================================================

nonoverlapping_CNN_sigmoid -> overlapping_CNN_sigmoid

Student Model Parameters:
layers.0.weight: [[[ 0.18745594 -0.44312543  0.49650013]]

 [[ 0.03635393  0.36934337 -1.5258707 ]]

 [[-0.9701047   1.692244   -0.24385811]]

 [[ 2.4709907  -2.7300754   0.83415824]]]
layers.1.weight: [[[-0.37090033 -0.5364566 ]
  [ 0.40714937 -0.2296738 ]
  [-0.574223    0.80641663]
  [-0.83014846 -0.21185157]]

 [[ 0.0997119   0.08868037]
  [-0.5366154   0.11870059]
  [ 0.81494176  0.15569726]
  [ 0.5453639  -0.63343006]]

 [[ 0.         -0.10263303]
  [ 0.          0.        ]
  [ 0.24856646 -0.07774392]
  [-1.2617066   1.0659662 ]]

 [[ 0.25638244  0.14080603]
  [-1.2962567   0.05048232]
  [ 0.20059827  0.69092625]
  [ 0.43583414  0.17580654]]]
layers.2.weight: [[[ 0.03277798 -0.03068141]
  [-0.32891     0.32349652]
  [ 0.85677963 -0.8359438 ]
  [ 0.154906   -0.15138002]]]

Final Loss: 0.0000
Distance Metric: 6.0863
L1 norm: 0
L2 norm: 0
Batch size: 16
Clipping: 0

================================================================================

