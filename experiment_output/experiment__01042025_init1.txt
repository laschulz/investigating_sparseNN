Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[ 2.59 -2.83  0.87]]]
layers.1.weight: [[[-1.38  1.29]]]
layers.2.weight: [[[ 0.86 -0.84]]]

================================================================================

nonoverlappingCNN_sigmoid -> fcnn_decreasing_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.11553876  0.15165576 -0.00345808 ... -0.11957081  0.14450645
   0.0237184 ]
 [-0.14749059 -0.04491408  0.0548828  ...  0.08482482 -0.11777315
  -0.1017372 ]
 [ 0.02601428 -0.0373594  -0.08908386 ...  0.06100429  0.13349633
   0.10199185]
 ...
 [ 0.04674593  0.11041935  0.1045399  ...  0.06410952 -0.1163839
   0.01986022]
 [-0.01436274  0.00951914  0.05747858 ... -0.08140595  0.00334244
   0.07102396]
 [-0.01504968  0.06121343 -0.00861058 ...  0.04805093 -0.11953508
  -0.05791402]]
layers.1.weight: [[-0.1172187   0.00250404 -0.10912961 ...  0.07698375 -0.04626036
   0.12521745]
 [-0.03850959 -0.00254066 -0.14374492 ...  0.07531166  0.13606653
  -0.03731722]
 [-0.08552988  0.07231874 -0.01057251 ...  0.03947945 -0.10505472
   0.02767924]
 ...
 [-0.01612304 -0.10336269  0.00452731 ... -0.09435938 -0.00814545
   0.00102779]
 [ 0.1650753   0.03064111 -0.09252203 ... -0.15050758  0.09036566
  -0.12471821]
 [-0.1448716  -0.12150369 -0.08926226 ...  0.12667152 -0.08542628
   0.06896787]]
layers.2.weight: [[-0.22347036  0.21929131 -0.34704384 -0.07790767  0.14913817 -0.01723059
  -0.42946267 -0.1148662   0.18608047 -0.3381496  -0.11599664  0.07618146
   0.20604168  0.09077229 -0.3883436  -0.01756829  0.12360794  0.2882892
  -0.22745012  0.63762873 -0.20045795  0.2006058   0.22872601  0.28256252
  -0.08020405  0.3400051  -0.16254637 -0.45198134 -0.13186307 -0.397152
   0.3677936  -0.45244396]]

Final Loss: 0.0088
Distance Metric: 19.5869
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_sigmoid -> fcnn_decreasing_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.12082455 -0.0496771   0.13141847 ...  0.03836841 -0.10752881
   0.06776761]
 [-0.07573454 -0.12501532  0.01588102 ... -0.03622257 -0.11929097
   0.11324547]
 [-0.10162082  0.02310864 -0.00176978 ... -0.14330748  0.14449018
   0.05424829]
 ...
 [ 0.03982608 -0.01871494  0.13400698 ... -0.1451324   0.0120777
  -0.06812365]
 [ 0.00451072  0.10776735  0.05779203 ...  0.12554722 -0.10422237
   0.00410057]
 [-0.02228488  0.13436553 -0.14315045 ...  0.12665954 -0.10828255
   0.01945093]]
layers.1.weight: [[-0.01896704  0.02977411  0.12122814 ... -0.00853431  0.04542003
  -0.06782717]
 [ 0.12448041 -0.09296343 -0.05723461 ...  0.03945967  0.13272771
  -0.01697839]
 [ 0.14612548 -0.10168988  0.00760617 ...  0.0543143   0.06460328
  -0.13544844]
 ...
 [ 0.13162631 -0.03628255 -0.1268103  ...  0.02898015  0.10615968
  -0.06353124]
 [ 0.02794901 -0.04604485  0.10913696 ... -0.02710433  0.10382908
  -0.06450826]
 [-0.04057259  0.06869033  0.0837556  ...  0.06800623 -0.09719879
  -0.0392471 ]]
layers.2.weight: [[ 0.11111029 -0.24372853 -0.20083423  0.3238272  -0.33808145  0.01321047
  -0.2983599  -0.4819439  -0.39568505  0.4024681  -0.29260084  0.2077221
  -0.40692526  0.16647135  0.19023827  0.50303906  0.4007091   0.16924393
   0.19178459  0.44117218  0.3130059   0.19475156  0.36218953 -0.20848532
  -0.0208889  -0.19407293 -0.39309543  0.3424856   0.13499972 -0.2889673
   0.39232826 -0.3842941 ]]

Final Loss: 0.0088
Distance Metric: 19.8227
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_sigmoid -> fcnn_decreasing_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.14326581 -0.00237163  0.03996532 ... -0.11857207 -0.05596811
  -0.0633354 ]
 [ 0.11109038  0.03872551  0.08752827 ...  0.01114597 -0.05875064
  -0.12512673]
 [ 0.02420822 -0.13783637  0.0221827  ... -0.06668772 -0.11760334
   0.10393678]
 ...
 [-0.01680473  0.18960974 -0.01212466 ... -0.09687474  0.10084415
   0.04069294]
 [ 0.0402013  -0.1189035  -0.03785497 ... -0.1118149   0.11807039
  -0.06776601]
 [-0.00772792  0.10766721  0.06388551 ...  0.10074866  0.08851321
   0.06279665]]
layers.1.weight: [[-0.09794009  0.04739697  0.05351024 ... -0.0995969   0.12174933
   0.03256603]
 [-0.14909168 -0.11614963  0.10894988 ...  0.05689999 -0.0734306
   0.14685886]
 [-0.1259431   0.08254887 -0.101082   ...  0.02941375  0.09235708
  -0.04394969]
 ...
 [-0.09942666  0.14672156  0.03266847 ...  0.05719271 -0.04436851
   0.08895645]
 [ 0.0018732   0.06535511  0.14472537 ... -0.10219511 -0.02487224
  -0.09237662]
 [ 0.01552964  0.10488421  0.07966875 ... -0.02111389  0.04919629
  -0.02979043]]
layers.2.weight: [[-0.37972847  0.26834175 -0.3149639   0.0911083   0.24155186 -0.44361496
   0.11963618  0.41217774 -0.40923887  0.07867442 -0.02268643  0.43501487
   0.332102   -0.0157972  -0.04617404 -0.3386059  -0.02772933  0.09591806
  -0.03204946 -0.4937008  -0.31823754  0.46467143 -0.49399817  0.49487397
  -0.33738795 -0.10926203 -0.18238823 -0.08167566  0.29898003  0.408841
  -0.4831425   0.02853179]]

Final Loss: 0.0088
Distance Metric: 19.8657
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_sigmoid -> fcnn_decreasing_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.14902756 -0.09413124 -0.10722287 ... -0.12821817  0.05926525
   0.10911011]
 [ 0.00572908  0.14922696 -0.03087507 ...  0.09042735  0.04275839
  -0.13559441]
 [ 0.08264305 -0.06816737 -0.06086803 ... -0.11933444 -0.11090779
   0.03750928]
 ...
 [-0.05193955 -0.16035068  0.00671038 ... -0.06194034  0.09707299
   0.07658888]
 [-0.06604562  0.08665647  0.1592938  ...  0.06499355  0.05633138
   0.01371546]
 [ 0.05326438 -0.03058064 -0.03722062 ...  0.12850468 -0.11318445
  -0.06448701]]
layers.1.weight: [[-0.0413797   0.05518739 -0.1330412  ...  0.01896009  0.13639204
  -0.09959461]
 [-0.07696471  0.10502837  0.09268062 ...  0.08455564  0.01967286
   0.11901489]
 [-0.05821719  0.07050303  0.13775568 ... -0.13260126 -0.05117207
   0.07323775]
 ...
 [-0.12216195 -0.12410753  0.11122225 ...  0.0980554   0.08198158
  -0.05011562]
 [-0.05433913  0.01839637 -0.09666817 ...  0.08924624 -0.00819612
  -0.04952738]
 [ 0.08428229  0.10556806  0.11901134 ...  0.08815085  0.02555689
   0.05178129]]
layers.2.weight: [[ 0.25361696  0.22004738  0.11684162 -0.19780017  0.00246671 -0.2519865
  -0.09112449 -0.05936463  0.07819435  0.29034957 -0.5070439   0.3831002
  -0.4538929  -0.21129484  0.4483971  -0.3634191   0.46353462  0.43579474
   0.0767123  -0.21783625 -0.12769285  0.236933    0.07655706  0.04104931
   0.0238177   0.38396263 -0.3766711  -0.14379665  0.13827284 -0.35499096
  -0.17663191 -0.28904393]]

Final Loss: 0.0087
Distance Metric: 19.5832
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_sigmoid -> fcnn_decreasing_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.10427641  0.1419506   0.1377083  ...  0.05313243  0.07038047
  -0.05408807]
 [ 0.13086277  0.00210379  0.0647141  ...  0.14907621 -0.09173247
   0.04069514]
 [ 0.10627672 -0.12514633 -0.09338651 ... -0.08159956 -0.07137353
   0.05271643]
 ...
 [ 0.1159815  -0.14902662  0.01927426 ... -0.09733826  0.03003394
  -0.04783611]
 [ 0.05746076 -0.01312279 -0.0475606  ...  0.03489667 -0.07960477
   0.12614019]
 [ 0.09104607  0.07315966  0.06003384 ...  0.05486964  0.09473582
  -0.05300931]]
layers.1.weight: [[-0.02266837  0.05706303  0.06343168 ... -0.11969434  0.04177122
   0.05832683]
 [-0.0149015  -0.00018325  0.14027512 ...  0.02479613  0.00089755
   0.12142928]
 [ 0.01920511 -0.13052225 -0.04179078 ...  0.1118435  -0.05012752
   0.11233882]
 ...
 [-0.08531486  0.14138171  0.11058483 ...  0.12849991  0.05162371
  -0.09169983]
 [ 0.13223456  0.04960537 -0.00391241 ...  0.01093614 -0.02223144
   0.12142889]
 [ 0.08873728 -0.04971914  0.09092604 ...  0.13734823 -0.02550549
   0.07086778]]
layers.2.weight: [[-0.06249781  0.51814574  0.34793586  0.4324103  -0.49530298  0.39390033
  -0.10287772 -0.23780532  0.18223356 -0.25058198 -0.46122828 -0.2101954
   0.43679088 -0.09414248 -0.20141335  0.3149025   0.44354817 -0.39808878
   0.07868346  0.15746416  0.04053725  0.3335683   0.07182734  0.2174667
   0.2044893  -0.07649302 -0.3798919  -0.07621516  0.4515382  -0.21324296
  -0.46495375 -0.21337783]]

Final Loss: 0.0088
Distance Metric: 19.8256
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_sigmoid -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[-0.05353849  0.1301639  -0.09553237 ...  0.17196162 -0.13256347
   0.01944308]
 [-0.04089526 -0.1403212  -0.17721055 ... -0.01554034  0.55255604
   0.02188814]
 [ 0.09708484 -0.28764454  0.01240294 ... -0.42048404  0.58017284
   0.33413625]
 ...
 [ 0.07207318  0.03703584  0.07811848 ... -0.01217113 -0.04545872
   0.13403665]
 [-0.0851925  -0.01632462 -0.1420584  ... -0.03641734  0.00189445
   0.12692875]
 [-0.13334346 -0.11079652 -0.09874927 ...  0.02193291  0.01006706
  -0.03196096]]
layers.1.weight: [[-0.17679742 -0.06997313 -0.2342627  ...  0.21486227  0.1611928
   0.03443079]
 [ 0.558383    0.16864246  0.11969768 ...  0.32411054 -0.30154622
   0.12505327]
 [ 0.30502072  0.42107004  0.3155427  ...  0.10328216 -0.34044507
   0.21196638]
 ...
 [-0.1946701  -0.23518737  0.3657734  ...  0.018106   -0.44473073
   0.19524275]
 [-0.07820247  0.4348356   0.11478172 ... -0.34794417 -0.35991696
   0.04158976]
 [-0.5662683   0.5118459  -0.1037212  ... -0.35354918  0.0626047
   0.4054219 ]]
layers.2.weight: [[ 2.4218397  -1.3863506  -2.0686545   0.82939994 -0.11742064 -1.4651529
   0.02262281 -2.7663898   0.55969906  2.3382437   1.5287911   2.46706
   2.443134    2.1907997   1.6610912   1.1013433  -0.72430336  0.46139577
  -0.17451853  0.6750378   0.15435177  2.4968712  -1.6219841   0.30219385
  -1.3868564  -1.7849818   3.541075   -1.0255497  -1.6732459  -0.29760307
   0.5674794  -1.081583  ]]

Final Loss: 0.2751
Distance Metric: 43.9904
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_sigmoid -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[-0.09542646  0.06875491 -0.05475272 ... -0.08065297  0.03068521
   0.02030529]
 [-0.01335246 -0.09427938 -0.06627958 ...  0.00199385  0.1509411
   0.09788179]
 [-0.00348057 -0.08068885 -0.32870394 ...  0.14177762  0.02480822
   0.02455797]
 ...
 [ 0.02688021  0.09456081  0.02608904 ... -0.02208604 -0.04569134
  -0.09708612]
 [-0.11424807  0.1009229   0.12419596 ... -0.00924015 -0.00111531
  -0.11894707]
 [-0.15664253  0.0542055   0.04815545 ... -0.06448085 -0.06218509
  -0.00725208]]
layers.1.weight: [[ 0.19800238  0.11104868  0.1149353  ...  0.47446686  0.28625923
  -0.20611829]
 [ 0.08628864 -0.06053928  0.0385766  ...  0.17158921  0.1665094
   0.00062051]
 [-0.10406575  0.23483953 -0.25363696 ...  0.2551234  -0.09571581
  -0.3147248 ]
 ...
 [ 0.0624176   0.1736858   0.19299309 ... -0.38567722 -0.04882989
   0.22169508]
 [ 0.06685722  0.04802582  0.18498209 ... -0.09434231 -0.03926236
   0.24797025]
 [ 0.05948486  0.23294947  0.16486448 ... -0.0982898   0.01591529
   0.24495345]]
layers.2.weight: [[-1.9570956  -0.6903853   0.4619233   2.62088    -0.0719938  -2.35815
   0.7002351  -1.7769228   0.67402667 -0.22809394 -3.5357754  -0.8818328
   2.20985     0.7289224   0.12229032 -0.98498565 -1.6253539   1.1974597
  -0.1356814   1.2140663   1.7332685  -1.7473001   0.9999918   0.20103717
  -1.9088866  -1.7820312   1.4086815  -1.7981042   1.8386716  -0.38735992
  -0.6982093   0.5960164 ]]

Final Loss: 0.2741
Distance Metric: 40.4548
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_sigmoid -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[-0.06955496  0.0702941  -0.33044845 ... -0.11709334 -0.03345417
  -0.06296793]
 [-0.03759545  0.04938513 -0.05851828 ... -0.04512557  0.19806978
  -0.04720469]
 [-0.21601586 -0.05187459  0.08838031 ... -0.15247852  0.1565344
  -0.12219426]
 ...
 [ 0.08268838 -0.00242949  0.01567074 ... -0.08613451  0.21102166
  -0.17001595]
 [ 0.14594477 -0.01704426  0.07710768 ...  0.14367957  0.05201725
  -0.04033449]
 [ 0.12024178  0.06711899 -0.09872037 ...  0.08847147 -0.00141598
   0.03650854]]
layers.1.weight: [[-0.13618493 -0.16193655  0.27248278 ... -0.4421135   0.
  -0.10087224]
 [-0.37526765 -0.15244079  0.5217185  ...  0.00080827 -0.22965682
  -0.08538794]
 [ 0.26580206  0.26932973 -0.02535694 ... -0.076648    0.07787053
  -0.22385931]
 ...
 [ 0.1059621  -0.37799844 -0.10710838 ... -0.51478326 -0.14116897
  -0.22446428]
 [ 0.4030785   0.31263438  0.54392236 ...  0.14669332 -0.1486323
   0.4955598 ]
 [ 0.2837988   0.01800546  0.00669034 ... -0.56915116  0.07394623
  -0.3705682 ]]
layers.2.weight: [[ 0.7062612  -1.2302753  -2.6310449  -2.4133353   0.0931529  -1.1328334
   0.96963066 -1.6563336   1.1166543  -0.79674375  0.8312431   1.1021782
  -0.46684366  2.9575737   0.79117846  0.40686545 -0.81784403 -0.865569
  -1.6092845  -0.60489553  4.8477325  -0.45364675 -1.6290132  -1.9131815
   0.37495503  0.38287845  0.99214965  1.9725949  -2.0060234   0.13406007
  -0.11412109 -1.4507968 ]]

Final Loss: 0.2747
Distance Metric: 41.3824
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_sigmoid -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[ 0.18224292  0.00895742  0.47962183 ...  0.15455839  0.04631483
  -0.09751263]
 [-0.03013869 -0.05193688  0.02702358 ... -0.06085109  0.11904604
  -0.1297489 ]
 [-0.03923246  0.07096207  0.0841568  ...  0.13071531  0.02109952
   0.10487977]
 ...
 [-0.14155865  0.18383086 -0.28999555 ... -0.26938847 -0.29184806
   0.13541955]
 [-0.01177481  0.10012597  0.08423356 ... -0.16178201 -0.22639418
  -0.0043344 ]
 [ 0.06642286 -0.1014118  -0.01018816 ...  0.05952295  0.02564449
   0.0438404 ]]
layers.1.weight: [[-0.303915   -0.37527424 -0.03870096 ... -0.50355685 -0.05052251
  -0.19175857]
 [ 0.29189736  0.18670386  0.44689664 ...  0.30296513  0.21324664
   0.11611623]
 [-0.21114317  0.08095222 -0.39833146 ... -0.03628541 -0.2791374
  -0.08725148]
 ...
 [ 0.02449304  0.2312851  -0.20961969 ... -0.06370606  0.03615231
  -0.8080684 ]
 [-0.3558785  -0.2911062  -0.2485244  ... -0.02881719  0.1672445
   0.19040893]
 [-0.22259516  0.12032768  0.16275027 ... -0.11069319 -0.14146377
  -0.71255237]]
layers.2.weight: [[-0.06168849  0.48141983  1.4119338  -2.588545   -2.2240984  -0.13728592
  -0.14645797 -1.9617766  -2.218552   -1.4660311  -0.11199215 -1.2224827
  -0.881268    1.0103356   2.0526774  -1.6182913  -0.01287305 -1.0487169
  -0.68430215  0.7639122   2.5582666  -1.4630258   2.2798717  -1.8615175
   0.33551326  0.22264661  1.0077717  -0.20843484 -1.1148432  -1.8876227
   1.6617842  -0.17937425]]

Final Loss: 0.2760
Distance Metric: 40.5588
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_sigmoid -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[-0.13804135  0.3063635  -0.17404586 ... -0.12364219 -0.16577387
   0.2823655 ]
 [ 0.02453816 -0.01152029  0.09933566 ...  0.0441609   0.01634187
  -0.10483015]
 [-0.09021662 -0.19823731 -0.31153288 ... -0.02206051 -0.05815688
  -0.10689063]
 ...
 [ 0.10287846  0.15560992  0.24907559 ...  0.17313896  0.38294053
  -0.02246404]
 [ 0.04841558 -0.10299533  0.086658   ... -0.03890285 -0.01838157
  -0.03589821]
 [ 0.39300814 -0.13723738  0.13234915 ...  0.21532547 -0.1269899
   0.24206136]]
layers.1.weight: [[-0.05885712  0.21836758  0.15066758 ...  0.4842034  -0.28615844
  -0.3178322 ]
 [-0.10197899  0.13640091 -0.31556123 ...  0.2518014  -0.57692593
   0.02050904]
 [ 0.4215545  -0.3118673   0.3051662  ...  0.17710754 -0.1841793
   0.25024873]
 ...
 [-0.08604816 -0.10490761 -0.23740494 ...  0.15734565  0.4848868
  -0.10010135]
 [-0.01263788 -0.10527563  0.1597347  ...  0.15413707  0.02763387
  -0.06920739]
 [-0.34056062 -0.07360765 -0.05780017 ... -0.25026658 -0.4280233
  -0.1775215 ]]
layers.2.weight: [[ 0.4476673   0.22031382 -0.9656435   0.5339012   1.3044199  -1.0362908
  -1.3145561  -1.1290272  -0.52573305  0.49220756 -3.6022708   0.33576655
  -2.5875409   0.30401418 -0.49869204 -0.5050232   1.3842828  -0.3174391
   1.2017276   0.99427974  0.32930946 -0.68263066 -1.8997018  -1.2727703
  -0.01254789  2.355944   -1.2672335   0.00430749 -0.8796763  -1.8960718
  -0.7087764   1.3700902 ]]

Final Loss: 0.2769
Distance Metric: 44.6832
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_sigmoid -> fcnn_decreasing_tanh

Student Model Parameters:
layers.0.weight: [[-0.7964517   0.48563498 -0.05083575 ...  0.8453844  -0.42027524
   0.7642366 ]
 [ 0.5959551   0.05284617  0.5765554  ...  0.48637867 -0.28682473
   0.12527364]
 [ 0.06647843 -0.34141505  0.08376938 ...  0.4034422   0.73627603
  -0.33217096]
 ...
 [-0.02054869  0.067167    0.14005022 ... -0.6499247   0.2538081
   0.05709435]
 [ 0.31854764 -0.8651579  -0.8659894  ...  0.2907903   0.15258911
   0.07417932]
 [-0.7292017  -0.18250047  0.08819862 ...  0.35907     0.53455323
  -0.35441288]]
layers.1.weight: [[-0.21780911 -0.21345712  0.02241088 ... -0.13971545 -0.1273776
   0.1577049 ]
 [-0.00079674  0.25555012  0.28988916 ... -0.06060228  0.10727764
   0.12604664]
 [ 0.15770711  0.22889498  0.19411974 ... -0.17312755 -0.0255583
  -0.40473568]
 ...
 [ 0.32106978  0.00652139 -0.18367583 ... -0.06010492 -0.4751131
   0.43829504]
 [ 0.05576514  0.15951896 -0.08605672 ...  0.13115333  0.14664339
   0.4652991 ]
 [-0.06723174 -0.0296338   0.1857164  ... -0.02096344 -0.2985559
  -0.5957766 ]]
layers.2.weight: [[ 0.24705483  0.42634064 -0.3286914   0.463607   -0.5409523  -0.22133188
   0.49546623 -0.44218764 -0.47744125  0.5027104   0.3524445   0.515345
   0.23540843 -0.39729178  0.42235324 -0.49333423 -0.35755065  0.5032586
  -0.34337777 -0.3409824   0.49682638  0.49401549  0.503122   -0.60050684
  -0.4341555   0.45848766  0.4731537   0.50369984  0.41260087  0.44161645
  -0.51766336  0.46227244]]

Final Loss: 0.0263
Distance Metric: 50.4283
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_sigmoid -> fcnn_decreasing_tanh

Student Model Parameters:
layers.0.weight: [[-0.29388052  0.09286999 -0.11609597 ... -0.7786516  -0.10082207
  -0.85567206]
 [ 1.1244037   0.3611386   0.74812245 ... -0.12796377 -0.63390446
  -0.1763368 ]
 [ 0.11589261 -0.80327994  0.28458247 ...  0.16891037 -0.30378312
  -0.06784342]
 ...
 [-0.29026482  1.0574839  -0.34616974 ... -0.35080063 -0.765369
  -0.6011899 ]
 [ 0.31890392 -0.52815634 -0.33703768 ... -0.53330696 -0.3785315
  -0.14236405]
 [ 0.5363986   0.21952756 -0.1841986  ...  0.33734164 -0.75176823
   0.03482861]]
layers.1.weight: [[ 0.3418705  -0.1080792  -0.0340472  ...  0.19047602  0.34793565
   0.10772975]
 [ 0.0233521   0.12088729  0.5501315  ...  0.29863498  0.06888297
   0.35697168]
 [-0.2588151   0.18217513 -0.00246107 ... -0.19066155 -0.2877071
   0.32314935]
 ...
 [-0.07318957  0.1214764  -0.00291508 ...  0.12134261  0.02747138
   0.20734946]
 [ 0.19067416  0.18655466 -0.08896319 ... -0.10783205 -0.31830093
   0.15595822]
 [ 0.06496329 -0.02742643 -0.09347609 ... -0.17432307  0.10586506
  -0.23331861]]
layers.2.weight: [[ 0.4400684   0.51023287  0.40718663 -0.4467402  -0.5222166  -0.583211
   0.58822614  0.49909     0.28058028 -0.34521556 -0.22777261 -0.19408618
   0.35491112  0.3712414   0.50272465 -0.45665157  0.45627004  0.40760022
   0.5139429   0.61462736  0.5028639  -0.35657614  0.35710502  0.40564245
   0.56523746 -0.32196206  0.44248486 -0.69404733 -0.51091903  0.21790469
  -0.30545536  0.5896163 ]]

Final Loss: 0.0260
Distance Metric: 49.8833
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_sigmoid -> fcnn_decreasing_tanh

Student Model Parameters:
layers.0.weight: [[ 0.23723896  0.24218908  0.24752547 ... -0.0113265  -0.5877105
  -0.76590616]
 [ 0.7568038   0.6046066   0.6427201  ...  0.4702581   0.16955407
   0.91943747]
 [ 0.08637416 -0.4132248  -0.28770685 ... -0.44119263  0.02873935
   0.05350624]
 ...
 [-0.65963787  0.35595202  0.47247922 ...  0.13324048  0.70481634
   0.45100242]
 [ 0.5644704  -0.56961644 -0.66789615 ... -0.15481912 -0.29216775
   0.37038514]
 [-0.08055719  0.46364897 -0.49078545 ... -0.00276272 -0.51725763
   0.08436431]]
layers.1.weight: [[-0.1721939   0.08082227  0.07740194 ... -0.17662413  0.01883477
  -0.09011328]
 [ 0.09455828  0.20357005 -0.08977062 ... -0.2649965  -0.28065777
   0.0724019 ]
 [-0.21768644  0.20684546  0.04674085 ... -0.2911455  -0.22124694
   0.03497685]
 ...
 [ 0.52745885  0.15696125  0.11545957 ... -0.170449   -0.02571705
   0.42651367]
 [ 0.05281643  0.20215495  0.06136342 ...  0.10616641  0.16748886
   0.17103624]
 [ 0.362353    0.27569494  0.12215225 ... -0.53276366  0.21279825
   0.04796793]]
layers.2.weight: [[ 0.27545372 -0.31043705  0.54668236  0.49875262  0.32336107 -0.47043332
   0.4533143   0.50054044 -0.38068604  0.510445    0.5340972  -0.4227832
  -0.4536817  -0.35463065 -0.48581678 -0.52580976 -0.48281926 -0.24194121
  -0.17239898  0.5340828   0.45815787 -0.49374056  0.39461315 -0.47404116
   0.40697274 -0.26201755  0.57478446 -0.31561977  0.5548144  -0.48018828
  -0.47052267  0.524501  ]]

Final Loss: 0.0259
Distance Metric: 49.5833
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_sigmoid -> fcnn_decreasing_tanh

Student Model Parameters:
layers.0.weight: [[-0.7071389   0.08615717 -0.5840446  ...  0.34299368  0.8145494
  -0.89331263]
 [ 0.64621407 -0.37629375 -0.8081551  ...  0.30427533 -0.5065413
   0.25385237]
 [-0.3418697  -0.8319267  -0.3485055  ...  0.04827069  0.28499058
   0.29563144]
 ...
 [ 0.57622474  0.1643757   0.77869684 ... -0.06654825  0.20738755
   0.18343753]
 [ 0.19057535  0.08177599 -0.00799515 ...  0.01416132  0.04073093
  -0.06214024]
 [-0.2359205   0.08416571 -0.10070602 ... -0.4762478   0.7305657
  -0.17302684]]
layers.1.weight: [[ 0.31638956 -0.18207072 -0.41817528 ... -0.35753852  0.0210949
   0.21125607]
 [ 0.06561963 -0.19512689  0.0565304  ... -0.36712274  0.21756989
   0.44342607]
 [ 0.407009   -0.28272086  0.28463948 ...  0.07166437 -0.05817429
  -0.20070997]
 ...
 [ 0.10757305  0.02671884 -0.31731865 ...  0.19171587  0.08201252
   0.43545043]
 [ 0.05344642  0.29605028  0.54479456 ... -0.22900127  0.1434256
   0.08787861]
 [ 0.19273062  0.3457751  -0.48221827 ... -0.17514302  0.39649746
   0.3418336 ]]
layers.2.weight: [[ 0.39143905 -0.4446277   0.5206544   0.5311849  -0.3879834   0.48436993
  -0.33763817  0.4495102  -0.4366728   0.52383465 -0.2331386  -0.4182502
  -0.4848632   0.5088051   0.05490305  0.5453438  -0.38470262 -0.44647714
  -0.39880565  0.41730976  0.46892875  0.449949   -0.4535267  -0.5348032
   0.42024583  0.22850159  0.51346344  0.48932573  0.39596865  0.46588966
  -0.49427062 -0.5174521 ]]

Final Loss: 0.0262
Distance Metric: 50.1976
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_sigmoid -> fcnn_decreasing_tanh

Student Model Parameters:
layers.0.weight: [[-0.03877568  0.08672121  0.31033224 ...  0.7505853   0.6118246
  -0.3163138 ]
 [ 0.11510479 -0.27695036 -0.6496855  ...  0.3366604  -0.38600373
  -0.6587341 ]
 [-0.8192131   0.86326337  0.42540598 ...  0.84764266  0.37111434
  -0.43546477]
 ...
 [ 0.65217555 -0.7897069   0.44184607 ... -0.90518266  0.13468452
   0.44335458]
 [ 0.39620465  0.0140561   0.01979581 ...  0.57267743  0.5718803
  -0.3268029 ]
 [-0.21187244 -0.14692287 -0.03840057 ...  0.04052359  0.12607405
   0.03499048]]
layers.1.weight: [[ 0.23161975 -0.32845384  0.4950642  ...  0.24269305 -0.18623757
   0.14056043]
 [-0.08936621 -0.0949521   0.06908206 ... -0.25172594 -0.06982569
  -0.02257471]
 [-0.45872357 -0.28817144  0.401897   ...  0.21038249 -0.06367969
   0.03845153]
 ...
 [ 0.04636268  0.04957715 -0.15386291 ... -0.20333253  0.37657106
  -0.00184191]
 [-0.03016196  0.61296916  0.17661397 ... -0.24138927 -0.21467201
  -0.2453432 ]
 [-0.5846204   0.16727985 -0.46915212 ... -0.15556313  0.46820253
  -0.04897357]]
layers.2.weight: [[-0.52486527 -0.49780113  0.38941917 -0.5307375  -0.49628794 -0.12225949
  -0.39313015 -0.46363062 -0.501632   -0.4584948   0.31294844 -0.41012916
  -0.25450978  0.44129008 -0.36724946  0.5115035  -0.13565062 -0.33437404
   0.43388727  0.5054106   0.5830283   0.5202324  -0.61665374  0.02320871
  -0.56646067 -0.5161972  -0.55785614 -0.5181511   0.37634483 -0.6393966
   0.5204924  -0.61056304]]

Final Loss: 0.0264
Distance Metric: 51.0861
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_relu -> fcnn_decreasing_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.1043551   0.15271424  0.1041356  ...  0.1320537  -0.02860632
   0.08583584]
 [ 0.07007908 -0.10765062 -0.16830857 ...  0.22791593  0.09511352
  -0.00577276]
 [-0.13215916  0.30144218 -0.11933272 ... -0.02700705  0.00769614
   0.04150046]
 ...
 [-0.21861538  0.39202225  0.04713098 ... -0.20112142 -0.1410056
   0.08078092]
 [ 0.00090961 -0.00816846  0.05096503 ... -0.03846789 -0.14095415
  -0.04520103]
 [-0.0272415   0.17134881 -0.09949409 ...  0.11544755  0.15719606
  -0.09266219]]
layers.1.weight: [[ 0.04599862 -0.01008102 -0.01621527 ...  0.02249482  0.03249635
   0.06631016]
 [-0.01327574 -0.01127091  0.00067761 ...  0.01002028 -0.03339671
   0.06667857]
 [-0.07919282 -0.07816704 -0.01699235 ...  0.15263696  0.06387269
  -0.10837932]
 ...
 [ 0.05671795 -0.04466391  0.17842583 ... -0.08540057  0.02000578
  -0.00908833]
 [-0.12217101 -0.12612118  0.07033647 ... -0.03661599 -0.1151723
   0.00174758]
 [ 0.05972321  0.05986392 -0.1043824  ...  0.10142284 -0.00940768
  -0.07815444]]
layers.2.weight: [[-2.6483305   2.5278292  -2.7525852  -1.3913946  -3.3432727   2.1190019
  -0.2242922  -2.846976   -4.592299    1.081301    2.271487    2.9855933
   3.6636126   2.4615598  -1.4611123   2.1248057   2.279264   -1.012609
  -2.341459    1.9884479  -2.1326716   3.2809463   1.8903618   2.8933802
  -0.87735736 -2.776034    0.8265361   2.8969002   1.1696303  -2.2421758
   0.02205816  1.1321895 ]]

Final Loss: 3.3977
Distance Metric: 49.5059
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_relu -> fcnn_decreasing_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.05971752  0.04157393  0.04570096 ... -0.10964422 -0.17205861
   0.08287939]
 [-0.08886854 -0.04047134  0.11834716 ...  0.0050545   0.03680645
  -0.06410304]
 [-0.03943179  0.12518899  0.15774313 ...  0.16185331 -0.13690771
  -0.05061962]
 ...
 [-0.05324928 -0.13969618 -0.2577246  ...  0.66360825 -0.702231
   0.18271768]
 [ 0.13162671 -0.10644458 -0.04124669 ...  0.12554808 -0.2354358
  -0.05606006]
 [-0.04231543 -0.0275056  -0.03893664 ... -0.17954314  0.3239418
  -0.166698  ]]
layers.1.weight: [[-0.0272394  -0.09692036 -0.05890847 ...  0.11607835 -0.01383258
   0.10966551]
 [-0.09105803  0.13253707  0.10717978 ... -0.01710751  0.03570659
   0.02042896]
 [-0.03301644  0.05254687 -0.13495114 ...  0.2209128  -0.046918
   0.03549726]
 ...
 [-0.05963929 -0.07182105 -0.09190167 ...  0.18995903 -0.11047561
   0.14607534]
 [-0.10025885  0.11185945 -0.07157361 ... -0.14517958 -0.07391799
   0.04115411]
 [ 0.0973205   0.03812158  0.10359149 ...  0.24968769  0.06558887
   0.00600672]]
layers.2.weight: [[ 2.2419696  -0.5471312   2.230555    3.2210991  -4.4428988   0.5080849
  -2.969548    0.4567556   5.924473   -0.3871746   3.1423361  -1.367319
  -0.21666571 -2.2130296   1.1737056  -4.495213    1.1520997   1.1454164
   0.93233323  4.16255    -1.7594932   1.0570935  -2.932225    0.25436237
  -2.7379334   2.5540133  -0.95138603 -0.28598657 -0.15863594  2.691947
  -0.92739236  3.5559437 ]]

Final Loss: 3.1759
Distance Metric: 49.8452
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_relu -> fcnn_decreasing_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.10208208 -0.1707951   0.04773067 ... -0.13413917 -0.01759081
  -0.06561267]
 [-0.06467976  0.0661698  -0.0963694  ... -0.13970906  0.1333223
   0.04538138]
 [ 0.02550409 -0.04238002  0.03114043 ... -0.21884297  0.27383438
  -0.08912098]
 ...
 [ 0.01214117  0.06015196  0.12682396 ... -0.02887107  0.06665942
  -0.02883233]
 [ 0.11947239  0.26885298 -0.2554953  ... -0.16488816  0.258685
   0.0772333 ]
 [ 0.03126589  0.0791273  -0.06281164 ...  0.11966307 -0.11636542
  -0.0515906 ]]
layers.1.weight: [[ 0.00920459  0.09000714 -0.04860831 ... -0.12158105 -0.15126798
   0.03268582]
 [ 0.0871737   0.06695607  0.08677515 ...  0.09526274 -0.06451429
  -0.08602539]
 [ 0.00684624  0.07392223 -0.00944816 ...  0.00402688 -0.04169918
  -0.04619407]
 ...
 [-0.03559329 -0.15139055 -0.1272056  ... -0.12379351 -0.2487397
  -0.08206259]
 [-0.01852201 -0.11776566 -0.05173859 ...  0.20541635 -0.05700201
  -0.04335336]
 [ 0.02726381  0.05391203  0.10174131 ...  0.11393619  0.0468103
  -0.04277301]]
layers.2.weight: [[ 1.9548254   3.058972   -1.5211316  -0.76281756 -3.0121205  -3.6407654
   4.0699677   2.9432993   0.2818221   1.9209371   4.452153   -2.5002964
   0.0252769   0.44376296 -2.980402   -0.18631108 -3.406068   -1.2685525
   4.5508065   0.8255943  -2.5813277  -0.5204212  -0.6503848  -2.0366447
   2.0942261   0.13547894  0.9493051  -0.872092    0.92670876 -3.499535
   3.8973005   1.0905793 ]]

Final Loss: 3.4394
Distance Metric: 50.2345
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_relu -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[-0.48263738  0.15705594 -0.18816744 ... -0.22493085  0.32401055
   0.20846859]
 [-0.04526205 -0.1343342   0.06818899 ...  0.08607565  0.01105812
   0.07183526]
 [ 0.12563772 -0.09903765  0.05033293 ...  0.01268031  0.07673926
   0.08227377]
 ...
 [ 0.03269922 -0.03605965 -0.04065229 ... -0.15764634 -0.01877296
  -0.12846798]
 [ 0.05298939  0.04004671 -0.02224298 ... -0.02392086 -0.00337247
   0.02989616]
 [-0.01093441  0.18592435 -0.0030279  ... -0.17868152 -0.05473555
  -0.10285075]]
layers.1.weight: [[ 0.3117726  -0.458112   -0.15810718 ... -0.04900231  0.24756488
  -0.1179011 ]
 [ 0.41021472  0.00334795 -0.45343727 ... -0.1319835   0.39530593
  -0.04531118]
 [-0.11624356  0.00668751 -0.1403364  ... -0.3538819  -0.30412033
  -0.1309728 ]
 ...
 [ 0.02926664  0.05157654 -0.00832369 ...  0.03001566  0.09681667
  -0.10565501]
 [ 0.56879777  0.34121844 -0.15703954 ...  0.02501787 -0.19872074
  -0.06778808]
 [ 0.2800454  -0.04035958 -0.30053923 ... -0.5024904   0.1998274
   0.34650353]]
layers.2.weight: [[ 1.3533933  -1.3230964   0.9421947  -1.1722741  -0.44335774  0.71541554
  -0.4932812  -0.7550177  -0.04888777 -1.0105666  -1.7953825   0.7065181
  -2.9525297  -2.3684757  -0.14534256 -0.7468877   0.7795612   1.9149822
  -0.3962442  -1.7239627  -0.77564245 -1.7718475   0.7482844   0.13069513
   1.9385256  -0.76062465 -0.27118236  0.29010206  2.0752323  -2.276547
  -2.3307507  -0.03989828]]

Final Loss: 5.0859
Distance Metric: 41.2833
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_relu -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[ 0.06066533 -0.02385077 -0.14307848 ...  0.04701209  0.14555728
  -0.17546257]
 [-0.18668462  0.169816   -0.5807915  ... -0.00766216  0.3096771
  -0.02624265]
 [-0.01205266  0.16610631 -0.12497073 ... -0.12309434  0.19432098
   0.14216919]
 ...
 [ 0.18942453  0.07879668  0.09365428 ... -0.03719212  0.06056168
   0.0897892 ]
 [-0.14411901 -0.15717332  0.07546951 ...  0.10823964  0.15174831
   0.06423013]
 [-0.09658943  0.0761965  -0.1959995  ... -0.05532406  0.20638242
   0.03166027]]
layers.1.weight: [[ 0.17749453  0.03511802 -0.06543849 ... -0.22860254  0.10924689
   0.35973087]
 [ 0.08991749 -0.08020946  0.3912901  ... -0.40460497 -0.23625775
  -0.45063707]
 [ 0.29285562 -0.00133852  0.4713744  ...  0.44125068  0.10110579
  -0.2751332 ]
 ...
 [-0.06608638  0.24324352  0.14579572 ...  0.23197263 -0.38722607
  -0.1377398 ]
 [-0.4336236   0.2437668   0.1157902  ... -0.28671113  0.07883111
   0.1668628 ]
 [-0.0953341   0.11599245 -0.1793052  ... -0.07765231 -0.12937246
  -0.1178563 ]]
layers.2.weight: [[-0.04976317 -0.10194304 -1.0288842  -1.2238494   0.11690854 -0.37411642
  -1.6193317  -1.9668068   0.3880982  -0.99683446  0.17508137 -1.1228293
   1.730577    0.40603015  0.04714755 -0.37181774 -0.70614535 -2.5974529
  -1.6231934   1.1530786   0.5319896  -0.21445343 -1.1239694   1.3968434
   0.9602788  -0.07727009 -0.37215135  0.5546838   0.16922587 -0.31874484
   0.6686925  -1.6992309 ]]

Final Loss: 5.0544
Distance Metric: 39.7211
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_relu -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[-0.08854818 -0.361174   -0.0126163  ... -0.07764298  0.04556727
   0.02162315]
 [-0.20312713 -0.3776746   0.49638504 ...  0.09778295 -0.01196904
  -0.2171556 ]
 [-0.2379775   0.15496565 -0.01558405 ... -0.29897037  0.22224465
   0.10546196]
 ...
 [ 0.0457832  -0.1458928   0.16952862 ... -0.06757257  0.07715424
   0.11670971]
 [ 0.09160355  0.17089008  0.28386328 ...  0.33700287  0.12360748
   0.0043259 ]
 [-0.26936668 -0.09311718  0.18388405 ... -0.12287178 -0.08870165
  -0.11706907]]
layers.1.weight: [[-0.08135841 -0.2921394   0.3193815  ... -0.01199032 -0.16477938
   0.05402632]
 [ 0.05163907 -0.01067638  0.46534082 ... -0.09498142  0.08815562
  -0.04227436]
 [-0.31730697 -0.0450765   0.07096282 ...  0.04953735 -0.62208647
  -0.02646536]
 ...
 [ 0.17877306 -0.36592636  0.24557656 ... -0.32823762  0.16000962
   0.03129962]
 [-0.2832034   0.31827518 -0.24795641 ... -0.19545849  0.01114799
   0.01396315]
 [-0.1447085   0.18224116 -0.29046854 ...  0.12396588 -0.00362759
   0.19576779]]
layers.2.weight: [[ 1.4140636e+00 -2.1168909e+00  4.9911880e-01 -8.8704515e-01
   9.0125424e-01  1.6310409e+00  1.7933886e+00 -1.8837398e+00
  -1.9357134e-01  1.5106944e+00  3.9036196e-01 -1.3028024e-01
  -3.9595813e-01  1.5708827e+00  3.8075893e+00 -1.1772212e+00
  -2.9768183e+00 -4.2394301e-01  2.2592884e-01 -2.0612504e-01
  -2.9157715e+00 -6.2265433e-02 -4.3279970e-01  1.2637093e+00
  -6.9166279e-01 -1.9853349e+00  1.8437171e-03  2.2522447e+00
  -9.4262636e-01 -8.6372101e-01  1.5134027e+00 -1.5291760e+00]]

Final Loss: 4.7707
Distance Metric: 46.4317
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_relu -> fcnn_decreasing_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.07664707 -0.17107454 -0.05576482 ... -0.202743    0.21358788
   0.04371797]
 [-0.02453301  0.07502909  0.0239912  ...  0.02573712  0.17005634
  -0.04287975]
 [ 0.1122358  -0.1771702  -0.07842558 ...  0.18973663 -0.02201143
   0.05699749]
 ...
 [-0.02448706  0.11991519  0.03861556 ... -0.04270237  0.07909209
   0.19644885]
 [ 0.66438794 -0.68732494 -0.25238174 ... -1.2153229   0.96617115
  -0.42326677]
 [ 0.04511815 -0.0167915  -0.07213292 ...  0.08141863 -0.09382048
  -0.101105  ]]
layers.1.weight: [[-0.06668936  0.09300738  0.00526568 ...  0.06968831 -0.2681965
  -0.02954351]
 [ 0.11395835 -0.12667878  0.01085024 ... -0.01533683 -0.02326983
   0.05894609]
 [ 0.1249083  -0.0403867  -0.09807226 ... -0.04742749  0.7258649
  -0.05211733]
 ...
 [-0.07618657  0.01512696  0.01416251 ... -0.06904472 -0.02901755
  -0.12530917]
 [-0.07845543  0.12694365 -0.01799347 ...  0.00908374  0.07055783
  -0.08246893]
 [-0.18780003 -0.16823469  0.03734409 ... -0.17955233 -0.25757673
   0.00272737]]
layers.2.weight: [[ 2.3752723e+00  1.8183881e+00 -3.7188535e+00  2.9846523e+00
   1.3212872e+00  5.0483890e+00  4.5908013e-01  3.7647388e+00
  -2.7363927e+00 -1.7311749e+00 -2.7163510e+00 -3.5351102e+00
   3.2341278e-01 -3.1364074e+00 -1.3092130e+00  1.4989183e+00
   8.4504777e-01 -2.7416708e+00  1.3823231e-03 -1.4609808e+00
   2.0357757e+00  1.0275972e+00 -2.8780513e-02  1.8005782e+00
   4.4262724e+00  2.5915654e+00  4.5164213e+00 -2.2633171e+00
  -1.9067068e+00 -1.3470646e+00 -6.6494413e-02 -1.9762729e+00]]

Final Loss: 3.3148
Distance Metric: 52.5187
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_relu -> fcnn_decreasing_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.4189162   0.01160779  0.02195522 ... -0.5071473   0.716386
  -0.08817255]
 [-1.4065316  -0.09186435 -0.36072704 ...  0.40185404 -1.4048353
   0.5500248 ]
 [-0.08948112 -0.07728814 -0.00396158 ...  0.0861822   0.05365355
   0.0638478 ]
 ...
 [ 0.1724988  -0.25766113  0.07546142 ...  0.06202937 -0.01296831
   0.04787356]
 [ 0.29523268  0.37892717  0.18636182 ...  0.03005352  0.24560407
   0.1515182 ]
 [ 0.04695467  0.22727625 -0.05666082 ... -0.05751181  0.1077835
   0.10444334]]
layers.1.weight: [[ 0.07442689 -0.00122451  0.03000771 ...  0.11326887  0.0781885
   0.00258327]
 [ 0.15091248 -0.652279    0.10204946 ...  0.11607262 -0.16202702
  -0.03799865]
 [ 0.00862795 -0.04750361  0.07064418 ...  0.06129333 -0.10867215
   0.08569299]
 ...
 [-0.02223995  0.01707368  0.04202933 ... -0.09744422  0.01760273
   0.09819709]
 [ 0.07763612 -0.10713553  0.02352084 ... -0.0179882   0.09705175
   0.03167413]
 [ 0.01408505 -0.29553524 -0.09410375 ...  0.1436884  -0.01062929
   0.03843577]]
layers.2.weight: [[-0.1764169   3.5930908   0.4261814   2.2361279  -1.1542492  -1.2761405
  -2.545216    2.2057478   1.7732953   2.7860043  -3.7779994  -4.6635222
   1.7753824   3.531266   -3.048262    0.9383118   4.036548   -0.89471465
   2.9303775  -2.9221263   2.981685   -0.15684478 -0.18905582 -3.5967166
  -1.0034912   2.7699723  -2.9681568   1.3724431   1.6012012   0.07419114
   0.23983213  2.3968198 ]]

Final Loss: 3.2189
Distance Metric: 52.3273
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_relu -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[ 0.21495922  0.02764313 -0.07386914 ... -0.3038659   0.1943262
   0.22666436]
 [-0.08798812 -0.01918194  0.04506756 ...  0.0262059  -0.02456578
   0.0041628 ]
 [ 0.01701304 -0.00691387  0.11829919 ... -0.10192022 -0.04185463
   0.1599854 ]
 ...
 [-0.02586708  0.23035902  0.31733087 ... -0.1739325  -0.49142337
   0.18238673]
 [ 0.27149978  0.03876744 -0.46895862 ...  0.14687416 -0.13668792
  -0.00778391]
 [ 0.10647036  0.05221177  0.18628418 ...  0.53460085  0.14267877
  -0.04349973]]
layers.1.weight: [[ 0.14541727 -0.08781728 -0.26337203 ...  0.20179076 -0.17203005
   0.24476159]
 [ 0.4188079  -0.00622348  0.1622133  ...  0.32163385  0.3363811
  -0.26986837]
 [-0.20566206 -0.42058197  0.28750342 ... -0.37251624  0.39827186
  -0.06747919]
 ...
 [-0.0950975  -0.27828476 -0.2450009  ... -0.177645    0.149545
   0.00968331]
 [-0.12088019 -0.00879089  0.19098605 ...  0.10529175 -0.0161747
   0.12926209]
 [-0.34210774  0.11849719  0.12460788 ...  0.36071455 -0.1369976
   0.20683426]]
layers.2.weight: [[-1.0679904e+00 -1.2953280e+00 -8.3492833e-01 -3.0188384e+00
  -2.9810065e-01 -5.4894447e-01  8.0581033e-01  2.3957226e+00
  -2.4573135e+00  9.8864073e-01  2.5794342e+00  1.0204130e+00
   1.3665572e+00  8.8483936e-01  1.7837275e+00  4.9856067e-01
  -1.8009782e+00  1.5067037e+00  1.3424246e+00  7.9315537e-01
   3.1008995e+00 -1.4739774e+00  2.9327822e+00 -3.7915829e-01
  -2.9783587e+00  7.1623788e-04 -7.8687304e-01  1.2631662e+00
   1.4290118e+00  1.8294729e+00  1.3961519e+00 -2.7589673e-02]]

Final Loss: 4.9846
Distance Metric: 48.3481
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_relu -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[-0.13902012  0.12427678 -0.05523071 ... -0.09206177  0.11564334
   0.22254184]
 [ 0.37463182  0.10281561  0.00846206 ... -0.04283212 -0.11104906
  -0.12732968]
 [ 0.41556078  0.23825401  0.15967354 ... -0.22965114 -0.20082662
  -0.05396296]
 ...
 [ 0.48920292  0.17377178  0.24721307 ... -0.0088687  -0.09855655
   0.03463723]
 [ 0.13559051  0.08271843  0.03439314 ... -0.03805492  0.18642896
  -0.09899418]
 [-0.06905347  0.14158714  0.2427705  ...  0.08252665 -0.06539569
   0.2515795 ]]
layers.1.weight: [[ 0.39886424 -0.00426689  0.11486159 ...  0.02908867  0.63355577
   0.19956037]
 [ 0.00643096  0.04114259 -0.1123119  ... -0.00470178  0.37943807
  -0.23094189]
 [-0.22963758  0.20742685  0.37734234 ...  0.19336751  0.43471843
  -0.24330086]
 ...
 [ 0.6021751  -0.04879034 -0.22772302 ...  0.04199091 -0.01008044
  -0.26087844]
 [-0.03718656 -0.1113037  -0.03595441 ... -0.09294079 -0.17612696
   0.05680539]
 [ 0.32663077 -0.09377715  0.18638475 ...  0.3897688   0.15939789
   0.10822178]]
layers.2.weight: [[ 0.7876986   1.561855    0.7770169   1.2016584  -1.0054086  -1.3413421
   0.53053814 -4.3251877  -1.059155   -3.334431    2.0718038   0.20136924
   2.4484153   0.59480244  0.21839336 -0.71667606  1.9505131  -0.26280025
  -0.43847358 -1.534989   -1.4308872  -0.04204624  0.5094954   0.71732837
   0.69648325 -2.396268    0.57499707  1.5210614  -1.3432274  -1.1171836
   0.7543069  -2.215157  ]]

Final Loss: 4.8574
Distance Metric: 44.0442
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_relu -> fcnn_decreasing_tanh

Student Model Parameters:
layers.0.weight: [[-0.912341   -0.3328205   0.1715284  ...  0.9961752  -1.2230847
  -0.16202824]
 [-0.16872439  0.45451865  0.46763185 ...  0.3396471  -0.53041965
  -0.19189866]
 [-0.00189872 -0.22975641 -1.0154364  ... -0.63625866 -0.6795224
  -0.6728983 ]
 ...
 [-0.05654649  0.20211789 -1.0821612  ... -0.15133172  0.29599103
   0.22628759]
 [ 0.94968885  0.18565246 -0.45845237 ...  0.03015928 -0.31482896
   1.0641531 ]
 [-0.36402977  0.23536818  0.39997512 ... -0.02307725 -0.3299362
  -0.31682837]]
layers.1.weight: [[-0.2552545   0.22471462 -0.32109436 ... -0.1497071   0.0549334
   0.06542457]
 [-0.05647297  0.28217688  0.01341601 ...  0.2426584   0.28295827
   0.3155941 ]
 [ 0.00259788  0.07724151  0.2772193  ...  0.12144291  0.0364219
   0.10237262]
 ...
 [ 0.02811505  0.1666735  -0.17788373 ... -0.23734471  0.09724838
   0.18223317]
 [-0.3602233   0.08490203  0.49802297 ... -0.11088807 -0.1272366
   0.03892189]
 [-0.07652858 -0.39127505 -0.2048159  ... -0.06926408 -0.00163862
  -0.37020245]]
layers.2.weight: [[-0.43935528  0.3888478  -0.8636867   0.6188508  -0.7599113   0.5465155
  -0.63893414  0.67517436  0.82502383 -0.59138036  0.9034955   0.40498385
   0.6561508   0.49865314  0.5020081  -0.46237567 -0.44741112  0.3198532
   0.45322716  1.2740439  -0.51339436  0.59599763  0.8346783   0.44768193
  -0.5136906   0.3871438   0.49202165  1.0168397   1.0129644  -0.47283986
   0.37831208 -0.52030784]]

Final Loss: 3.5291
Distance Metric: 58.5638
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_relu -> fcnn_decreasing_tanh

Student Model Parameters:
layers.0.weight: [[ 0.02017587  0.05771248  0.127706   ...  0.05995102 -0.08429328
   0.02409574]
 [-0.38696548 -0.4598864  -0.54083914 ...  0.78795874 -0.98200953
   0.03812509]
 [-0.58281285 -0.57579035 -0.78871787 ...  0.0942257  -0.09321465
   0.7797891 ]
 ...
 [ 0.05552657  0.6202862  -0.08967097 ...  0.39849335 -0.01034658
  -0.03365603]
 [-0.0540603  -0.04121311 -0.29706714 ...  0.31263757 -0.05296146
  -0.00782567]
 [-1.0673229   0.50530523 -0.46828404 ... -0.11075985  0.13468184
  -0.70706   ]]
layers.1.weight: [[-0.02113361  0.09616604  0.29254153 ...  0.15479574  0.10229814
  -0.23512943]
 [ 0.19854559  0.3616313  -0.11438567 ... -0.1217535   0.19141454
   0.5734375 ]
 [-0.13585201 -0.13798994  0.06592336 ... -0.00313353 -0.20687339
   0.99895346]
 ...
 [-0.16190083  0.42405578  0.46774396 ...  0.23350266 -0.04824791
  -1.2700964 ]
 [-0.14952448  0.13268867  0.43308857 ...  0.12693864 -0.22050619
   0.02721243]
 [-0.15101136  0.37195483 -0.29913926 ... -0.43972683  0.0844321
   0.05559767]]
layers.2.weight: [[ 0.7906277   0.79827726 -1.0618874   0.58076847  0.6751365  -0.48913932
   0.54287064 -0.8696495  -0.37002224  0.45493048  0.84451044 -0.47410554
  -0.6223369  -0.5641373  -0.40772223  0.8050836  -0.3755648   0.81380624
  -0.35118213  0.24978545 -0.48547715  0.6402132  -0.64455545 -0.33813813
  -0.573759   -0.414946   -0.8844445   0.7415152  -0.62111473  0.5722156
   0.48638603 -0.5498538 ]]

Final Loss: 3.4968
Distance Metric: 58.7173
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_relu -> fcnn_decreasing_tanh

Student Model Parameters:
layers.0.weight: [[-1.1438844  -0.15662517 -1.1351256  ...  0.5150651  -1.1019431
   0.22864176]
 [ 0.61150134  0.05399964  0.13661207 ...  0.2934835  -0.65331614
   0.6847271 ]
 [ 0.04072522 -0.82589126  0.14666489 ...  0.16996683  0.4967038
   0.37454462]
 ...
 [-0.44053072  0.35749918 -0.25569415 ...  0.0734943   1.0462784
   0.447845  ]
 [ 1.1386585   0.50889134 -0.13073263 ... -0.3208657  -0.13183057
  -0.1719684 ]
 [ 0.22864728  0.4409264   0.00715884 ... -0.57154405  0.2279484
   0.37400636]]
layers.1.weight: [[ 0.08906313  0.03976847  0.07362276 ...  0.29651308  0.08371727
  -0.12927052]
 [ 0.37060818  0.06276384 -0.01172074 ... -0.20885034  0.29379863
  -0.0072805 ]
 [ 0.15460227  0.09738002 -0.04338679 ... -0.3443538   0.00435491
   0.36714727]
 ...
 [-0.52512693 -0.39379263  0.07241638 ... -0.26077062 -0.14834757
   0.2708201 ]
 [-0.07786629 -0.1405568  -0.32460672 ... -0.23514293  0.10850326
   0.13051179]
 [ 0.33417663 -0.04312966  0.29629672 ... -0.37995955 -0.11317441
  -0.4256154 ]]
layers.2.weight: [[-0.5105244  -0.24112307  2.7725284   0.65588355 -0.36145946 -0.34197074
   0.51472366 -0.37558842  0.29327485  0.3668793  -0.767958    0.55418056
  -0.79603684 -1.3910719  -0.24742946 -0.16759759 -0.5004431  -0.2155147
  -2.7297812  -0.35795337  1.3261122  -0.7073591  -0.46331006  0.2142899
  -0.65921223 -0.37580252  0.34609145 -0.4333669  -0.2699712  -0.46042082
   0.34134507  0.6904882 ]]

Final Loss: 3.3229
Distance Metric: 52.7737
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_relu -> fcnn_decreasing_tanh

Student Model Parameters:
layers.0.weight: [[ 0.44328764 -1.3165439  -0.22365935 ...  0.0254551   0.68466616
  -0.5981016 ]
 [ 0.16913365  0.43784258  0.28056136 ...  0.66938317  0.07116639
   0.17875555]
 [-1.1617874   1.2834829  -0.5052666  ...  0.5722853  -0.3799502
  -0.21994005]
 ...
 [ 0.20800078  0.35540304  0.19585195 ...  0.67023855 -1.1013644
  -0.13973148]
 [ 0.15758799 -0.26684937  0.6249331  ...  0.11268625 -0.3784744
  -0.17389692]
 [ 2.314341   -2.8273551   0.7316106  ...  0.22626565 -0.49295995
   0.11275954]]
layers.1.weight: [[ 0.2405865   0.2610054  -0.28227264 ... -0.1251785   0.31701398
  -0.06074758]
 [ 0.32481083 -0.4722362  -0.18628107 ... -0.42176872  0.41243583
   0.37859666]
 [ 0.30714703 -0.20205572 -0.04372975 ... -0.0567833   0.17170268
   0.11461026]
 ...
 [-0.01121846  0.20051688 -0.24121894 ...  0.0203403  -0.3167235
  -0.02124179]
 [-0.6573564   0.04270238  0.28686702 ... -0.3887173   0.48346958
  -0.44668463]
 [ 0.13374016  0.11947067  0.7337965  ...  0.3347108   0.18280675
  -0.21770002]]
layers.2.weight: [[ 0.6188343   0.9618451  -0.38180476 -1.3837048   0.467758   -0.82728404
  -0.51442987 -0.55000305  0.4433718   0.31280595  0.5929272   1.420676
  -0.44793195 -0.80013907 -0.5322561  -0.37354097 -0.4310443   0.40930226
  -0.47507563  1.0054259  -0.6236863  -0.7130443   0.6356902  -0.56085783
   0.7317443  -0.37027103  0.5485427   0.45049128  0.62390137  0.40774497
   0.7800905   0.64284277]]

Final Loss: 3.2398
Distance Metric: 61.1317
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120

nonoverlappingCNN_tanh -> fcnn_decreasing_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.06866731  0.05174267 -0.03131647 ... -0.11723216 -0.05879818
   0.02399715]
 [ 0.43024185 -0.44694924  0.18301512 ... -0.04290316 -0.07818523
  -0.03052849]
 [ 0.06113352  0.05704872 -0.01354612 ...  0.03151245 -0.18803404
   0.07589951]
 ...
 [ 0.37336457 -0.4191086   0.2147803  ...  0.11592875 -0.08789046
   0.05527839]
 [-0.32333085  0.41719332 -0.13136612 ... -0.07507521  0.00989489
  -0.14103715]
 [ 0.313655   -0.05841511  0.10338418 ... -0.24309115  0.09314184
  -0.05269623]]
layers.1.weight: [[-0.03935538  0.12784043  0.15161878 ...  0.10666633  0.07341322
  -0.13129693]
 [-0.14992772  0.08112513  0.02704545 ... -0.03984131 -0.00603423
  -0.0011046 ]
 [ 0.04696944  0.00599273 -0.17083374 ...  0.0476554   0.12310464
   0.00188652]
 ...
 [-0.09721892 -0.11362492  0.07345144 ... -0.07945956 -0.10879513
   0.0137326 ]
 [-0.06016427 -0.11368351  0.04876405 ... -0.1670754   0.01600781
   0.03947071]
 [-0.1746958  -0.14699559  0.00989573 ...  0.0427613  -0.13778578
   0.08663166]]
layers.2.weight: [[ 1.2453182   1.309768   -2.1638281  -2.4519482  -2.5527036   1.6982129
  -1.5034965   0.11156688 -3.9478016   0.8756385   0.6858037  -2.7903774
  -1.4521865  -2.3628576  -0.8894337  -4.333366   -2.0037916   1.8576413
  -1.0950682  -0.88832617 -0.8806073  -0.9040157   0.47381812  0.31916413
  -0.2458858  -2.4618182  -2.4230945   1.0553344  -1.5696558   1.4421922
   2.6650612  -0.15789269]]

Final Loss: 0.2000
Distance Metric: 44.8571
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_tanh -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[-0.05828403  0.06867018  0.10068079 ... -0.06437272 -0.02795349
   0.05351923]
 [ 0.1602084   0.16321333  0.0701557  ...  0.1699345   0.02836911
  -0.01914849]
 [ 0.13900097 -0.26803142 -0.14644435 ... -0.03411786  0.06572232
   0.11239009]
 ...
 [-0.08009401 -0.02651653 -0.02499421 ...  0.04754862  0.0455597
   0.05814764]
 [-0.0697623  -0.03761627  0.05883889 ...  0.00657701  0.08202862
  -0.23462553]
 [ 0.09581009 -0.05767399  0.04156612 ...  0.02324982 -0.10379069
  -0.16284874]]
layers.1.weight: [[-0.14559795  0.4867832  -0.04134867 ... -0.02732971 -0.3030887
   0.17472807]
 [ 0.61740357  0.03363115 -0.01664221 ... -0.34048066 -0.3973234
  -0.23234724]
 [-0.2804951   0.25428766  0.07969094 ...  0.18497047 -0.43332034
  -0.03128533]
 ...
 [ 0.27598488  0.09894709 -0.22007635 ...  0.01895339 -0.06707838
   0.04048156]
 [-0.46732292 -0.3535649   0.38858312 ... -0.1543936   0.17407988
   0.0235154 ]
 [ 0.1185372   0.01370064 -0.03122456 ...  0.23569568  0.3079703
  -0.4403744 ]]
layers.2.weight: [[ 1.6118417   0.6672969   0.17614952 -0.3344179  -1.3847474  -1.3761517
  -0.07682165 -0.0960505   0.6511577  -1.2431324   0.8642858  -0.92929715
  -2.561234    1.921259   -2.193374    1.5176984   2.119491    1.5482178
  -0.445914   -0.75000054  1.6348232  -3.8150172  -0.5834348  -2.7082038
   2.5267293  -1.339829    1.3643422   2.3326144  -2.1677372   0.892836
   2.5900712  -2.8982694 ]]

Final Loss: 0.3878
Distance Metric: 41.9134
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_tanh -> fcnn_decreasing_sigmoid

Student Model Parameters:
layers.0.weight: [[ 0.13956852 -0.18788591  0.11972716 ... -0.07806074  0.07814056
   0.04319564]
 [ 0.1719853   0.0650799   0.1712364  ...  0.13652356 -0.04046218
   0.02196846]
 [ 0.13754725 -0.15632355  0.10864697 ...  0.11803491  0.12824692
  -0.14028329]
 ...
 [-0.99901384  1.0273253  -0.24998006 ... -0.14652611  0.03045943
   0.0115865 ]
 [ 0.06429507 -0.25343725 -0.05317488 ...  0.11220736  0.02065067
   0.1614205 ]
 [ 0.08305233  0.12028933 -0.06084841 ... -0.19013709  0.04455191
   0.08282112]]
layers.1.weight: [[-0.09624041 -0.05297179 -0.04248797 ...  0.05210435 -0.07531133
  -0.14570488]
 [-0.05028975  0.11143906  0.0859651  ...  0.04689288 -0.20382604
  -0.1567075 ]
 [ 0.14844273  0.07008054  0.07827574 ...  0.05853048  0.14198382
   0.09588818]
 ...
 [-0.05126609 -0.08284552 -0.08477057 ...  0.00257314 -0.10267495
  -0.06716843]
 [ 0.18251114 -0.02076432 -0.14746639 ... -0.14535846  0.05048751
  -0.191068  ]
 [ 0.0661346  -0.03133647 -0.08134492 ...  0.09518249 -0.01635513
   0.01653244]]
layers.2.weight: [[-1.2533287  -2.5002546   1.085474   -1.9381891   1.2588822  -0.6115654
  -1.39008    -3.7161164   0.41335633  0.05277694  0.9995548  -1.1264265
  -1.4336147  -1.0560168   0.74417764  1.1548226  -0.66876096  2.3469598
  -3.5552502  -1.5288233  -0.36832562 -2.4637172  -3.5936756  -0.46023265
   1.0570663  -4.3281465  -1.7083912   1.133759    0.9842858   2.0264432
  -2.4876122  -0.1980698 ]]

Final Loss: 0.1898
Distance Metric: 45.3235
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_tanh -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[ 0.10138065  0.00560897  0.13583852 ... -0.20326687 -0.01870747
   0.01513772]
 [-0.03652971 -0.24476683  0.10200886 ...  0.19622032  0.09925032
  -0.12265866]
 [-0.15243043  0.02365698 -0.02879818 ... -0.06276996  0.01715386
  -0.04782616]
 ...
 [ 0.0335163   0.07214254  0.07022361 ...  0.08798631 -0.0349426
  -0.07402754]
 [-0.04230808 -0.01583534  0.03659346 ... -0.03736982 -0.09176991
  -0.02724165]
 [-0.05533465 -0.09986597 -0.14718473 ... -0.04510808  0.06156123
   0.13355702]]
layers.1.weight: [[ 0.11624666  0.02431163 -0.20246129 ...  0.28012452 -0.39865097
   0.19761735]
 [-0.02710361 -0.22560918 -0.06932396 ...  0.03709112 -0.05040107
  -0.15670612]
 [-0.00810675  0.47789434  0.35394767 ... -0.20577398  0.739647
   0.15026894]
 ...
 [-0.06667244 -0.28245014  0.09008872 ...  0.2499678   0.18365718
   0.21349639]
 [-0.44855207  0.25312164  0.13212542 ...  0.09670988 -0.11169301
  -0.02465934]
 [-0.02746779  0.04860181  0.04086278 ...  0.4939319   0.367742
   0.36945042]]
layers.2.weight: [[-1.3732781   0.40438983 -2.7841473   2.3805711  -1.2847427   0.11571255
   0.8647465  -0.1594289   0.8393121  -0.5524102   0.8986299  -0.01080796
   0.94213057  0.968912    1.226521    1.0196304   0.81262803 -0.83299154
   1.5615876  -0.27119377 -0.51854354  0.16913238  1.4762723  -0.9943207
   0.44239405  1.2987483  -0.2518878   1.7517816   0.8166336   1.4765714
  -0.9312732  -0.2892372 ]]

Final Loss: 0.3855
Distance Metric: 39.8856
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_tanh -> fcnn_decreasing_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.07457064  0.07890528 -0.09560253 ...  0.40062305 -0.44820324
   0.24585456]
 [-0.03247168 -0.10005161 -0.07101444 ...  0.08014441 -0.08866885
   0.01055794]
 [ 0.04937555  0.04229338  0.03793896 ...  0.19583912  0.00394834
  -0.0716671 ]
 ...
 [-0.27445492  0.06192397 -0.06523779 ... -0.13772038  0.00689657
  -0.08856382]
 [ 0.08686052  0.1047976  -0.04148699 ... -0.20505519  0.17453022
   0.13076498]
 [ 0.02245396 -0.03373462 -0.01460665 ...  0.029714   -0.17205997
   0.00062313]]
layers.1.weight: [[-0.11777088  0.05426931 -0.06172376 ...  0.00339786 -0.03986951
  -0.10186725]
 [-0.00310343 -0.02014477  0.17710073 ...  0.0724579  -0.03520394
   0.00489626]
 [ 0.05368381  0.07790808  0.05229382 ...  0.11321028  0.12574637
   0.08485955]
 ...
 [-0.11262768 -0.03945453 -0.08758298 ... -0.03925505  0.1312514
  -0.06588428]
 [-0.03181166  0.15625514 -0.03128286 ... -0.06519776  0.08599139
   0.0243323 ]
 [ 0.03235168 -0.0348952   0.10249912 ...  0.0577082   0.06210185
   0.1062289 ]]
layers.2.weight: [[ 0.16239284 -2.388962    1.1412312   0.63917375  0.35210857  1.2110744
  -3.7388086  -3.2782536  -0.82976377 -0.998845   -2.0737872   0.4230265
  -2.2105694  -3.255044   -1.7327229   1.1218289   0.36293492 -1.7051687
  -3.1520846  -1.9455582  -0.09134947 -0.7859609  -2.0585341   0.74244815
  -1.0137411   1.211473   -2.8982124   1.2849612   2.0046399  -1.3192346
   0.7599779  -2.6161788 ]]

Final Loss: 0.2023
Distance Metric: 45.8461
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_tanh -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[-4.8199814e-02 -4.0351357e-02 -5.4976907e-02 ... -1.3650294e-01
   1.7098668e-01  2.1983463e-02]
 [ 8.1741661e-02 -1.2765064e-02 -2.3784267e-04 ...  5.0603800e-02
   9.5216051e-02 -1.2649305e-01]
 [-1.4512654e-01 -4.9116030e-02 -6.2959939e-02 ...  4.5201622e-02
  -1.3409744e-01  8.7883852e-02]
 ...
 [ 1.3530846e-01 -4.8768558e-02 -2.1797165e-02 ... -9.6967071e-03
   9.9401805e-04 -2.5437152e-01]
 [-1.4813182e-01  8.1900984e-02 -6.4509332e-02 ... -9.1783278e-02
   2.8502500e-02 -1.6831489e-01]
 [ 5.3702015e-02  5.6500532e-02  1.7950292e-01 ... -7.0916682e-02
   8.6485669e-02 -8.5648537e-02]]
layers.1.weight: [[ 0.06309553 -0.15603314 -0.16084999 ...  0.08926491 -0.21011046
   0.19420047]
 [ 0.02678999 -0.05269234  0.47341695 ... -0.2525451   0.13271607
   0.66388047]
 [-0.2841685   0.02416807 -0.4598422  ... -0.6432264  -0.12438042
  -0.5099791 ]
 ...
 [ 0.24094449 -0.5299487  -0.19213036 ...  0.01049657  0.25454503
   0.27481946]
 [-0.1516404  -0.22947308  0.16770543 ...  0.6441603   0.20345078
  -0.36276996]
 [-0.4237762   0.19466074 -0.3440998  ...  0.18714184  0.42896423
   0.01704021]]
layers.2.weight: [[-3.6111734   0.3351459  -0.5913896   1.6011945   0.44527665 -2.107512
   0.5804312   0.6019314  -0.8231694   2.0537481  -0.7221779  -0.96016073
  -0.9731566  -1.6139357  -0.84735656  0.78002375  0.8120081   0.56629026
   1.0935     -5.119961   -0.49313074  2.220948    1.2992313  -0.02582237
  -2.8450785  -1.6542537  -0.2255864   1.4923476  -0.9362024  -2.3526666
  -1.5808774   0.07781523]]

Final Loss: 0.3871
Distance Metric: 41.1280
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_tanh -> fcnn_decreasing_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.0639824   0.19947465  0.00661253 ... -0.32268548  0.20397389
  -0.1602445 ]
 [-0.1806061   0.23081571 -0.01077757 ... -0.28066134  0.32108128
  -0.10194786]
 [ 0.20625018 -0.10832968  0.09885052 ... -0.09813983 -0.1749116
   0.02749739]
 ...
 [ 0.15042089 -0.12454567  0.10649008 ...  0.31344104 -0.12396878
   0.09133481]
 [-0.1822094   0.1071528  -0.17597589 ...  0.06222489  0.06959457
  -0.04992472]
 [ 0.03378527 -0.13518368  0.1519191  ...  0.01060987 -0.04619797
  -0.10992616]]
layers.1.weight: [[ 0.00756868 -0.12397117  0.15112628 ...  0.00730649 -0.10262124
   0.13467532]
 [ 0.15229979  0.24197231  0.08168119 ... -0.03272438  0.05500912
   0.05367853]
 [-0.08126505 -0.09948076  0.01356379 ... -0.07695208  0.00820492
   0.11889669]
 ...
 [ 0.3128937  -0.18583868 -0.04359958 ... -0.32778302 -0.08614756
   0.1443035 ]
 [ 0.09559784  0.30301863 -0.02957907 ...  0.18359007  0.17918347
  -0.0980851 ]
 [-0.02280141 -0.09830745  0.06780735 ... -0.11465921 -0.12721983
   0.1444653 ]]
layers.2.weight: [[ 1.0784652  -1.0734292   0.9331131  -1.6009476   0.92201424 -0.9260105
  -1.7146313   0.02890399  1.5236424   0.9043588  -4.350969    0.
  -4.081655    1.1480279   0.00810122 -1.4468625  -1.1557952  -2.5163686
  -1.4148737  -0.12030796  0.17771515 -0.19588853 -1.1763874   0.04265109
  -0.6206008  -0.25388607 -3.1458516   0.83644956  0.7372949  -3.4002702
   1.9818474   0.22077066]]

Final Loss: 0.2021
Distance Metric: 41.5864
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_relu -> fcnn_decreasing_tanh

Student Model Parameters:
layers.0.weight: [[-0.23834644 -0.77657616 -0.6762796  ...  0.5666771   0.35406187
  -0.07831696]
 [-0.0276078  -0.45995355 -0.36245483 ... -1.1284717  -0.6417832
   1.2073021 ]
 [-1.15586     0.14546567 -0.40737906 ... -0.37861186  0.32349825
   0.4681516 ]
 ...
 [-0.04908054 -0.13197692  0.45246673 ...  0.7914851  -0.50839955
  -0.51546127]
 [ 1.1684042  -0.0271807   0.5604958  ...  0.22894716  0.7907647
  -0.09262008]
 [ 0.47522852 -1.1030271   0.1443118  ...  0.25134647 -0.17597297
   0.02356127]]
layers.1.weight: [[ 0.4501099   0.1868267   0.5031716  ...  0.00980974 -0.58866984
  -0.33031845]
 [ 0.19907208  0.8835649  -0.37207878 ...  0.321169   -0.04078332
   0.4856229 ]
 [-0.10480381  0.12953906  0.33748108 ...  0.14002877 -0.38954288
  -0.30814803]
 ...
 [-0.26132065  0.4909956   0.21790172 ...  0.00503836  0.05202961
  -0.25124753]
 [ 0.03801837 -0.34518668  0.13890184 ...  0.1611342   0.06525838
  -0.01417801]
 [ 0.4135003   0.08498846 -0.11419894 ...  0.3854733  -0.06857076
   0.14264107]]
layers.2.weight: [[-0.644838   -0.39612377  0.7000301   0.7627439  -0.5531624   0.8186784
  -0.74929917 -0.6466949  -0.3774219  -1.1943758  -0.53607714  0.56699383
  -0.49730802  0.5467114   0.59370726  0.6084068   0.54446477  0.53840625
  -0.3570831   0.76123285 -0.5944874  -0.75956964 -1.0199251  -0.9106824
  -0.4085226  -0.35294667 -0.45199648 -0.5009785   0.8273897  -0.7049721
   0.40373942 -0.4272865 ]]

Final Loss: 3.3822
Distance Metric: 62.6742
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_tanh -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[-0.11584213 -0.05192599  0.0198532  ... -0.02150243 -0.0814645
  -0.03941523]
 [-0.07100344  0.1152238  -0.12007421 ...  0.08292409  0.01647181
   0.01552695]
 [-0.02435631  0.03269106 -0.13383593 ...  0.00657626 -0.09516574
  -0.0549111 ]
 ...
 [-0.12688597 -0.16518334  0.05302345 ...  0.02797872 -0.09245803
   0.18464553]
 [-0.10435554  0.05725199  0.01538852 ... -0.01516471 -0.15888256
   0.0527077 ]
 [ 0.10466556 -0.1032903  -0.05703802 ...  0.01596833 -0.0765597
  -0.02992086]]
layers.1.weight: [[-0.2699888   0.17299646 -0.45552275 ...  0.19837515 -0.1616826
  -0.01329088]
 [ 0.3235601   0.10811792  0.22188544 ... -0.49257937  0.04566982
   0.360129  ]
 [ 0.04440739 -0.38377354 -0.33373168 ... -0.22075309  0.6860643
   0.238426  ]
 ...
 [-0.06976268  0.0277045   0.08795387 ...  0.08456744  0.33969042
  -0.0035185 ]
 [-0.15758365 -0.11120185  0.11805036 ...  0.33454308 -0.22574458
   0.04196304]
 [ 0.0339468  -0.10205398 -0.01203266 ... -0.43361607 -0.1389618
  -0.0626697 ]]
layers.2.weight: [[-0.16095822 -1.9924449  -0.989559   -0.57446784 -2.3747218   0.13494784
  -0.8695213  -0.49338552  1.0697422  -0.03623096 -0.8764891   0.84799105
  -0.40121683 -0.7498474   0.98229885  0.7942348  -1.6540902   0.3617838
  -0.19421567 -1.1319908  -1.3876393  -0.15797913 -0.47259977 -4.2621922
   0.99584574  1.7773925   1.7283773   0.3046885  -0.9375548   0.08753049
  -1.9106249  -1.5908648 ]]

Final Loss: 0.3918
Distance Metric: 39.3282
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_tanh -> fcnn_decreasing_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.08435635 -0.02639057  0.11096407 ...  0.26926005 -0.06884442
  -0.00601617]
 [-0.00785907 -0.11740251  0.03136724 ...  0.10747466  0.0410969
   0.0761365 ]
 [-0.6080943   0.62228554 -0.24854553 ... -0.01405638 -0.21508956
  -0.09959379]
 ...
 [ 0.18474075  0.10853101  0.02178529 ...  0.08172027 -0.18477401
   0.15288736]
 [ 0.2922402  -0.430665    0.2392983  ... -0.09383415  0.03425049
  -0.1243792 ]
 [ 0.23248033 -0.36897165  0.18287678 ... -0.16060196  0.01744515
   0.09017128]]
layers.1.weight: [[ 0.09642924  0.12212238 -0.21635686 ... -0.00880412  0.06021035
   0.03106475]
 [ 0.03127476  0.05927225  0.01207078 ...  0.11406129  0.11990203
   0.09116945]
 [-0.05274795  0.02253546  0.08555763 ... -0.08115142  0.0110175
   0.01855209]
 ...
 [-0.11771797  0.04014466  0.1848748  ... -0.12268464 -0.14228934
   0.03717332]
 [ 0.11544283  0.00225864 -0.17822781 ...  0.05982173  0.0705742
  -0.0033315 ]
 [ 0.13702421  0.13387889  0.11029181 ...  0.09112366  0.00250625
  -0.13570929]]
layers.2.weight: [[-7.90509105e-01  8.57555687e-01 -1.06743574e+00 -1.03335607e+00
  -5.34801364e-01  1.52070606e+00 -1.62521791e+00 -1.29340768e+00
  -2.59192125e-03  1.68918884e+00 -2.34947681e+00  2.67318296e+00
   1.02606571e+00  1.10431395e-01 -3.05688715e+00 -1.32712591e+00
   3.00980955e-01 -2.02687120e+00  1.16958249e+00 -1.50324380e+00
   1.18222773e+00 -5.33112526e-01 -4.35766554e+00  9.82660055e-01
   2.02690408e-01 -3.63827729e+00 -1.02438819e+00 -9.34009910e-01
   5.47487617e-01 -1.25986242e+00 -2.95257044e+00  2.24361852e-01]]

Final Loss: 0.1989
Distance Metric: 42.6097
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120
nonoverlappingCNN_tanh -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[-0.01100163  0.04531153 -0.07237527 ...  0.0076433   0.02759701
   0.06116869]
 [-0.14684805 -0.01051011  0.12504648 ...  0.1597026  -0.07214426
  -0.05697475]
 [-0.09030868  0.00410995 -0.12791571 ...  0.06725741  0.029156
   0.10286753]
 ...
 [-0.01042049  0.08272292  0.02496615 ... -0.13085762  0.07342995
   0.09362762]
 [-0.0029389  -0.0674246   0.1539221  ...  0.02822539 -0.15057734
   0.10338417]
 [ 0.13249855 -0.06378339 -0.02757125 ...  0.40944308  0.11850782
  -0.002883  ]]
layers.1.weight: [[-0.06487896  0.30717435  0.23742044 ...  0.07668662 -0.45770925
   0.4666145 ]
 [-0.304209    0.41473943 -0.02207517 ... -0.06872763  0.09465507
   0.74616754]
 [-0.2141777  -0.33361268 -0.39603835 ...  0.02592076  0.29906878
  -0.19685845]
 ...
 [ 0.35920045  0.23303159  0.33838788 ... -0.09944314  0.06985649
   0.3764747 ]
 [ 0.18797635  0.27641255  0.03889006 ... -0.02829018  0.18826267
  -0.00196257]
 [ 0.22954732  0.38125402  0.37203756 ... -0.38029224 -0.19284901
  -0.36005712]]
layers.2.weight: [[ 0.24354528 -2.1817582   0.94452465 -1.6428732  -2.0907388  -0.5525272
  -1.0376328   0.6898979  -3.141401    0.08444776  2.8143184  -0.88589823
  -0.0581497   4.205968   -0.3822944  -0.7568172   0.58394194 -0.18524481
   0.2662414  -0.55628294  0.19996415  2.0955005   0.50160944  0.5185816
   1.4157554   0.08649852  1.0673469   1.8035761  -3.136196   -3.5927246
   0.5095389  -0.3571072 ]]

Final Loss: 0.3883
Distance Metric: 41.7256
L1 norm: 1e-05
L2 norm: 0
Batch size: 16
Clipping: 0
Learning rate: 0.005
data size: 5120

