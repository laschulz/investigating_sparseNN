Experiment Summary:
================================================================================

Teacher Model Parameters:
layers.0.weight: [[[ 2.59 -2.83  0.87]]]
layers.1.weight: [[[-1.38  1.29]]]
layers.2.weight: [[[ 0.86 -0.84]]]

================================================================================

nonoverlappingCNN_relu -> fcnn_decreasing_relu

Student Model Parameters:
layers.0.weight: [[ 0.21549861  0.30984676 -0.03634432 ... -0.31938237  0.4457476
   0.56288314]
 [-0.19230701  0.08761163  0.06399405 ... -0.39438158  0.30672526
   0.17968296]
 [ 0.2763523  -0.26948047  0.20409529 ... -0.26553285  0.5826616
  -0.4846936 ]
 ...
 [-0.29562336 -0.00560526 -0.6215391  ...  0.13206048 -0.47848234
  -0.05611621]
 [-0.92434543  0.4430339   0.07985766 ...  0.18649867 -0.2796598
  -0.02549963]
 [-0.73081046  0.94750774  0.43589947 ...  0.5030124  -0.25030842
   0.06491626]]
layers.1.weight: [[-0.03644295  0.07289802  0.00379129 ...  0.10842875 -0.0047506
  -0.15646793]
 [-0.03750568  0.01887455 -0.05129938 ...  0.01477986  0.1089951
   0.01881241]
 [ 0.05784627 -0.03106482  0.03622854 ...  0.02720485  0.02266906
  -0.03207216]
 ...
 [ 0.07657573  0.06327182 -0.06761628 ... -0.02016928 -0.13896456
   0.06216938]
 [-0.0589847  -0.06801662 -0.04664244 ... -0.08154169  0.00859497
   0.00965025]
 [ 0.03724185 -0.04747933  0.01523807 ...  0.04741799  0.0048721
   0.0240647 ]]
layers.2.weight: [[ 2.13627040e-01 -2.12574422e-01 -6.87881589e-01  2.68637627e-01
  -5.31703174e-01 -1.91859201e-01  4.03765649e-01 -3.90305698e-01
   1.44968718e-01 -2.33107731e-01 -6.47900030e-02 -1.10244900e-01
  -1.16531581e-01  3.92608702e-01 -2.04285339e-01 -1.01455316e-01
  -2.38383442e-01 -2.28660405e-01 -5.27403593e-01 -2.46606573e-01
  -4.35984373e-01  1.69207379e-01 -1.84170976e-01 -1.18066251e-01
  -2.07536846e-01  9.80308503e-02 -1.88695341e-01  4.30139095e-01
   9.02754962e-02 -3.46493453e-01  2.29337737e-01  2.35272935e-04]]

Final Loss: 5.0851
Distance Metric: 44.5369
L1 norm: 0
L2 norm: 1e-05
Batch size: 32
Clipping: 0

================================================================================

nonoverlappingCNN_tanh -> fcnn_decreasing_tanh

Student Model Parameters:
layers.0.weight: [[ 0.27426735  0.3068764  -0.76095957 ...  0.18649961  0.15886898
  -0.69695   ]
 [ 0.34053743  0.07117596  0.7398146  ...  0.04025751 -0.2476737
   0.35893893]
 [-0.48475215  0.39037383 -0.7034223  ... -0.00698916 -0.12931277
   0.06587927]
 ...
 [-0.14869441  0.927736   -0.46043143 ...  0.42219272  0.15695521
   0.34908086]
 [ 0.26287416  0.28371432  0.02546446 ... -0.8558276   0.07369571
   0.0943763 ]
 [-0.06662759 -0.34973785 -0.40573892 ... -0.6106547   0.18817033
  -0.42886   ]]
layers.1.weight: [[ 0.06993356  0.08210831  0.07444113 ... -0.04679875  0.00336186
  -0.01720145]
 [-0.03018967  0.07587684 -0.1362505  ...  0.06074822 -0.09039266
  -0.04640438]
 [ 0.00892742  0.01310048  0.02474031 ...  0.03303944 -0.05245228
  -0.08011774]
 ...
 [-0.00899989  0.03065101  0.00140308 ... -0.03707089 -0.05052541
  -0.09350855]
 [ 0.04825364 -0.03754352 -0.03109195 ... -0.02287705  0.0020809
   0.03575702]
 [ 0.07160953  0.04994925  0.03776028 ...  0.01794529  0.06553942
  -0.13124679]]
layers.2.weight: [[-0.00052599  0.00818451  0.          0.01125971 -0.00056778 -0.00493771
   0.00079948  0.00094832  0.01131855 -0.00578452  0.00983411  0.0004179
  -0.00214806  0.0058635  -0.00392111  0.00234401  0.00101053  0.00999578
  -0.00641555 -0.00011259 -0.01474797 -0.01065059 -0.0054059   0.00490639
  -0.00735387  0.00337708  0.00576677 -0.00438696  0.00279354 -0.00613039
  -0.00306938  0.00907056]]

Final Loss: 0.3586
Distance Metric: 44.0761
L1 norm: 0
L2 norm: 1e-05
Batch size: 32
Clipping: 0

================================================================================

nonoverlappingCNN_sigmoid -> fcnn_decreasing_sigmoid

Student Model Parameters:
layers.0.weight: [[-0.02243422 -0.07875562  0.2718513  ...  0.15664272 -0.42773363
  -0.05273784]
 [ 0.6391877  -0.18282442 -0.45455828 ... -0.06400884  0.16555463
  -0.7188827 ]
 [-0.01214101  0.11852868 -0.44180164 ... -0.00425095  0.16295566
  -0.01202295]
 ...
 [ 0.26246065 -0.14108531 -0.07664665 ...  0.19290194 -0.3290355
   0.362671  ]
 [ 0.0840708  -0.7042417   0.3934513  ...  0.33873993  0.04784764
   0.09437707]
 [-0.4740163   0.04544398 -0.71455157 ... -0.23676893  0.20471758
  -0.1525625 ]]
layers.1.weight: [[-0.00801751 -0.06603236 -0.11237403 ...  0.02297886 -0.05905271
   0.02595302]
 [-0.00506356 -0.06015097  0.00906968 ...  0.04590816 -0.0154678
   0.02431592]
 [ 0.0260688  -0.02563699  0.00647959 ...  0.03063454  0.08373345
  -0.04087939]
 ...
 [ 0.03623792  0.02394179  0.05601909 ...  0.05150282 -0.08374176
  -0.00919389]
 [-0.00980427  0.06405116  0.03879893 ...  0.03758275  0.08112746
   0.03404744]
 [-0.06434583 -0.01563091  0.04110278 ... -0.10869496 -0.11628226
  -0.04368792]]
layers.2.weight: [[ 2.39001349e-01 -3.87391821e-02  1.04081094e-01 -6.72263131e-02
   1.68077394e-01 -5.60356071e-03 -6.78151324e-02 -3.94661188e-01
   2.28450119e-01 -2.85382956e-01 -1.33236438e-01  3.88020784e-01
   3.85667294e-01  2.46066542e-04 -1.27103433e-01 -1.60821512e-01
  -6.06170017e-03 -3.27707157e-02 -1.26952127e-01  5.55286231e-03
   5.86173944e-02  1.08764123e-03  3.10266882e-01  3.98029625e-01
  -4.00554202e-03  5.12055792e-02  8.36171582e-02  1.13270961e-01
   1.13580540e-01 -1.35073408e-01  4.16333526e-01 -1.84562787e-01]]

Final Loss: 0.0024
Distance Metric: 44.8172
L1 norm: 0
L2 norm: 1e-05
Batch size: 32
Clipping: 0

================================================================================

